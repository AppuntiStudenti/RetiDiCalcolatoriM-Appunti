%% ================================================================================
%% This LaTeX file was created by AbiWord.                                         
%% AbiWord is a free, Open Source word processor.                                  
%% More information about AbiWord is available at http://www.abisource.com/        
%% ================================================================================

\documentclass[a4paper,12pt]{article}
\usepackage[latin1]{inputenc}
\usepackage{calc}
\usepackage{setspace}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[normalem]{ulem}
%% Please revise the following command, if your babel
%% package does not support it-IT
\usepackage[italian]{babel}
\usepackage{color}
\usepackage{hyperref}

\title{Riassunto di studio per Reti di Calcolatori LS}
\author{Daniele Tiles}
\date{7 ottobre 2007}


\begin{document}
\maketitle
\tableofcontents

.


.





.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.





.


.


.


.


.


.


.


.


.


.





72


73


75


76


77


77


78


78


78


79


79





\begin{flushleft}
8 I Web Services
\end{flushleft}


\begin{flushleft}
8.1 Struttura generale de
\end{flushleft}


\begin{flushleft}
8.2 SOAP . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.3 WSDL . . . . . . . .
\end{flushleft}


\begin{flushleft}
8.4 UDDI e WSIL . . .
\end{flushleft}





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





.


.


.


.





80


80


81


82


83





\begin{flushleft}
WS
\end{flushleft}


. . .


. . .


. . .





.


.


.


.





.


.


.


.





.


.


.


.





3





.


.


.


.





.


.


.


.





.


.


.


.


.


.


.


\begin{flushleft}
e
\end{flushleft}


.


.





. .


. .


. .


. .


. .


. .


. .


\begin{flushleft}
dei
\end{flushleft}


. .


. .





\newpage
8.5





\begin{flushleft}
Considerazioni nali sui WS . . . . . . . . . . . . . . . . . . . . .
\end{flushleft}





\begin{flushleft}
9 Gestione delle risorse e sistemi
\end{flushleft}


\begin{flushleft}
9.1 Mobilit` delle risorse . . . . .
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
9.2 Muovere i processi . . . . . .
\end{flushleft}


\begin{flushleft}
9.3 Sistemi ad agenti mobili . . .
\end{flushleft}


\begin{flushleft}
9.4 Classicazione della mobilit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
9.5 Servono gli agenti mobili? . .
\end{flushleft}


\begin{flushleft}
9.6 Gli agenti mobili . . . . . . .
\end{flushleft}





\begin{flushleft}
mobili
\end{flushleft}


. . . . .


. . . . .


. . . . .


. . . . .


. . . . .


. . . . .





4





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





.


.


.


.


.


.





83


84


84


85


89


89


90


90





\begin{flushleft}
\newpage
L'obiettivo del corso ` introdurre modelli e tecnologie per poter superare il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
modello Client/Server (C/S), in modo da poter:
\end{flushleft}


\begin{flushleft}
$\bullet$ Migliorare la gestione
\end{flushleft}


\begin{flushleft}
$\bullet$ Introdurre un supporto alla qualit` del servizio, QoS : questo ` fondaa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mentale, perch` solo se un sistema presenta QoS, allora si pu` pensare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ad un sistema di retribuzione (Internet, mail e gli altri servizi lavorano
\end{flushleft}


\begin{flushleft}
best-eort): vi sono sistemi {`}pi` standard', importanti per i sistemi molto
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
carichi.
\end{flushleft}


\begin{flushleft}
$\bullet$ Sviluppare sistemi in grado di far fronte anche ad alta mobilit`, l'intea
\end{flushleft}


\begin{flushleft}
grazione di sistemi legacy, . . .
\end{flushleft}


\begin{flushleft}
Si tratta quindi di un corso per poter descrivere le tecnologie di sviluppo possibili
\end{flushleft}


\begin{flushleft}
per poter creare un sistema distribuito: cosa conviene scegliere, quando usare
\end{flushleft}


\begin{flushleft}
una tecnologia invece che un'altra? Ha senso cercare di realizzare una nuova
\end{flushleft}


\begin{flushleft}
tecnologia, un middleware 1 proprio? Per fare qualche esempio, non ha senso
\end{flushleft}


\begin{flushleft}
usare CORBA se il sistema necessita di un unico nodo, dove si deve interagire
\end{flushleft}


\begin{flushleft}
con componenti Java, oppure si devono usare agenti mobili dove ` necessaria la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mobilit`! Vi ` un particolare interesse per il progetto e testing (soprattutto per
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'esecuzione e il deployment).
\end{flushleft}





1





\begin{flushleft}
Modelli di computazione
\end{flushleft}





\begin{flushleft}
Per poter sviluppare un sistema distribuito, ` utile denire diversi modelli per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'esecuzione, in modo da poter classicarli (modelli diversi possono avere vantaggi/svantaggi a seconda del sistema che si deve andare a realizzare). La maggior
\end{flushleft}


\begin{flushleft}
parte dei modelli purtroppo son troppo astratti per poter essere realmente utili
\end{flushleft}


\begin{flushleft}
da un punto di vista ingegneristico, cio` non riescono a comprendere in toto la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
complessit` reale.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Le prime distinzioni che si possono fare sono su come si possono prendere le
\end{flushleft}


\begin{flushleft}
decisioni:
\end{flushleft}


\begin{flushleft}
$\bullet$ modelli statici : le decisioni vengono prese prima dell'esecuzione. Risulta
\end{flushleft}


\begin{flushleft}
quindi essere meno essibile, e non si pu` variare nel corso dell'esecuzione,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
fornendo quindi poca qualit` di servizio.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ modelli dinamici : in questo modello le decisioni risultano essere maggiormente costose, proprio perch` si prendono mentre il modello ` in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
esecuzione.
\end{flushleft}


\begin{flushleft}
Per fare un esempio, il collegamento fra un client e un Name Server come deve
\end{flushleft}


\begin{flushleft}
essere stabilito? In maniera statica o dinamica? E fra il client e server? Si tratta
\end{flushleft}


\begin{flushleft}
1 Un middleware ` un qualcosa che si interpone fra l'applicazione e i livelli pi` bassi: fornisce
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
servizi di aiuto per lo sviluppatore, mette a disposizione meccanismi per poter implementare
\end{flushleft}


\begin{flushleft}
diverse politiche
\end{flushleft}





5





\begin{flushleft}
\newpage
di problematiche da risolvere in fase di progettazione, tenendo conto dei costi.
\end{flushleft}


\begin{flushleft}
Un middleware introduce questi costi, fornendo possibilit` statiche/dinamiche
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(non esiste un sistema totalmente dinamico, realmente totalmente aperto).
\end{flushleft}


\begin{flushleft}
Una seconda distinzione riguarda sulla reazione in caso di errori o concorrenza:
\end{flushleft}


\begin{flushleft}
$\bullet$ modelli preventivi : si fornisce un comportamento garantito, oppure si pre`
\end{flushleft}


\begin{flushleft}
viene/evitano determinati errori. E quindi un sistema rigido, che presenta
\end{flushleft}


\begin{flushleft}
dei costi ssi.
\end{flushleft}


\begin{flushleft}
$\bullet$ modelli reattivi : il modello reagisce in maniera dinamica alle situazioni
\end{flushleft}


\begin{flushleft}
che si presentano: non ` prevista quindi una politica di default, non si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
stabiliscono risorse a priori come nel caso precedente, fornendo un comportamento pi` essibile. I costi risultano essere variabili, a seconda della
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
complessit` del sistema (al crescere degli attori, aumenta il numero neca
\end{flushleft}


\begin{flushleft}
essario di lock/semafori da utilizzare, per esempio). Il costo pu` quindi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
essere limitato a seconda delle esigenze.
\end{flushleft}


\begin{flushleft}
Esempio: una serie di clienti vogliono accedere in maniera univoca ad una risorsa unica: si tratta quindi di un problema di sincronizzazione e mutua esclusione.
\end{flushleft}


\begin{flushleft}
Si potrebbe risolvere fornendo dei quanti di tempo decisi a priori per ogni singolo cliente, oppure si fornisce un token, per cui chi lo possiede ` l'unico a poter
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
accedere alla risorsa.
\end{flushleft}


`


\begin{flushleft}
E da osservare che un sistema distribuito in generale ore un insieme di
\end{flushleft}


\begin{flushleft}
politiche diverse, che si possono mescolare a seconda delle esigenze: un sistema
\end{flushleft}


\begin{flushleft}
moderno infatti deve essere in grado di seguire l'evoluzione dei servizi per poter
\end{flushleft}


\begin{flushleft}
sopravvivere (es CORBA: in versioni successive aggiunge supporto al Web).
\end{flushleft}


\begin{flushleft}
Un ulteriore modello semplice da descrivere riguarda in che modo le risorse
\end{flushleft}


\begin{flushleft}
sono associate alle applicazioni:
\end{flushleft}


\begin{flushleft}
$\bullet$ Siamo in monoutenza se le risorse sono tutte dedicate all'applicazione
\end{flushleft}


\begin{flushleft}
descritta
\end{flushleft}


\begin{flushleft}
$\bullet$ Altrimenti si parla di multiutenza: pi` complessa, ma decisamente pi`
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
diusa. Infatti, un numero superiore di applicazioni pu` portare ad un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
uso pi` eciente delle risorse.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
A seguito, si pu` ragionare quindi come sono disponibili le risorse:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello workstation: le risorse sono concentrate su un unico nodo.
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello processor pool : le risorse sono distribuite, e vengono associate in
\end{flushleft}


\begin{flushleft}
maniera trasparente al servizio.
\end{flushleft}





6





\newpage
1.1





\begin{flushleft}
Processi o oggetti?
\end{flushleft}





\begin{flushleft}
Un'ulteriore distinzione riguarda su cosa basarsi per descrivere eettivamente
\end{flushleft}


\begin{flushleft}
come avviene l'esecuzione.
\end{flushleft}


\begin{flushleft}
Un primo modello si basa sull'idea del processo, che incarna la capacit` di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
esecuzione della macchina. Si specicano quindi delle operazioni, e si tratta di
\end{flushleft}


\begin{flushleft}
modelli che tengono conto della macchina su cui si lavora, e funzionano molto
\end{flushleft}


\begin{flushleft}
bene con risorse locali e stato locali. Vi sono pi` modelli:
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
$\bullet$ Processi alla Unix: si tratta di processi pesanti, ognuno dotato di un
\end{flushleft}


\begin{flushleft}
proprio stato locale. In questo modello interessa solo in che modo i processi
\end{flushleft}


\begin{flushleft}
possono comunicare, essendo lo stato non condivisibile.
\end{flushleft}


\begin{flushleft}
$\bullet$ Processi alla Java: i processi son leggeri, hanno uno stato condiviso che
\end{flushleft}


\begin{flushleft}
pu` essere usato anche per comunicare. Risulta essere pi` facile fare anche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
dei cambi di contesto, ma si possono presentare delle interferenze.
\end{flushleft}


\begin{flushleft}
I thread di una JVM, proprio perch` dotati di uno stato condiviso, si possono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
rapportare con un'altra JVM. I thread leggeri utilizzano lo stato comune per
\end{flushleft}


\begin{flushleft}
comunicare.
\end{flushleft}


`


\begin{flushleft}
Un'altra idea riguarda la modellazione basata sul paradigma ad oggetti. E
\end{flushleft}


\begin{flushleft}
importante ricordarsi che questi son sempre delle astrazioni, e quindi necessitano
\end{flushleft}


\begin{flushleft}
di una concretizzazione successiva. Anche qui si possono supporre due diversi
\end{flushleft}


\begin{flushleft}
modelli:
\end{flushleft}


\begin{flushleft}
$\bullet$ Oggetti passivi : i classici oggetti alla Java. Rappresentazione l'astrazione
\end{flushleft}


\begin{flushleft}
di dati su cui delle entit` esterne possono lavorare. Non sono quindi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dotati di capacit` propria d'esecuzione. Si pu` quindi avere concorrenza
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
fra diversi processi che vogliono accedere allo stesso oggetto, non si ha un
\end{flushleft}


\begin{flushleft}
buon connamento e si ha scarsa protezione.
\end{flushleft}


\begin{flushleft}
$\bullet$ Oggetti attivi : sono oggetti dotati di propria capacit` d'esecuzione. I
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
processi quindi non entrano nell'oggetto, perch` vi ` gi` all'interno dele
\end{flushleft}


\begin{flushleft}
e a
\end{flushleft}


\begin{flushleft}
l'oggetto una propria logica di gestione (si ha quindi un modello a request/response: un processo richiede di poter usare l'oggetto mediante i
\end{flushleft}


\begin{flushleft}
{`}metodi' forniti da questo, e questo in base alla sua schedulazione risponde
\end{flushleft}


`


\begin{flushleft}
alla richiesta E sempre da osservare che un oggetto attivo ha comunque
\end{flushleft}


\begin{flushleft}
un proprio stato interno, descritto da una parte sequenziale, ma a cui
\end{flushleft}


\begin{flushleft}
non vi si accede con dei metodi, proprio grazie a questa logica interna: i
\end{flushleft}


\begin{flushleft}
metodi veri e propri sono utilizzati solo internamente!). Un oggetto attivo
\end{flushleft}


\begin{flushleft}
` quindi dotato di una coda delle richieste che si sono presentate, e una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sua politica di scheduling. Si supera in questo modo il problema degli
\end{flushleft}


\begin{flushleft}
oggetti passivi, proteggendo del tutto l'oggetto e determinandolo completamente. Un oggetto attivo quindi, massimizzando la parte sequenziale,
\end{flushleft}


\begin{flushleft}
si pu` spostare pi` facilmente. Rappresent lo stesso modello dei servitori
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
paralleli, e, per esempio, degli agenti mobili. Un oggetto attivo quindi
\end{flushleft}


7





\begin{flushleft}
\newpage
si preoccupa di tutta la gestione dell'esecuzione internamente (richieste,
\end{flushleft}


\begin{flushleft}
attivit`, errori, processi interni. . . :si forniscono meccanismi, mediante il
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
quale si possono specicare delle politiche diverse!
\end{flushleft}


\begin{flushleft}
Come mai in Java tale modello non ` stato implementato? Si tratta di un mode
\end{flushleft}


\begin{flushleft}
ello molto costoso, che non presenta delle scorciatoie utili se si lavorasse solo in
\end{flushleft}


\begin{flushleft}
ambito locale!
\end{flushleft}


\begin{flushleft}
Nei sistemi moderni, in realt` si parla di classi che contengono le denizioni
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
degli oggetti, e deniscono lo stato interno e i metodi con cui accedere. In particolare, in generale si parla di semantica per riferimento, che per` ` in grado
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
di funzionare solo in un ambito locale. Per riferire in remoto, serve un supporto
\end{flushleft}


\begin{flushleft}
esterno. Per esempio, si parla di utilizzare socket, protocolli standard de facto
\end{flushleft}


\begin{flushleft}
come TCP/IP. . .
\end{flushleft}


\begin{flushleft}
Tuttavia, ` proprio questo il motivo per cui si vengono a denire dei mide
\end{flushleft}


\begin{flushleft}
dleware, ovvero delle strutture in grado di fornire un supporto completo alla
\end{flushleft}


\begin{flushleft}
comunicazione in remoto. Per esempio, Java Remot Method Invocation ` un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sistema in grado di estendere la semantica per riferimento locale, al remoto,
\end{flushleft}


\begin{flushleft}
cercando di fornire un sistema omogeneo per poter accedere sia ad oggetti locali
\end{flushleft}


\begin{flushleft}
che remoti. Nel caso specico di RMI, per esempio, si utilizza un classico pattern dei middleware, il proxy come delegato per la comunicazione. Si realizzano
\end{flushleft}


\begin{flushleft}
infatti uno stub lato cliente e uno skeleton lato server, che riescono a garantire
\end{flushleft}


\begin{flushleft}
un qualcosa di simile alla normale comunicazione locale. Si cerca di presentare
\end{flushleft}


\begin{flushleft}
un sistema trasparente per l'utente!
\end{flushleft}


`


\begin{flushleft}
Perch` quindi non realizzare tutti i riferimenti come riferimenti remoti? E
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sempre una questione di costo, sarebbe inaccettabile. Basta pensare a cosa
\end{flushleft}


\begin{flushleft}
succede ad un oggetto passato via RMI: deve essere serializzabile, e cos` tutti
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
i suoi componenti, in maniera che si possa fare marshalling e unmarshalling.
\end{flushleft}


\begin{flushleft}
Ci` non ` sempre possibile in Java RMI (si pensi ad un oggetto che riferisce un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
oggetto di tipo File, una risorsa strettamente locale). Vi sono poi altri problemi
\end{flushleft}


\begin{flushleft}
da considerare:
\end{flushleft}


\begin{flushleft}
$\bullet$ Un oggetto remoto viene registrato in un apposito registry, ma se viene
\end{flushleft}


\begin{flushleft}
deattivato? Come viene gestita quindi la persistenza? E lo stato remoto?
\end{flushleft}


\begin{flushleft}
$\bullet$ Due stub diversi possono riferire lo stesso oggetto remoto? Se s` come si
\end{flushleft}


\begin{flushleft}
\i{},
\end{flushleft}


\begin{flushleft}
gestisce la concorrenza?
\end{flushleft}


\begin{flushleft}
$\bullet$ Come risolvere i nomi? Si pu` usare un riferimento sso, ma l'oggetto pu`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
essere diverso (ma non ` il caso di Java).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Si deve anche passare l'indicatore della classe, perch` si possa realmente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
utilizzare l'oggetto: cosa succede se la classe ` gi` presente? Java per
\end{flushleft}


\begin{flushleft}
e a
\end{flushleft}


\begin{flushleft}
esempio controlla mediante l'hash se la classe ` eettivamente quella core
\end{flushleft}


\begin{flushleft}
retta.
\end{flushleft}





8





\newpage
1.2





\begin{flushleft}
Deployment dell'applicazione
\end{flushleft}





\begin{flushleft}
Un'applicazione distribuita spesso necessita che sia suddivisa in diversi componenti, anche allocati su nodi diversi! Un componente ` un'entit` con una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
granularit` superiore all'oggetto, ovvero introduce comportamento e interazione,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
estendo l'idea dell'oggetto.
\end{flushleft}


\begin{flushleft}
Se si hanno quindi diversi componenti, che devono dialogare fra di loro, non
\end{flushleft}


\begin{flushleft}
` detto che il deployment su una singola macchina sia la soluzione ideale: infate
\end{flushleft}


\begin{flushleft}
ti, su un solo processore si ha una sequenzializzazione delle operazioni, e quindi
\end{flushleft}


\begin{flushleft}
dell'applicazione stessa.
\end{flushleft}


\begin{flushleft}
Spesso e volentieri, un middleware non si occupa del deployment, ma deve
\end{flushleft}


\begin{flushleft}
essere realizzato da chi gestisce l'interazione fra i componenti. L'allocazione
\end{flushleft}


\begin{flushleft}
pu` essere statica, cio` decisa prima dell'esecuzione, oppure dinamica, quindi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
durante; quest'ultimo modello permette di poter spostare le risorse a seconda
\end{flushleft}


\begin{flushleft}
delle esigenze durante l'esecuzione. Spesso e volentieri, l'allocazione viene realizzata utilizzando dei semplici le batch, rendendola semi-manuale (certe congurazioni devono poi essere sistemate a seconda dei casi dall'operatore). L'approccio misto ` quello pi` usato, essendo una via di mezzo fra l'allocazione esplicita
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
(tutta a carico dell'utente) e quella implicita (decisa in toto dal sistema).
\end{flushleft}





1.3





\begin{flushleft}
Altri modelli oltre il C/S
\end{flushleft}





\begin{flushleft}
Esistono diversi altri modelli oltre il classico C/S:
\end{flushleft}


\begin{flushleft}
$\bullet$ Push: il servitore fornisce il servizio al cliente
\end{flushleft}


\begin{flushleft}
$\bullet$ Pull: il cliente recupera il servizio che necessita in maniera diretta.
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello a delega: il cliente delega un altro agente per attendere il risultato,
\end{flushleft}


\begin{flushleft}
e poi lo recupera da questo.
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello a notica: simile al precedente, solo che il delegato notica al
\end{flushleft}


\begin{flushleft}
cliente la disponibilit` del risultato.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello ad eventi: il tipico modello consumer/provider, in cui chi ` intere
\end{flushleft}


\begin{flushleft}
essato si registra a chi produce gli eventi.
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello a provisioning: oltre agli end-point, vi sono intermediari interessati al risultato.
\end{flushleft}


\begin{flushleft}
Di particolare interesse ` la classicazione dei modelli a scambio di messaggi :
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ In fase di progettazione, si parla di sistemi sincroni se si ` interessati al
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
risultati, altrimenti asincroni.
\end{flushleft}


\begin{flushleft}
$\bullet$ In fase implementativa, si parla di comunicazione bloccante se il richiedente
\end{flushleft}


\begin{flushleft}
si blocca in attesa del risultato, altrimenti non bloccante
\end{flushleft}





9





\begin{flushleft}
\newpage
Oltre alla classicazioni principali, altre caratteristiche con cui si possono classicare i modelli a scambio di messaggi:
\end{flushleft}


\begin{flushleft}
$\bullet$ In fase di progettazione si parla di
\end{flushleft}


\begin{flushleft}
-- un sistema simmetrico se mittente e ricevente si conoscono (rarissimo) oppure asimmetrico (caso tipico:C/S).
\end{flushleft}


\begin{flushleft}
-- un sistem diretto (cio` se avviene una comunicazione diretta fra i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
processi), oppure indiretto (se si utilizzano strutture tipo le socket)
\end{flushleft}


\begin{flushleft}
$\bullet$ In fase di implemtazione si parla di
\end{flushleft}


\begin{flushleft}
-- un sistema buerizzato se la comunicazione richiede un certo numero
\end{flushleft}


\begin{flushleft}
di messaggi prima di poter trasmettere
\end{flushleft}


\begin{flushleft}
-- Sistemi reliable se possono fornire QoS, senza perdere messaggi.
\end{flushleft}


\begin{flushleft}
Nel caso si introduca un terzo oggetto che faccia da mediatore, si pu` quindi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
lavorare in maniera sincrona ma non bloccante: ` il mediatore che resta in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
attesa, sganciando il ricevente. Si possono avere due diverse modalit`:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
1. Oggetti poll : ` un contenitore per la risposta alla richiesta, che viene
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
periodicamente interrogato dal ricevente con un sistema a polling. Si ha
\end{flushleft}


\begin{flushleft}
cos` una comunicazione a 3 entit`. In questo modello, il ricevente deve
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sapere dove si trova l'oggetto poll, e vi deve essere un oggetto per ogni
\end{flushleft}


`


\begin{flushleft}
risultato. E conveniente se si hanno operazioni corte, e attese brevi.
\end{flushleft}


\begin{flushleft}
2. Oggetti callback : ` sempre un oggetto che conterr` il risultato, ma dotato
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di una sua vita indipendente, e dotato di codice particolare da eseguire
\end{flushleft}


`


\begin{flushleft}
quando giunge il risultato. E lui quindi a dover fornire il risultato al
\end{flushleft}


\begin{flushleft}
richiedente, svincolandolo del tutto da questo! Conveniente in caso di
\end{flushleft}


\begin{flushleft}
operazioni lunghe, indipendenti dal chiamante.
\end{flushleft}


\begin{flushleft}
Spesso e volentieri, questi intermediari vengono realizzati da proxy, che sono in
\end{flushleft}


\begin{flushleft}
grado di ridurre la complessit` logica della soluzione, integrando diverse funa
\end{flushleft}


\begin{flushleft}
zionalit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
In un modello basato sugli eventi, si ha un fortissimo disaccoppiamento (non
\end{flushleft}


\begin{flushleft}
vuol dire che non si conoscono, ma che non ` necessario che siano attivi conteme
\end{flushleft}


\begin{flushleft}
poraneamente per poter fare la comunicazione; ` una caratteristica fondamene
\end{flushleft}


\begin{flushleft}
tale per i middleware) fra le entit` interessate al risultato, e quelle che forniscono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
i servizi. In questo modello si ha quindi un'interazione molti a molti, per cui si
\end{flushleft}


\begin{flushleft}
pu` facilmente mappare il multicast. In generale gli eventi non sono persistenti,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
tuttavia non ` l'unico modello possibile.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





10





\newpage
1.4





\begin{flushleft}
Spazi di tuple
\end{flushleft}





\begin{flushleft}
Un modello che deriva dall'astrazione della memoria condivisa e della comunicazione, e che garantisce il disaccoppiamento fra le varie entit` ` lo spazio di
\end{flushleft}


\begin{flushleft}
a e
\end{flushleft}


`


\begin{flushleft}
tuple. E un meccanismo generale per la comunicazione e la sincronizzazione, in
\end{flushleft}


\begin{flushleft}
cui si specica uno spazio di informazioni fortemente tipato. (Una tipica informazione pu` essere $<$ mittente, destinatario, data $>$, per cui tutti i dati devono
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
essere diversi perch` possa essere inserita)
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Si hanno quindi due operazioni principali: la out consiste nell'inserire nello
\end{flushleft}


\begin{flushleft}
spazio delle tuple un nuovo messaggio, mentre la in (bloccante) estrae la prima
\end{flushleft}


\begin{flushleft}
tupla che fa match (in caso di pi` tuple che facciano match, ` una scelta non
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
deterministica). Ovviamente, si avr` sempre un numero inferiore di in rispetto
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
alle out. Se la in ` completamente specicata, si parla di sincronizzazione e non
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di comunicazione. Uno spazio di tuple permette anche l'introduzione di QoS,
\end{flushleft}


\begin{flushleft}
grazie alla persistenza della tupla nello spazio.
\end{flushleft}


\begin{flushleft}
Gerlenter, con Linda, presenta due diversi modelli:
\end{flushleft}


\begin{flushleft}
$\bullet$ A ring: si partiziona lo spazio delle tuple, per cui ogni nodo conosce
\end{flushleft}


\begin{flushleft}
precedente e successivo: si ha una conoscenza locale, quindi limitata. Un
\end{flushleft}


\begin{flushleft}
produttore pu` fare una out su un qualsiasi nodo, e il messaggio fa un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ciclo per vericare che non sia gi` presente su un qualche nodo. Lo stesso
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
discorso vale per la in, che fa un giro no a trovare un messaggio che fa
\end{flushleft}


\begin{flushleft}
match. In Linda sono state considerate ovviamente delle problematiche
\end{flushleft}


\begin{flushleft}
di replicazione (il messaggio deve essere ripetuto? Ma quindi lo si deve
\end{flushleft}


\begin{flushleft}
togliere da tutti i nodi che lo contengono), sfruttando gli hash dei messaggi
\end{flushleft}


\begin{flushleft}
$\bullet$ A matrice: le out vengono eseguite sulle righe, mentre le in si fanno sulle
\end{flushleft}


\begin{flushleft}
colonne.
\end{flushleft}





1.5





\begin{flushleft}
Modelli a contenimento
\end{flushleft}





\begin{flushleft}
Si tratta di supporti presenti in ogni middleware: sono funzionalit` che aga
\end{flushleft}


\begin{flushleft}
gregano diverse attivit` utili, che si possono replicare. In questo modo, uno
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sviluppatore si concentra soltanto sullo sviluppo della business logic vera e
\end{flushleft}


\begin{flushleft}
propria, utilizzando le politiche di default fornite dal middleware per quanto
\end{flushleft}


\begin{flushleft}
riguarda il supporto al tempo di vita, il gestore della concorrenza, fornire la
\end{flushleft}


\begin{flushleft}
QoS, sistemi di nomi. . . Fondamentalmente, un container ` un delegato che si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comporta come supervisore di certe attivit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





1.6





\begin{flushleft}
Il problema della trasparenza
\end{flushleft}





\begin{flushleft}
Esistono diversi signicati per la trasparenza: per esempio, si intende per l'allocazione l'indipendenza dalla localit` delle risorse. In generale, per trasparenza si
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
intende un sistema in grado di fornire all'utente nale un comportamento omogeneo, anche se ai livelli sottostanti sta lavorando con oggetti/servizi diversi
\end{flushleft}


\begin{flushleft}
(remoti/locali, server principale/copia, . . . ).
\end{flushleft}





11





\begin{flushleft}
\newpage
Non ` sempre un elemento positivo, perch` in molti casi i sistemi son cos`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
complessi, che non si possono gestire in maniera totalmente trasparente: si
\end{flushleft}


\begin{flushleft}
richiede l'intervento dell'utente. Un esempio ` nella trasparenza dell'allocazione:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
se non sappiamo dove si trova l'utente, come facciamo a dargli il servizio desiderato? La trasparenza non ` corretta a livello di infrastruttura in questo caso;
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'utente infatti ` sempre pi` coinvolto.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Per esempio, TINA-C2 prevede sia un sistema trasparente, che un sistema
\end{flushleft}


\begin{flushleft}
non trasparente in cui si possano denire le risorse inizialmente, e quindi introdurre la trasparenza.
\end{flushleft}





1.7





\begin{flushleft}
Le macchine astratte
\end{flushleft}





\begin{flushleft}
Son stati sviluppati diversi modelli per l'esecuzione, ma alla base vi ` la Rane
\end{flushleft}


\begin{flushleft}
dom Access Machine: ` una macchina special purpose, con codice inalterabile,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
in grado di eseguire istruzioni in sequenza (tutte le istruzioni hanno la stessa
\end{flushleft}


\begin{flushleft}
durata), memoria limitata e un sistema di input e uno di output.
\end{flushleft}


\begin{flushleft}
Un primo modello per la comunicazione ` la Parallel RAM, in cui simmagina
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
diversi programmi da eseguire contemporaneamente. Una PRAM ` costituita
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi da P macchina RAM, ognuna delle quali esegue un programma, e ad ogni
\end{flushleft}


\begin{flushleft}
clock vengono eseguite P istruzioni. Alla base vi ` una memoria condivisa, per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tutte le macchine, dove scrivere e leggere i risultati (anche i dispositivi di I/O
\end{flushleft}


\begin{flushleft}
sono unici per tutte le macchine). Si tratta di un modello MIMD sincrono, per
\end{flushleft}


\begin{flushleft}
cui quando tutti i programmi niscono, anche la macchina termina. Essendo
\end{flushleft}


\begin{flushleft}
dotata di un'unica memoria, come devino essere strutturate le operazioni? La
\end{flushleft}


\begin{flushleft}
concorrenza ` un requisito dicile da realizzare, in confronto al mettere le opere
\end{flushleft}


\begin{flushleft}
azioni in sequenza. Le diverse PRAM si possono quindi categorizzare a seconda
\end{flushleft}


\begin{flushleft}
della tipologia delle operazioni (in generale si hanno letture concorrenti e scritture sequenziali; la concorrenza ` invece utilizzata per il sistema di I/O, per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
limitarne il collo di bottiglia). Un PRAM ` dicile da realizzare perch` non `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
scalabile.
\end{flushleft}


\begin{flushleft}
Un secondo modello ` il Message Passing RAM, che ` sempre una collezione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di RAM, ma ognuna con la sua memoria dedicata (i sistemi di I/O son sempre
\end{flushleft}


\begin{flushleft}
condivisi). Si ha quindi che le diverse macchine comunicano mediante dei canali
\end{flushleft}


\begin{flushleft}
prestabiliti (vi devono essere almeno P-1 connessioni). Si hanno istruzioni ad
\end{flushleft}


\begin{flushleft}
hoc, cio` delle send e receive con rendez-vous, una semantica sincrona: questo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vuol dire che un'operazione sblocca la sua duale. Una MP-RAM ` pi` facilmente
\end{flushleft}


\begin{flushleft}
e u
\end{flushleft}


\begin{flushleft}
realizzabile, e rappresenta meglio un modello locale. Se per esempio si volesse
\end{flushleft}


\begin{flushleft}
eseguire un broadcast, servono almeno P-1 istruzioni, mentre una PRAM, per
\end{flushleft}


\begin{flushleft}
quanto pi` dicile da realizzare, richiederebbe una sola operazione: ` un modu
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ello con maggiore capacit` espressiva. Restano comunque entrambi dei modelli
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
troppo astratti per poter essere implementati realmente. Aggiungendo vincoli
\end{flushleft}


\begin{flushleft}
2 Si tratta di un consorzio di aziende per le telecomunicazioni, con l'obiettivo di andare
\end{flushleft}


\begin{flushleft}
oltre OSI: l'idea ` quella di immaginare anche i possibili servizi, fornendo un modello pi`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
coordinato, e un'infrastruttura con molti provider: si denisce un accordo/negoziazione fra i
\end{flushleft}


\begin{flushleft}
fornitori dei servizi e i clienti, per poter per esempio stabilire la QoS, e quindi si fornisce il
\end{flushleft}


\begin{flushleft}
servizio con i parametri indicati
\end{flushleft}





12





\begin{flushleft}
\newpage
e limitandoci quindi ad un'ipotesi di localit`, il progetto risulta pi` facilmente
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
realizzabile.
\end{flushleft}





1.8





\begin{flushleft}
Indicatori dell'ecienza
\end{flushleft}





\begin{flushleft}
In generale, ci si limita alla complessit` temporale, TP (N ), dove P ` il numero
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di processori considerati: se ` pari ad 1, siamo in un ambiente sequenziale.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Un primo indicatore ` lo speed-up, che indica l'incremento di prestazioni se si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
introducessero P processori:
\end{flushleft}


\begin{flushleft}
SP (N ) =
\end{flushleft}





\begin{flushleft}
T1 (N )
\end{flushleft}


$>$1


\begin{flushleft}
TP (N )
\end{flushleft}





(1)





\begin{flushleft}
Tuttavia, bisogna sempre tener presente che non tutti i programmi si possono
\end{flushleft}


\begin{flushleft}
parallelizzare: ci` dipende se vi sono troppe dipendenze fra le sotto parti.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Un altro indicatore ` l'ecienza nell'uso delle risorse:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
SP (N )
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





(2)





\begin{flushleft}
T1 (N ) 1
\end{flushleft}


·


\begin{flushleft}
TP (N ) P
\end{flushleft}





(3)





\begin{flushleft}
EP (N ) =
\end{flushleft}


\begin{flushleft}
Ma quindi, ci` corrisponde a dire:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
EP (N ) =
\end{flushleft}





\begin{flushleft}
Possiamo quindi denire lo speed-up massimo:
\end{flushleft}


\begin{flushleft}
SP (N ) = P
\end{flushleft}





(4)





\begin{flushleft}
EP (N ) = 1
\end{flushleft}





(5)





\begin{flushleft}
E l'ecienza massima:
\end{flushleft}


\begin{flushleft}
Sotto queste condizioni si avrebbe che tutti i processori lavorano al massimo,
\end{flushleft}


\begin{flushleft}
ovvero non abbiamo processori idle che possono risultare inutili. Questi sono
\end{flushleft}


\begin{flushleft}
coecienti statistici, validi per tutto l'algoritmo. Quello che si pu` osservare `
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che la situazione ideale la si avrebbe se lo speed-up dipendesse in maniera lineare dal numero dei processori. Una soluzione ideale non interessante sarebbe
\end{flushleft}


\begin{flushleft}
se si distribuisse i compiti ai processi in maniera uguale (un programma totalmente parallelo!), raccogliendo solo alla ne il risultato. In realt`, i casi pi`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
interessanti sono quelli dove si presentano delle dipendenze, per cui necessariamente vi deve essere una parte sequenziale: questo caso presenta quindi una
\end{flushleft}


\begin{flushleft}
comunicazione intrinseca, indipendente dal deployment che si viene a realizzare.
\end{flushleft}


\begin{flushleft}
Si possono quindi studiare diversi casi basandosi sui fattori di interesse N e
\end{flushleft}


\begin{flushleft}
P . In particolare, si pu` denire come fattore di carico, o loading factor:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
N
\end{flushleft}


(6)


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
che denisce la complessit` come viene suddivisa su ogni nodo. Vi possono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
essere diversi casi:
\end{flushleft}


\begin{flushleft}
L=
\end{flushleft}





13





\begin{flushleft}
\newpage
$\bullet$ N uguale a P : su ogni processore viene posta una parte molto semplice
\end{flushleft}


\begin{flushleft}
del problema. Si dice ipotesi di identit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Dipendenza di N da P
\end{flushleft}


\begin{flushleft}
$\bullet$ Indipendenza, interessante al crescere di N
\end{flushleft}


\begin{flushleft}
La legge di Grosh stabilisce che la soluzione migliore risulta essere quella di lavorare sempre nel concentrato. . . Ma ci` non ` sempre possibile! Se per esempio
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vi sono risorse limitate? Oppure, oltre un certo valore di N , non si riesce pi`
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a lavorare nel concentrato, e la legge ` sicuramente inutile nel caso di vincoli,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tipo la presenza di risorse distribuite.
\end{flushleft}


\begin{flushleft}
La legge di Amdhal stabilisce che vi ` un limite alla possibile parallelize
\end{flushleft}


\begin{flushleft}
zazione, dato che ogni programma ` costituito da una parte parallela e una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
parte sequenziale, e quest'ultima limita lo speed-up: si ha quindi che non cresce
\end{flushleft}


\begin{flushleft}
linearmente, ma tende a un valore asintotico! Nella situazione migliore immaginabile, con le risorse correttamente allocate, si ha quindi che si avr` uno speeda
\end{flushleft}


\begin{flushleft}
up sso, mentre sar` l'ecienza a variare a seconda dell'architettura del sistema!
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Come calcolare quindi lo speed-up massimo? Si vuole avere il numero di
\end{flushleft}


\begin{flushleft}
processori tali che si abbia la minore complessit` del problema, realizzando un
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sistema fortemente caricato: si denite quindi l'heavily loaded limit:
\end{flushleft}


\begin{flushleft}
THL (N ) = infP (TP (N ))
\end{flushleft}





(7)





\begin{flushleft}
Infatti, si lavora bene caricando molto ogni processore, i quali quindi lavorano
\end{flushleft}


\begin{flushleft}
per tutto il tempo necessario: abbiamo quindi in questomodo un buon uso delle
\end{flushleft}


\begin{flushleft}
risorse.
\end{flushleft}


\begin{flushleft}
Tuttavia, per la legge di Amdhal, dobbiamo ricordare che vi ` anche una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
parte sequenziale in ogni programma. . . che ` proprio la parte di comunicazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fra i diversi processori! Al crescere del numero dei processori, si ha quindi
\end{flushleft}


\begin{flushleft}
che lo speed-up diminuisce, allontanandosi dal valore massimo; questo degrado
\end{flushleft}


\begin{flushleft}
delle prestazioni ` dovuto proprio al peso crescente della comunicazione fra i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
processori, che diventa fondamentale.
\end{flushleft}





1.9





\begin{flushleft}
Caso di studio: somma di N numeri
\end{flushleft}





\begin{flushleft}
Una possibile soluzione, imponendo la condizione d'identit`, ` quella di utilizzare
\end{flushleft}


\begin{flushleft}
a e
\end{flushleft}


\begin{flushleft}
un albero binario per fare la sommma: le radici sommano i numeri, che passano
\end{flushleft}


\begin{flushleft}
il risultato al padre, e cos` via. Supponendo quindi un albero con profondit` H,
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
possiamo osservare che N = 2H+1 e P = 2H+1 $-$ 1, per cui P ` simile a N . Si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ha che quindi:
\end{flushleft}


\begin{flushleft}
TP (N ) = O(H)
\end{flushleft}


\begin{flushleft}
= O(log2 (N ))
\end{flushleft}


\begin{flushleft}
= 2 · log2 (N )
\end{flushleft}


14





\begin{flushleft}
\newpage
Perch` 2? Perch` abbiamo 2 comunicazioni in ogni nodo. Possiamo quindi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
valutare l'ecienza di questa architettura:
\end{flushleft}


1


\begin{flushleft}
log2 (N )
\end{flushleft}





\begin{flushleft}
EP (N ) = O
\end{flushleft}





\begin{flushleft}
Ma quindi, al crescere di N, l'ecienza tende a 0! Per quanto riguarda lo speedup, si ha che non lavorano tutti i nodi, ovvero pi` si risale l'albero e meno i
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
processori lavorano (il processore radice deve attendere, ovvero tempo di idle,
\end{flushleft}


\begin{flushleft}
che tutti gli altri abbiano nito!). Se invece avessimo un usso di dati, i processori risulterebbero tutti sempre impegnati (potremmo risolvere un insieme di
\end{flushleft}


\begin{flushleft}
problemi).
\end{flushleft}


\begin{flushleft}
Come si possono quindi mantenere sempre impegnati i processori? Si deve
\end{flushleft}


\begin{flushleft}
incrementare il lavoro sul singolo processore, per cui:
\end{flushleft}


\begin{flushleft}
L=
\end{flushleft}





\begin{flushleft}
N
\end{flushleft}


$>$$>$ 1


\begin{flushleft}
P
\end{flushleft}





(8)





\begin{flushleft}
e quindi la complessit` deve essere superiore al numero dei processori: su ogni
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
nodo si ha quindi un certo numero di valori da sommare. Ci` si pu` ottenere
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
per esempio con un albero sso, ovvero un numero di processori ssi. Infatti:
\end{flushleft}


\begin{flushleft}
TP (N ) = O (L + log2 (P ))
\end{flushleft}


\begin{flushleft}
I due componenti rappresentano rispettivamente il tempo di computazione e
\end{flushleft}


\begin{flushleft}
quello di comunicazione.
\end{flushleft}


\begin{flushleft}
SP (N ) =
\end{flushleft}





\begin{flushleft}
T1 (N )
\end{flushleft}


\begin{flushleft}
TP (N )
\end{flushleft}





\begin{flushleft}
=O
\end{flushleft}


\begin{flushleft}
=O
\end{flushleft}





\begin{flushleft}
N
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}





\begin{flushleft}
N
\end{flushleft}


\begin{flushleft}
+ log2 (P )
\end{flushleft}





\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


+


1


\begin{flushleft}
N · log2 (P )
\end{flushleft}





\begin{flushleft}
Per cui, lo speed-up tende eettivamente a P
\end{flushleft}


\begin{flushleft}
SP (N )
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


1


1


\begin{flushleft}
=O
\end{flushleft}


+


\begin{flushleft}
1 N · log2 (P )
\end{flushleft}





\begin{flushleft}
EP (N ) =
\end{flushleft}





\begin{flushleft}
E l'ecienza tende ad 1. Quindi, caricando al massimo i processori ed usandoli
\end{flushleft}


\begin{flushleft}
correttamente, si ottiene speed-up ed ecienza massimi.
\end{flushleft}





1.10





\begin{flushleft}
Considerare l'I/O
\end{flushleft}





\begin{flushleft}
In questi indicatori si ` tuttavia lasciato da parte il problema dell'I/O, che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
spesos ` il vero collo di bottiglia in diverse architetture. Inoltre, vi son diversi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


15





\begin{flushleft}
\newpage
fattori che possono inuenzare l'ecienza e lo speed-up dell'architettura, come
\end{flushleft}


\begin{flushleft}
il deployment reale. Si possono quindi estendere gli indicatori considerando
\end{flushleft}


\begin{flushleft}
l'eetto generale dell'overhead, T0 (N ), che rappresenta le risorse e il tempo
\end{flushleft}


\begin{flushleft}
realmente utilizzato per la comunicazione (caso ideale di deployment):
\end{flushleft}


\begin{flushleft}
T0 (N ) = |T1 (N ) $-$ P · TP (N )|
\end{flushleft}





(9)





\begin{flushleft}
Ma quindi, si ha che:
\end{flushleft}


\begin{flushleft}
T0 (N ) + T1 (N )
\end{flushleft}


\begin{flushleft}
P
\end{flushleft}


\begin{flushleft}
E si ha che che lo speed-up risulta essere:
\end{flushleft}


\begin{flushleft}
TP (N ) =
\end{flushleft}





\begin{flushleft}
SP (N ) =
\end{flushleft}





\begin{flushleft}
P · T1 (N )
\end{flushleft}


\begin{flushleft}
T0 (N ) + T1 (N )
\end{flushleft}





(10)





(11)





\begin{flushleft}
E che l'ecienza risulta essere:
\end{flushleft}


\begin{flushleft}
EP (N ) =
\end{flushleft}





1


1+





\begin{flushleft}
T0 (N )
\end{flushleft}


\begin{flushleft}
T1 (N )
\end{flushleft}





(12)





\begin{flushleft}
Per cui l'ecienza non sembra dipendere dal numero dei processori. . . in realt`,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
` proprio T0 (N ) a dipendere dal numero dei processori : l'overhead dipende dal
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
numero di processori impegnati.
\end{flushleft}


\begin{flushleft}
Supponiamo quindi di avere come obiettivo per l'architettura di mantenere
\end{flushleft}


\begin{flushleft}
costante l'ecienza:
\end{flushleft}


1





\begin{flushleft}
E=
\end{flushleft}


1+


\begin{flushleft}
E+E·
\end{flushleft}





\begin{flushleft}
T0 (N )
\end{flushleft}


\begin{flushleft}
T1 (N )
\end{flushleft}





\begin{flushleft}
T0 (N )
\end{flushleft}


=1


\begin{flushleft}
T1 (N )
\end{flushleft}


\begin{flushleft}
1$-$E
\end{flushleft}


\begin{flushleft}
T0 (N )
\end{flushleft}


=


\begin{flushleft}
T1 (N )
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}


\begin{flushleft}
(1 $-$ E)
\end{flushleft}


\begin{flushleft}
T0 (N ) =
\end{flushleft}


\begin{flushleft}
· T1 (N )
\end{flushleft}


\begin{flushleft}
E
\end{flushleft}


\begin{flushleft}
T0 (N ) = K · T1 (N )
\end{flushleft}





\begin{flushleft}
Se K fosse veramente una costante, saremmo in isoecienza. Un sistema isoeciente indica che, se manteniamo costante la complessit` e aumentiamo il
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
numero dei processori, l'ecienza non varia. Il valore di K quindi determina se
\end{flushleft}


\begin{flushleft}
il sistema ha un buon comportamento. In particolare:
\end{flushleft}


\begin{flushleft}
$\bullet$ K piccolo: il sistema ` altamente scalabile. Al crescere di K quindi la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
scalabilit` del sistema decresce
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Se non ` costante ma funzione dei processori, allora il sistema non `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
scalabile.
\end{flushleft}


\begin{flushleft}
I sistemi reali sono scarsamente scalabili.
\end{flushleft}


16





\newpage
1.11





\begin{flushleft}
Conclusioni
\end{flushleft}





\begin{flushleft}
Un progetto deve essere valutato attentamente, per cercare di dimensionarlo
\end{flushleft}


\begin{flushleft}
in maniera corretta: nel caso di una macchina singola l'heavily loaded limit `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un ragionamento corretto, ma bisogna ricordarsi che si deve sempre cercare di
\end{flushleft}


\begin{flushleft}
parallelizzare (non utilizzare la legge di Grosh). Per esempio, qual'` il numero
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ideale di processi da realizzare? Si pu` ben pensare che avere meno processi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
di processori risulti in processori che non lavorano, e quindi in un sistema non
\end{flushleft}


\begin{flushleft}
eciente: il limite superiore quindi ` che il numero dei processi sia lo stesso
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
del numero dei processori. Un processore ` idle quando comunica, quindi si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dovrebbe limitare la comunicazione, e quindi troppi processi comunicano troppo.
\end{flushleft}


\begin{flushleft}
In realt`, statisticamente si ha che un processore che lavora con 20 processi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
presenta ancora lo stato di idle: un centinaio di processi per processore ` un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
numero adeguato.
\end{flushleft}





2





\begin{flushleft}
Modelli per la replicazione
\end{flushleft}





\begin{flushleft}
Un obiettivo per poter fornire della qualit` di servizio ` ovviamente quello di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
poter orire un servizio continuativo, stabile: se il servizio non viene erogato,
\end{flushleft}


\begin{flushleft}
non si ` remunerati (anzi, in determinati ambiti ` proprio un danno economico
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
perch` si possono presentare anche delle richieste di risarcimento; in certi ambiti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si parla anche di rischi umani). L'obiettivo ` quindi quello di realizzare un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sistema fault tolerant, resistente ai guasti. Sono invarianti che devono essere
\end{flushleft}


\begin{flushleft}
comunque garantiti.
\end{flushleft}





2.1





\begin{flushleft}
Denire i comportamenti errati del sistema: cause ed
\end{flushleft}


\begin{flushleft}
eetti
\end{flushleft}





\begin{flushleft}
I possibili guasti si possono catalogare in maniera logica:
\end{flushleft}


\begin{flushleft}
$\bullet$ Si parla di failure quando il sistema presenta un comportamento diverso
\end{flushleft}


\begin{flushleft}
dagli invarianti di sistema previsti: ci` ` dovuto a un sistema progettato
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
male. Il failure ` l'eetto visibile, riscontrabile dall'utente.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Un errore ` invece il difetto che genera un failure del sistema, la causa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
concreta che ha portato il sistema in uno stato non corretto.
\end{flushleft}


\begin{flushleft}
$\bullet$ Un fault inne ` proprio il comportamento che si ` venuto a vericare che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ha portato il sistema a generare un failure: corrisponde quindi proprio alla
\end{flushleft}


\begin{flushleft}
causa a monte.
\end{flushleft}


\begin{flushleft}
I fault si possono classicare a seconda di quanto si ripetono:
\end{flushleft}


`


\begin{flushleft}
$\bullet$ E permanente se si ripresenta in maniera periodica: sono quindi facili
\end{flushleft}


\begin{flushleft}
da individuare, e facili da risolvere. Si parla di Bohrbug per errori che
\end{flushleft}


\begin{flushleft}
si ripetono facilmente, riproducibili, che si possono quindi osservare e
\end{flushleft}


\begin{flushleft}
correggere facilmente.
\end{flushleft}





17





\begin{flushleft}
\newpage
$\bullet$ Se invece ` transiente, sono pi` dicili da notare. Si parla di errori di tipo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Eisenbug, e sono molto dicili da eliminare.
\end{flushleft}





2.2





\begin{flushleft}
Ipotizzare il guasto
\end{flushleft}





\begin{flushleft}
Esistono diversi parametri per poter giudicare la disponibilit` di un servizio/sistema.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Un sistema ` fault tolerant se garantisce la dependability, ovvero si ha condenza
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per qualunque aspetto progettuale. Ci` comporta che il sistema debba garantire:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ Reliability: deve essere adabile, in ogni modo il sistema si comporta
\end{flushleft}


`


\begin{flushleft}
correttamente rispetto agli invarianti che sono stati imposti. E quindi un
\end{flushleft}


\begin{flushleft}
sistema corretto.
\end{flushleft}


\begin{flushleft}
$\bullet$ Availability: indica la disponibilit` nel tempo del sistema. La risposta da
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
parte del sistema deve arrivare entro una certa deadline prestabilita.
\end{flushleft}


\begin{flushleft}
Per poter garantire la disponibilit` del sistema a fronte di guasti, si devono fare
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
delle ipotesi sul guasto. In generale, la procedura di ripristino consiste infatti
\end{flushleft}


\begin{flushleft}
prima nell'identicazione del tipo di guasto, e ina base a ci` si cerca di riattivare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
con la corretta procedura il servizio (fase di recovery).
\end{flushleft}


\begin{flushleft}
In generale, si utilizza l'ipotesi delfault singolo, ovvero nel sistema si pu`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
presentare un singolo guasto: solo quando il sistema torna operativo, si ha che
\end{flushleft}


\begin{flushleft}
si potrebbe presentare un ulteriore fault. Quest'ipotesi ` necessaria per poter
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
semplicare il trattamento del recovery. Per poter denire ci`, ` necessario
\end{flushleft}


\begin{flushleft}
o e
\end{flushleft}


\begin{flushleft}
conoscere:
\end{flushleft}


\begin{flushleft}
$\bullet$ Il Time To Repair, TTR, che ` il tempo necessario per accorgersi e per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
poter correggereil guasto
\end{flushleft}


\begin{flushleft}
$\bullet$ Il Time Between Failure, ovvero il tempo che intercorre fra due failure
\end{flushleft}


\begin{flushleft}
(oppure la media)
\end{flushleft}


\begin{flushleft}
L'obiettivo ` quindi che il TTR sia inferiore in maniera stretta al (M)TBF.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Mediante l'ipotesi del guasto singolo, si pu` osservare che se abbiamo pi` copie
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
in grado di fornire il servizio, si pu`specicare il numero di fault tollerabili e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
identicabili. Se avessimo solo due copie, non possiamo tollerare un guasto,
\end{flushleft}


\begin{flushleft}
ma possiamo identicarne uno. Con gi` 3 copie, un guasto si pu` tollerare,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
perch` comunque restano due macchine con cui identicare i guasti successivi:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si riescono cos` ad identicare no 2 guasti. La generalizzazione ` che se si
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
hanno 3t copie, si tollerano massimo t guasti.3 Si possono quindi ridenire le
\end{flushleft}


\begin{flushleft}
propriet` precedenti in base a questi valori:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ La reliability ` il valor medio sulla disponibilit`/indisponibilit` della risore
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sa considerata
\end{flushleft}


\begin{flushleft}
3 Non
\end{flushleft}





\begin{flushleft}
si fanno ipotesi sul tipo di guasto, ma solo sul fatto che ` singolo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





18





\begin{flushleft}
\newpage
$\bullet$ L'availability si pu` esprimere come la percentuale utile di lavoro che il
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sistema riesce ad orire:
\end{flushleft}


\begin{flushleft}
A=
\end{flushleft}





\begin{flushleft}
M T BF
\end{flushleft}


\begin{flushleft}
M T BF + M T T R
\end{flushleft}





(13)





\begin{flushleft}
In particolare, si possono distinguere i casi di lettura e scrittua: infatti, la lettura
\end{flushleft}


\begin{flushleft}
non modica lo stato, per cui si pu` fornire un servizio di lettura anche se vi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sono diverse copie non funzionanti. Viceversa, per garantire uno stato coeso fra
\end{flushleft}


\begin{flushleft}
tutte le copie, la scrittura richiede che tutte siano disponibili.
\end{flushleft}


\begin{flushleft}
La reliability si pu` anche vedere come la probabilit` che un servizio sia
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
disponibile per un certo intervallo di tempo (a 0 deve corrispondere con l'availability).
\end{flushleft}


\begin{flushleft}
Esistono altre propriet` fondamentali, come la correttezza e la vitalit` : la
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
prima denisce che comunque sia, il risultato fornito dal sistema sar` corretto,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
la seconda invece stabilisce che comunque si raggiunger` l'obiettivo. L'ideale
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sarebbe disporre di entrambe le propriet`, cos` da poter mascherare i fault: si
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
pu` ottenere mediante oppurtune tecniche di replicazione spaziali e/o temporali:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ Se si hanno diverse macchine, che eseguono ognuna un algoritmo diverso
\end{flushleft}


\begin{flushleft}
ma forniscono lo stesso risultato, garantiamo la massima correttezza
\end{flushleft}


\begin{flushleft}
$\bullet$ Se si hanno invece diverse macchine ognuna con un compito specico, si
\end{flushleft}


\begin{flushleft}
ottimizzalo throughput del sistema
\end{flushleft}


\begin{flushleft}
Una singola macchina non basta per identicare e correggereun guasto! La
\end{flushleft}


\begin{flushleft}
replicazione ` fondamentale, almeno per fare monitoring (utilizzo di cluster per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fare il controllo di una risorsa): si potrebbero utilizzare delle speciche parti
\end{flushleft}


\begin{flushleft}
per controllare e correggere l'architettura, ma ` necessario rispettare sempre il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
principio della minima intrusione: il rischio sarebbe che troppe risorse sono
\end{flushleft}


\begin{flushleft}
allocate solo per vericare che il sistema funzioni correttamente, riducendone l'
\end{flushleft}


\begin{flushleft}
ecienza! La replicazione ` un costo che si va ad aggiungere al sistema: ma in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
generale si tratta di un costo sso, a fronte di possibili costi molto peggiori in
\end{flushleft}


\begin{flushleft}
caso di fallimento del sistema!
\end{flushleft}





2.3





\begin{flushleft}
Possibili guasti
\end{flushleft}





\begin{flushleft}
I guasti si possono anche classicare in base alla loro riconoscibilit` da un sistema
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(processore esterno):
\end{flushleft}


\begin{flushleft}
$\bullet$ Fail-stop: un processore si ferma perch` non rispetta un invariante, e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
questo viene identicato dagli altri processori
\end{flushleft}


\begin{flushleft}
$\bullet$ Fail-safe: come il precedente, tranne che gli altri processori non se ne
\end{flushleft}


\begin{flushleft}
accorgono: in questo caso quindi non ` identicato, ma potrebbe essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tollerato (dipende dall'architettura stessa).
\end{flushleft}





19





\begin{flushleft}
\newpage
$\bullet$ Fallimento di tipo bizantino: il processore termina presentando per` como
\end{flushleft}


\begin{flushleft}
portamenti assolutamente casuali.
\end{flushleft}


\begin{flushleft}
Nelle reti di calcolatori si possono poi presentare ulteriori generi di guasti, dovuti
\end{flushleft}


\begin{flushleft}
alla mancata totale ricezione/trasmissione di messaggi(send/receive omissions),
\end{flushleft}


\begin{flushleft}
oppure anche al fatto che un processore si blocca. Le reti poi possono aggiungere
\end{flushleft}


\begin{flushleft}
problemi (se un router per esempio non rispone pi`, si potrebbe avere che la
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
rete risulta partizionata in due sottoreti, incapaci di comunicare fra di loro).
\end{flushleft}





2.4





\begin{flushleft}
Architetture per garantire la fault-tolerance
\end{flushleft}





\begin{flushleft}
Nel corso del tempo sono state pensate e realizzate diverse tipologie di architetture in grado di fornire questo genere di servizio.
\end{flushleft}


\begin{flushleft}
Una prima ipotesi operativa ` quella di realizzare un sistema con vera e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
propria replicazione hardware, per cui si hanno due possibilit`:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
1. O si realizza un'architettura in cui vi ` una sola macchina a lavorare,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mentre un'altra ne controlla il corretto funzionamento, per cui interviene
\end{flushleft}


\begin{flushleft}
solo in caso di guasto. Per esempio, per avere la correttezza si potrebbe
\end{flushleft}


\begin{flushleft}
avere che a una determinata richiesta rispondano tutte le macchine, ma
\end{flushleft}


\begin{flushleft}
la risposta viene controllata prima di essere fornita.
\end{flushleft}


\begin{flushleft}
2. Oppure si realizza un sistema con cluster, dove si aggiunge una logica di
\end{flushleft}


\begin{flushleft}
controllo che ` in grado di stabilire se una risorsa ` disponibile o meno,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e quindi ` in grado di escluderla dal sistema. Al crescere delle risorse
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
aumenta la probabilit` di guasti, quindi si devono utilizzare algoritmi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ecienti per identicarli correttamente: si vuole un metalivello eciente!
\end{flushleft}


\begin{flushleft}
Un'ipotesi spesso comune ` quella della memoria stabile 4 : si vuole realizzare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un sistema per cui la memoria persistente dell'architettura non fallisca mai
\end{flushleft}


\begin{flushleft}
(sempre disponibile, sempre corretta). Una possibilit` per realizzare ci` consiste
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
nell'utilizzare due dischi, e fare in modo che ogni blocco sia replicato in maniera
\end{flushleft}


\begin{flushleft}
uguale su entrambi, con probabilit` d'errore congiunta nulla (caso dell'errore
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
singolo). Si ha che quindi i singoli blocchi possono indicare la presenza di errori
\end{flushleft}


\begin{flushleft}
o meno (omissions), con l'uso di appositi codici di controllo. Mediante questi
\end{flushleft}


\begin{flushleft}
indicatori infatti si ha il controllo se le copie sono uguali o meno:
\end{flushleft}


\begin{flushleft}
1. Sulla seconda copia potrei avere dei valori non corretti
\end{flushleft}


\begin{flushleft}
2. Sulla seconda copia potrei avere dei valori corretti ma diversi dalla prima
\end{flushleft}


\begin{flushleft}
copia
\end{flushleft}


\begin{flushleft}
4 Si potrebbe realizzare mediante la tecnologia RAID, Redundant Array of Inexpensive
\end{flushleft}


\begin{flushleft}
Disks; ` un sistema a basso costo, inizialmente realizzato per poter velocizzare la lettura e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi per poter fornire un semplice supporto alla replicazione. Le operazioni sui dischi son
\end{flushleft}


\begin{flushleft}
quindi coordinate. In realt`, quando un disco si guastava, essendoci problemi nel sistema di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
gestione non si aveva mai una replicazione veramente buona
\end{flushleft}





20





\begin{flushleft}
\newpage
Il secondo caso in real` ` il peggiore, dovuto magari a problemi di aggiornamenae
\end{flushleft}


\begin{flushleft}
to sulla seconda copia5 : clienti che accedono alla seconda copia prima della fase
\end{flushleft}


\begin{flushleft}
di recovery non potrebbero accorgersi che il dato ` stale. Ogni operazione deve
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
procedere su tutte le copie quindi per poter garantire risultati corretti! Tale
\end{flushleft}


\begin{flushleft}
sistema ` sicuramente costoso e dicile da realizzare.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Un'ulteriore aspetto riguarda un sistema software per fare il monitoraggio
\end{flushleft}


\begin{flushleft}
delle risorse, necessario e conveniente da mettere in parallelo al sistema di recovery hardware: si tratta quindi di progettare degli appositi protocolli e sistemi in
\end{flushleft}


\begin{flushleft}
grado di permettere all'applicazione di ripartire con il minimo costo e nel minimo
\end{flushleft}


\begin{flushleft}
tempo. Il problema di ci` ` che un sistema software del genere sfrutta le stesse
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
risorse dell'applicazione (CPU, RAm,. . . ), riducendone l'ecienza: si deve quindi progettare il tutto rispettando il principio della minima intrusione, limitando
\end{flushleft}


\begin{flushleft}
il pi` possibile quindi le risorse allocate al metalivello di monitoring/supporto
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
dell'applicazione. La replicazione presenta dei costi elevati in termine di realizzazione, ma anche di progettazione ed uso delle risorse, quindi deve essere
\end{flushleft}


\begin{flushleft}
attentamente studiata. Ipotizzare guasti singoli semplica la realizzazione dei
\end{flushleft}


\begin{flushleft}
protocolli, per esempio.
\end{flushleft}


\begin{flushleft}
Una possibile realizzazione ` un sistema tandem, cio` in cui tutto ` raddoppie
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ato: l'idea ` quella di realizzare un sistema fail-safe, per cui una CPU identica
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'errore. Ovviamente, un sistema del genere ` complesso e costoso.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





2.5





\begin{flushleft}
Copie calde e copie fredde
\end{flushleft}





\begin{flushleft}
Vi sono due possibili modelli per la replicazione, e dipendono dal comportamento
\end{flushleft}


\begin{flushleft}
delle copie:
\end{flushleft}


\begin{flushleft}
$\bullet$ Copie fredde: vi ` un'unica copia attiva che funziona, pi` diverse copie
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
dormienti. Deve essere quindi presente anche un manager del sistema, in
\end{flushleft}


\begin{flushleft}
grado di attivare in caso di necessit` una delle copie dormienti (ovvero se
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
la copia principale presenta un fault e smette di lavorare correttamente).
\end{flushleft}


\begin{flushleft}
Il manager si preoccupa quindi di attivare una nuova istanza dell'oggetto
\end{flushleft}


\begin{flushleft}
solo quando la precedente non funziona. Questo sistema presenta un alto
\end{flushleft}


\begin{flushleft}
tempo di congurazione, e ha il problema che lo stato non ` direttamente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
salvato sugli oggetti in standby (si dovrebbe recuperare in un qualche altro
\end{flushleft}


\begin{flushleft}
modo. . . ).
\end{flushleft}


\begin{flushleft}
$\bullet$ Copie calde: in questo caso vi sono diversi oggetti pronti, pronti a sostituire una copia che non funziona: l'idea ` che in questo caso vi sia invece
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un protocollo di ruolo, in grado di indicare ad ogni copia che comportamento deve assumere (` la principale o meno): infatti, la copia principale
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
` attiva, ovvero in grado di salvare lo stato, mentre le altre son passive,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che vengono sempre aggiornate ad ogni modica sulla copia attiva. Se
\end{flushleft}


\begin{flushleft}
5 Osservazione: ` sicuramente conveniente un'indicazione di tempo per la scrittura, in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
maniera tale da poter aggiornare tutte le copie al dato pi` recente eettivamente presente
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}





21





\begin{flushleft}
\newpage
fallissero anche tutte le copie calde, si pu` ripiegare su un sistema a copie
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
fredde, in grado di inizializzare una nuova copia.
\end{flushleft}





2.6





\begin{flushleft}
Gestione delle risorse
\end{flushleft}





\begin{flushleft}
La replicazione delle risorse ` necessaria per un sistema distribuito, perch` si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
introduce replicazione, e si pu` garantire la fruizione del servizio. In un progetto
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
quindi si deve considerare come allocare le risorse sui vari nodi, e con che grado di replicazione: risorse replicate signica quindi che si hanno copie multiple
\end{flushleft}


\begin{flushleft}
delle risorse su nodi diversi! Maggiore ` l'importanza della risorsa, maggiore
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
deve essere il suo grado di replicazione.
\end{flushleft}


\begin{flushleft}
Si possono ipotizzare sempre due modelli base:
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello passivo: una sola risorsa lavora, e le altre sono in attesa pronte
\end{flushleft}


\begin{flushleft}
a sostituirla in caso di failure. Il modello generale ` quindi quello di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un master con una serie di slave, organizzati in maniera gerarchica. Se
\end{flushleft}


\begin{flushleft}
il numero di partecipanti ` limitato non ` costoso, ed ` il modello pi`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
facile da implementare (ha un protocollo chiaro e semplice). Il grado di
\end{flushleft}


\begin{flushleft}
replicazione ` quindi indicato dal numero di copie passive disponibili.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello attivo: tutte le copie eseguono assieme per ottenere il risultato
\end{flushleft}


\begin{flushleft}
desiderato. Sono quindi tutte e attive, ed ` necessario predisporre una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
parte di controllo abbastanza complessa, quindi la modellazione e l'implementazione sono pi` costose (tutte le copie devono avere l'input, e tutti
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
gli output devono essere confrontati).
\end{flushleft}


\begin{flushleft}
In entrambi i modelli non si lavora in maniera sequenziale, ma parallela: le
\end{flushleft}


\begin{flushleft}
copie possono comunque svolgere anche altri compiti, eseguire pi` operazioni
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
contemporaneamente!
\end{flushleft}


\begin{flushleft}
Nel primo modello si deve pensare ad un sistema per tenere aggiornate le
\end{flushleft}


\begin{flushleft}
copie fredde: si utilizzano quindi dei checkpoint, per cui lo stato viene trasferito
\end{flushleft}


\begin{flushleft}
e replicato sulle copie fredde. . . ma quando farlo?
\end{flushleft}


\begin{flushleft}
$\bullet$ Se lo si fa prima di fornire la risposta al cliente, si garantisce un'alta
\end{flushleft}


\begin{flushleft}
ecienza a scapito della correttezza (se gli slave presentano un guasto,
\end{flushleft}


\begin{flushleft}
non saranno aggiornati correttamente)
\end{flushleft}


\begin{flushleft}
$\bullet$ Se invece si attende che tutte le copie garantiscano di aver ricevuto l'aggiornamento prima di spedire la risposta, il sistema ` corretto, ma la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
risposta avr` un tempo molto lungo.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
L'aggiornamento pu` essere eseguito periodicamente (time-driven) oppure ad
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ogni volta che si presenta un nuovo evento (event driven). Quest'ultima politica
\end{flushleft}


\begin{flushleft}
risulta essere maggiormente dinamica e complessa da realizzare. Per esempio,
\end{flushleft}





22





\begin{flushleft}
\newpage
un evento potrebbe essere scatenato dall'inizio del servizio della richiesta (estrazione dalla coda delle richieste), e terminare alla ne per poter fare il checkpoint.
\end{flushleft}


\begin{flushleft}
Le operazioni poi possono correlate o meno, e quindi anche il checkpoint
\end{flushleft}


\begin{flushleft}
potrebbe essere correlato! In questo caso, servono delle informazioni dall'utente
\end{flushleft}


\begin{flushleft}
su quando conviene fare il checkpoint (tipicamente, si attende che si giunga ad
\end{flushleft}


\begin{flushleft}
uno stato stabile e poi lo si esegue).
\end{flushleft}


\begin{flushleft}
Serve quindi la trasparenza? Il cliente deve sapere chi contattare se il master
\end{flushleft}


\begin{flushleft}
non ` raggiungibile, quindi no! Deve avere idea che non sta interagendo con la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
copia principale, per poter sfruttare le risorse per potersi collegare alla risorsa
\end{flushleft}


\begin{flushleft}
secondaria mediante un opportuno sistema di nomi. Inoltre, a seconda della
\end{flushleft}


\begin{flushleft}
complessit` del master, potrebbe essere conveniente farlo ritornare direttamente
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
come master, invece che come slave. Si pu` comunque realizzare cos` una sorta
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
di fault-transparency, per cui dall'esterno la risorsa sembra reggere diversi fault
\end{flushleft}


\begin{flushleft}
e riesce a fornire un servizio con continuit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Infatti, sarebbe meglio che all'esterno non si sapesse il grado di replicazione
\end{flushleft}


\begin{flushleft}
di una risorsa, perch` altrimenti sarebbe una decisione distribuita mediante il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
deployment: ` in realt` il middleware ad accorgersi e a fare da supporto, cone
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
tattando la nuova copia: per il client ` tutto trasparente!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Nel caso di copie attive, il client come le deve conoscere? Se le conosce in
\end{flushleft}


\begin{flushleft}
maniera esplicita, non abbiamo trasparenza e fornisce visibilit` alla replicazione:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
viene utilizzato solo in appositi sistemi ad-hoc. In realt`, vi ` sempre un sistema
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
implicito a garantire la comunicazione fra il client e le copie attive. E quindi necessario pensare ad un frontend che si preoccupi di smistare opportunatamente le
\end{flushleft}


\begin{flushleft}
richieste: potrebbe essere statico (in grado quindi di smistare qualunque richiesta) oppure dinamico (specializzato per una determinata richiesta). Ma nel caso
\end{flushleft}


\begin{flushleft}
di oggetto singolo, questo diventa un collo di bottiglia, perch` se viene a mancare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'architettura non si regge pi` in piedi! Deve garantire un'alta adabilit`.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Il secondo modello ` realizzabile facendo in modo che ogni client diventi il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
gestore di quel tipo di richiesta, ma ci` necessita che le varie copie si mettano
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
d'accordo: vi ` un problema di sincronismo. Si pu` risolvere in diversi modi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
(sfruttando una politica ad anello, utilizzando un token univoco, in modo da
\end{flushleft}


\begin{flushleft}
simulare cos` un gestore unico fra tutte le copie attive), ma utilizzando delle
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
approssimazioni per la sincronia, si possono ottenere dei protocolli pi` semplici
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
da implementare (si possono presentare dei problemi dal punto di vista semantico, ovvero come devono essere ordinate le operazioni), risultando meno costose
\end{flushleft}


\begin{flushleft}
e pi` veloci. Infatti, in caso di richieste indipendenti fra di loro, la perfetta
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
sincronia ` soltanto un costo aggiuntivo! La sincronicit` deve quindi essere stue
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
diata a seconda del tipo di operazioni che si devono svolgere (letture sincrone,
\end{flushleft}


\begin{flushleft}
scritture sequenziali). Per altre operazioni, si deve tener conto dell'architettura
\end{flushleft}


\begin{flushleft}
e del signicato dell'operazione: si potrebbero eseguire in maniera indipendente,
\end{flushleft}


\begin{flushleft}
e procedere quindi successivamente ad una riconciliazione fra le copie per avere
\end{flushleft}


`


\begin{flushleft}
uno stato univoco coeso. E importante per` nel caso di copie attive che l'ago
\end{flushleft}


23





\begin{flushleft}
\newpage
giornamento delle copie preceda la consegna del risultato al cliente.
\end{flushleft}


`


\begin{flushleft}
E quindi necessario pensare ad un gestore delle copie attive, in grado di escludere correttamente le copie non funzionanti (altrimenti si avrebbero tempi
\end{flushleft}


\begin{flushleft}
di attesa altissimi per avere conferma degli aggiornamenti; se un'operazione si
\end{flushleft}


\begin{flushleft}
guasta, deve esserci comunque un modo per poter fornire una risposta all'esterno) e quindi di poter essere in grado di coordinare le diverse copie attive. Per
\end{flushleft}


\begin{flushleft}
esempio, invece che utilizzare un sistema per cui tutte le copie garantiscono la
\end{flushleft}


\begin{flushleft}
conferma dell'azione, si potrebbe utilizzare una forma di voting: solo la maggioranza delle copie in concordanza fra di loro proseguono l'esecuzione, mentre le
\end{flushleft}


\begin{flushleft}
altre dovranno essere sospese e si dovr` procedere con il recovery (identicazione
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e recupero dal gestore o da chi altro: dovr` essere deciso in fase progettuale).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Questo protocollo sgravia la risposta verso l'esterno, che pu` essere fornita pi`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


`


\begin{flushleft}
velocemente! E evidente la necessit` di un gestore per il monitoraggio, controla
\end{flushleft}


\begin{flushleft}
lo delle copie. In generale, in un sistema reale, il numero di copie ` limitato:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
studiando opportunatamente il protocollo si riduce l'overhead al minimo.
\end{flushleft}





2.7





\begin{flushleft}
Modelli per la replicazione, copie attive
\end{flushleft}





\begin{flushleft}
L'ipotesi ` che vi ` un insieme di copie che devono produrre un risultato per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un insieme di clienti. Si deve quindi pensare a delle opportune fasi di coordinamento sia prima che dopo l'esecuzione, per poter organizzare le copie e
\end{flushleft}


\begin{flushleft}
fornire il risultato deciso. Si possono quindi pensare modelli in cui le copie lavorano s` in maniera indipendente, ma all'occorrenza sarebbero in grado di fare
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
da supporto a copie non funzionanti, ottenendo cos` un bilanciamento del carico.
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
Nel caso delle copie attive, vi sono 5 passaggi che si devono fare in ordine:
\end{flushleft}


\begin{flushleft}
1. All'arrivo di una richiesta, come deve essere smistata? Vi sono due possibilit`: o arriva ad un'unica copia che poi deve fornirla anche alle altre,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
oppure viene mandata dal client direttamente a tutti. Per avere maggiore
\end{flushleft}


\begin{flushleft}
trasparenza, ` ovviamente preferibile il primo modello. La copia quindi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pu` avere un comportamento dinamico o statico.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
2. Vi ` poi la fase di coordinamento fra le copie: dipende nuovamente dale
\end{flushleft}


\begin{flushleft}
l'architettura che si vuole realizzare. Si potrebbe avere un unico master
\end{flushleft}


\begin{flushleft}
gestore, oppure tutte le copie possono eseguire o in maniera paritaria o
\end{flushleft}


\begin{flushleft}
sono pesate a seconda della loro importanza. Questa fase pu` servire per
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
bilanciare correttamente il carico fra le varie copie attive.
\end{flushleft}


\begin{flushleft}
3. Quindi vi ` la vera esecuzione. In generale tutte le copie devono eseguire,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ma non devono farlo in contemporanea. Tutte hanno stato, e devono
\end{flushleft}


\begin{flushleft}
fornire un risultato. Per certi servizi vi potrebbe essere una copia dedicata
\end{flushleft}


\begin{flushleft}
che pu` fornire subito la risposta.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
4. Seconda fase di coordinamento: il master (oppure le copie con un sistema
\end{flushleft}


\begin{flushleft}
di voting) determina il risultato nale basandosi sulle risposte ottenute
\end{flushleft}





24





\begin{flushleft}
\newpage
da tutte le copie. Questa ` anche la fase in cui si possono individuare i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
guasti. Questa fase pu` essere utile nel caso si fossero ricevute pi` richieste
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
correlate fra di loro, e quindi si potrebbe evidenziare un ordine non corretto
\end{flushleft}


\begin{flushleft}
d'esecuzione. Ci` per` non ` sempre possibile, quindi bisogna pensare alla
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
prima fase di coordinazione mediante l'uso di un'operazione atomica, cos`
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
da evitare un eventuale undo. In base quindi all'ordine delle richieste, le
\end{flushleft}


\begin{flushleft}
varie copie sanno come eseguire.
\end{flushleft}


\begin{flushleft}
5. Presentazione del risultato al cliente, che deve essere univoco.
\end{flushleft}


\begin{flushleft}
Il protocollo ` molto pi` complesso di quello a master/server, tuttavia per grae
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
di di replicazione limitati, ovvero con poche copie e un protocollo denito in
\end{flushleft}


\begin{flushleft}
maniera eciente si ha un tempo di risposta piccolo.
\end{flushleft}


\begin{flushleft}
Un'architettura basata su master/slave (copie passive) riduce di moltoi costi,
\end{flushleft}


\begin{flushleft}
visto che vi ` un'unica macchina a lavorare: produce il risultato e si preoccupa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di fare l'operazione di checkpoint su tutte le altre copie, e quindi lo fornisce al
\end{flushleft}


\begin{flushleft}
cliente. La gestione ` maggiormente semplicata.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





2.8





\begin{flushleft}
Politiche di aggiornamento
\end{flushleft}





\begin{flushleft}
Esistono diverse possibilit` per eettuare l'aggiornamento delle copie. Vi potrebbe
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
essere una copia primaria che si preoccupa di aggiornare le altre, oppure tutte
\end{flushleft}


\begin{flushleft}
le copie possono assumere questo compito. Si deve poi decidere se privilegiare
\end{flushleft}


\begin{flushleft}
la correttezza (situazione eager o pessimista, si prevede di aggiornare tutte le
\end{flushleft}


\begin{flushleft}
copie prima di fornire la risposta al cliente, quindi a scapito della prontezza della risposta), oppure il tempo di risposta (situazione lazy o ottimista, aggiorno
\end{flushleft}


\begin{flushleft}
prima il client e poi le altre copie).
\end{flushleft}


\begin{flushleft}
$\bullet$ Copia primaria eager : una copia esegue, si preoccupa di aggiornare tutte
\end{flushleft}


\begin{flushleft}
le altre copie, e quindi fornisce il risultato al cliente. Esegue quindi
\end{flushleft}


\begin{flushleft}
un'operazione alla volta
\end{flushleft}


\begin{flushleft}
$\bullet$ Copia primaria lazy: aggiorna prima il cliente poi le altre copie. Pu`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


`


\begin{flushleft}
quindi eseguire pi` operazioni alla volta. E compito del gestore controllare
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
gli aggiornamenti e vericare che siano stati recepiti da tutte le copie in
\end{flushleft}


\begin{flushleft}
maniera corretta, coordinandole.
\end{flushleft}


\begin{flushleft}
$\bullet$ Aggiornamento di tutte eager : tutte le copie devono eseguire, mettesi d'accordo (two-phase commit) e quindi fornire il risultato: ` in questo caso
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che si potrebbero avere undo costosi. Un'altra soluzione sarebbe che una
\end{flushleft}


\begin{flushleft}
copia, ricevuta la richiesta, la propaga a tutte utilizzando un'operazione
\end{flushleft}


\begin{flushleft}
multicast atomica.
\end{flushleft}


\begin{flushleft}
Il problema del coordinamento ` che ` costoso: tuttavia, ` anche lo strumento
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che ci fornisce le maggiori garanzie di correttezza. Vi possono essere dei rilassamenti, per esempio: si parla di copie tiepide quando i checkpoint sono fatti a
\end{flushleft}


\begin{flushleft}
determinati intervalli, per ridurre il costo dell'operazione.
\end{flushleft}


25





\newpage
2.9





\begin{flushleft}
Clustering
\end{flushleft}





\begin{flushleft}
L'idea del cluster ` quella di realizzare un insieme di risorse replicate sempre
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
disponibili (high availability), cercando di snellire il tutto per non avere un tempo di risposta troppo alto. L'idea quindi sarebbe avere un protocollo semplice
\end{flushleft}


\begin{flushleft}
e le soluzioni sempre disponibili (ma spesso ` solo un bello slogan).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Per realizzare ci` si utilizzano componenti o the shelf, a basso costo e facilo
\end{flushleft}


\begin{flushleft}
mente reperibili e sostituibili (alla Google). Si pu` cercare anche di bilanciare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
il carico: all'arrivo di una richiesta, una sola copia lavora, possibilmente quella
\end{flushleft}


\begin{flushleft}
pi` libera (esecuzione dinamica quindi). In generale quindi:
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
$\bullet$ Si riceve la richiesta
\end{flushleft}


\begin{flushleft}
$\bullet$ La si smista alla macchina meno carica
\end{flushleft}


\begin{flushleft}
$\bullet$ Esecuzione
\end{flushleft}


\begin{flushleft}
$\bullet$ Viene fornito il risultato al client.
\end{flushleft}


`


\begin{flushleft}
Per decidere quale copia debba eseguire, come si fa? E necessario un sistema
\end{flushleft}


\begin{flushleft}
di monitoring (necessario per la QoS), uno scheduler (in generale strutturato
\end{flushleft}


\begin{flushleft}
master/slave). Questo sistema deve anche essere in grado di identicare eventuali copie guaste, e quindi di escluderle per mantenere delle buone prestazioni,
\end{flushleft}


\begin{flushleft}
possibilmente facendo migrare i servizi sulle macchine al momento migliori. Per
\end{flushleft}


\begin{flushleft}
determinare se una copia ` attiva, si usano degli heartbeat, ovvero si mandano
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dei messaggi per vericare se la copia ` viva: se non risponde, si suppone che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ci siano problemi. Questo sistema deve essere correttamente dimensionato (ogni quanto si manda l'impulso? Qual'` il tempo di comunicazione? Il massimo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ritardo accettabile? In generale vi ` una macchina apposita per questo compito).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Nel caso di fail-over, vi sono due diverse politiche da attuare:
\end{flushleft}


\begin{flushleft}
$\bullet$ O si attiva una macchina che era passiva
\end{flushleft}


\begin{flushleft}
$\bullet$ Oppure si sfrutta una macchina che era gi` attiva per un altro servizio,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
caricandola ulteriormente. Ci` pu` essere costoso alle volte
\end{flushleft}


\begin{flushleft}
o o
\end{flushleft}


\begin{flushleft}
Se l'heartbeat non ` progettato correttamente, potrebbe causare fail-over!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Se si partizionano le risorse (abbiamo per esempio due sottoreti) cosa succede? Pu` essere problematico, il cluster dovrebbe lavorare comunque! Si deve
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ripristinare la rete globale. Il servizio deve funzionare anche se vi sono problemi
\end{flushleft}


\begin{flushleft}
di coordinamento, quindi in realt` si prosegue lo stesso, e si rinvia l'aggiornaa
\end{flushleft}


\begin{flushleft}
mento ad un secondo momento. Le due sotto-reti quindi si coordineranno pi`
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
avanti!
\end{flushleft}





3





\begin{flushleft}
Qualit` di servizio e nuovi protocolli per Ina
\end{flushleft}


\begin{flushleft}
ternet
\end{flushleft}





\begin{flushleft}
Esistono diversi indicatori con cui poter valutare la QoS:
\end{flushleft}


26





\begin{flushleft}
\newpage
$\bullet$ Prontezza di risposta: viene indicata dal tempo di risposta, il jitter, o il
\end{flushleft}


\begin{flushleft}
ritardo. Nel caso vi siano pi` servizi correlati fra di loro, la qualit` viene
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
associata a pi` operazioni.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
$\bullet$ La banda, cio` quanti bit/byte al secondo si riescono a trasmettere (dati
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
trasmessi con successo)
\end{flushleft}


\begin{flushleft}
$\bullet$ L'adabilit` del sistema
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Lo throughput, ovvero il numero di servizi che si riescono ad erogare
\end{flushleft}


\begin{flushleft}
nell'unit` di tempo.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Tuttavia, questi non sono gli unici indicatori, e probabilmente non sono neanche
\end{flushleft}


\begin{flushleft}
quelli pi` interessanti per un utente che volesse pagare per un servizio. Vi sono
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
infatti degli altri parametri pi` qualitativi da considerare, perch` requisiti dalu
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'utente (come la qualit` dell'immagine, sincronizzazione audio/video,. . . ): sono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
requisiti non funzionali, legati alla tipologia di servizio! Per poter quindi servire
\end{flushleft}


\begin{flushleft}
un cliente, si deve anche poter interagire con lui, per avere un'idea di quale
\end{flushleft}


\begin{flushleft}
qualit` gli possa interessare: ci` per` ` contro la trasparenza! La negoziazione
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
e l'accordo controllato con il cliente fanno in modo che i servizi moderni non
\end{flushleft}


\begin{flushleft}
risultino trasparenti, proprio perch` l'utente pu` (e spesso deve) specicare delle
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
preferenze! Il sistema deve essere dinamico, in grado di reagire all'evoluzione
\end{flushleft}


\begin{flushleft}
delle richieste, in maniera da mantenere la QoS concordata: deve apportare
\end{flushleft}


\begin{flushleft}
delle azioni correttive durante l'esecuzione! In generale, i parametri che un
\end{flushleft}


\begin{flushleft}
utente ritiene fondamentali sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Importanza
\end{flushleft}


\begin{flushleft}
$\bullet$ La QoS percepita, che dipende dalla tipologia del servizio
\end{flushleft}


\begin{flushleft}
$\bullet$ Il costo da dover sopportare
\end{flushleft}


\begin{flushleft}
$\bullet$ La garanzia di avere degli adeguati supporti per la sicurezza (non ripudio
\end{flushleft}


\begin{flushleft}
del servizio, autenticazione, . . . )
\end{flushleft}





3.1





\begin{flushleft}
Calcolare la QoS
\end{flushleft}





\begin{flushleft}
Oltre alla quantit` di dati trasmessi con successo (la banda), un altro parametro
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
fondamentale da tener da conto ` il tempo di latenza: questo consiste nella
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quantit` di tempo necessaria per trasmettere un'unit` di informazione. Questo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dipende da tre contributi:
\end{flushleft}


\begin{flushleft}
TL = Tpropagazione segnale + Ttrasmissione + Tritardo
\end{flushleft}





(14)





\begin{flushleft}
Il tempo di trasmissione dipende dalla dimensione del messaggio e dalla banda
\end{flushleft}


\begin{flushleft}
disponibile, mentre il tempo di ritardo dipende dai tempi di accodamento che
\end{flushleft}


\begin{flushleft}
si vengono a vericare. In particolare, ` quest'ultimo a tener da conto gli overe
\end{flushleft}


\begin{flushleft}
head presenti nel sistema (spesso ` alto, e lo si pu` ridurre realizzando un buon
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}





27





\begin{flushleft}
\newpage
protocollo).
\end{flushleft}


\begin{flushleft}
La qualit` di servizio dipende da come si riescono a risolvere i colli di bottiglia
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dell'applicazione, cio` su cosa ` orientata (trasmettere tanti dati di dimensioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
molto limitate? Prevale il tempo di latenza. trasmettere diversi dati di di`
\end{flushleft}


\begin{flushleft}
mensioni elevate? E necessaria una banda suciente). Spesso, si utilizza come
\end{flushleft}


\begin{flushleft}
ulteriore indicatore il prodotto fra la latenza e la banda: riesce infatti a dare
\end{flushleft}


\begin{flushleft}
un'idea del ritardo fra mittente e ricevente, e di quante informazioni sono state
\end{flushleft}


\begin{flushleft}
inviate nel frattempo. Si rappresenta cos` il numero eettivo di bit trasmessi,
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
perch` non sar` mai uguale alla banda essendo presente proprio il tempo di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
latenza! Su questi indicatori, una prima possibile strategia molto semplice `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quella di occupare sempre al massimo le pipe (e quindi la banda), per poter
\end{flushleft}


\begin{flushleft}
garantire i tempi di risposta concordati: tuttavia, si deve tener conto anche
\end{flushleft}


\begin{flushleft}
del tempo di latenza nel far ci`. . . Spesso quindi si incorpora un tempo per il
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
buering delle applicazioni.
\end{flushleft}


\begin{flushleft}
Un altro parametro ` il jitter, ovvero la variazione della latenza che si presene
\end{flushleft}


\begin{flushleft}
ta in un usso: infatti, non ` in realt` costante (sarebbe la situazione ideale. . . ).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Basti pensare per esempio che nella maggior parte delle comunicazioni vi sono
\end{flushleft}


\begin{flushleft}
degli intermediari a supporto: a seconda del carico di lavoro presente su di loro,
\end{flushleft}


`


\begin{flushleft}
il tempo di latenza pu` variare notevolmente! E quindi necessario pensare anche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a una QoS distribuita fra i vari nodi !
\end{flushleft}


\begin{flushleft}
Lo skew rappresentalo sfasamento fra due ussi, che dovrebbero essere invece
\end{flushleft}


\begin{flushleft}
percepiti come una singola entit` dall'utente nale (per esempio, discrepanze
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
nella velocit` fra audio e video).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Spesso, in realt`, la QoS ` un parametro che ` trascurato in fase progeta
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tuale, nonostante sia un obiettivo. Questo perch` durante lo sviluppo si hanno
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
situazioni con traco molto limitato. Ci` per` non ` vero per tutti i servizi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(ad esempio, video streaming o qualunque altro usso di informazioni continuative): la QoS ` fondamentale proprio per poter erogare il servizio, per cui i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
problemi della banda e della latenza son fondamentali. Per garantire la QoS, le
\end{flushleft}


\begin{flushleft}
entit` devono eettuare una negoziazione per decidere certi parametri (il ritara
\end{flushleft}


\begin{flushleft}
do inziale per assorbire il jitter medio, il massimo ritardo accettabile per non
\end{flushleft}


\begin{flushleft}
dover scartare un pacchetto. . . ). Per esempio, una prima idea per ottimizzare
\end{flushleft}


\begin{flushleft}
la trasmissione ` quella di introdurre delle risorse sul client, e di buerizzarla:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si trasmette quindi soltanto avendo un certo numero di frame a disposizione.
\end{flushleft}





3.2





\begin{flushleft}
QoS in Internet
\end{flushleft}





\begin{flushleft}
Il mondo di Internet si basa sul protocollo TCP/IP, che lavora best eort: ci`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
signica che non pu` garantire QoS 6 . OSI ` da sempre stato progettato con
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
6 Perch` ci`? Internet non prenota o mantiene le risorse, ma cerca di determinare un
\end{flushleft}


\begin{flushleft}
e o
\end{flushleft}


\begin{flushleft}
cammino fra C/S che quindi pu` variare. Non abbiamo garanzia del servizio. OSI invece
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
denisce la possibilit` di denire gli intermediati e riservarli, in maniera da distribuire la
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
latenza totale del servizio su di loro, e in maniera da progettare i nodi intermedi con le risorse
\end{flushleft}





28





\begin{flushleft}
\newpage
l'idea di supportare QoS, ma risulta essere ancora lontana da essere realmente
\end{flushleft}


\begin{flushleft}
implementata. Si tratta quindi di individuare tecniche per garantire QoS in Internet. Le idee principali riguardano l'introduzione di nuovi protocolli e nuove
\end{flushleft}


\begin{flushleft}
applicazioni
\end{flushleft}


\begin{flushleft}
Le applicazioni classiche di Internet (tipo mail) sono elastiche, ovvero sono
\end{flushleft}


\begin{flushleft}
in grado di adattarsi alla congurazione della rete, e non richiedono QoS al
\end{flushleft}


\begin{flushleft}
supporto (possono tuttavia specicare un tempo di latenza per poter eseguire).
\end{flushleft}


\begin{flushleft}
In queste applicazioni quindi l'utente non specica dei tempi rigidi per poter
\end{flushleft}


\begin{flushleft}
eseguire.
\end{flushleft}


\begin{flushleft}
Le applicazioni moderne invece sono non elastiche: questo perch` presentano
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dei vincoli temporali precisi, e quindi richiedono QoS. Di queste, quelle real-time
\end{flushleft}


\begin{flushleft}
moderne sono tolleranti rispetto a problemi che si possono vericare, ovvero
\end{flushleft}


\begin{flushleft}
possiamo avere che sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Adattative in banda: il servizio ` erogabile ma con una banda minore, e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi qualit` diminuita: si parla per esempio di un video peggiore.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Adattative per la latenza: il servizio ` erogabile, ma con un ritardo mage
\end{flushleft}


\begin{flushleft}
giore, riducendo la QoS: uno streaming audio che perde pacchetti, un video
\end{flushleft}


\begin{flushleft}
che perde dei frame.7
\end{flushleft}


\begin{flushleft}
Bisogna ricordare che in generale la latenza non ` costante: potrebbe essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
conveniente quindi specicare la latenza su ogni frame.
\end{flushleft}


\begin{flushleft}
Un servizio per Internet potrebbe quindi richiedere garanzie diverse:
\end{flushleft}


\begin{flushleft}
$\bullet$ Il classico best-eort
\end{flushleft}


\begin{flushleft}
$\bullet$ Un controlled load, ovvero la gestione di una latenza limitata. Spesso
\end{flushleft}


\begin{flushleft}
questa ` la scelta per i servizi elastici, trattandosi di una via di mezzo fra
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il best-eort e la garanzia di determinati valori.
\end{flushleft}


\begin{flushleft}
$\bullet$ Il guaranteed load, per cui si ha un limite temporale stretto al ritardo, ma
\end{flushleft}


\begin{flushleft}
non limitato al jitter.
\end{flushleft}


\begin{flushleft}
Per poter fornire servizi che si basino sulle ultime due opzioni, ` necessario
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
far evolvere Internet da un sistema best-eort (dovuto all'uso di IP) elastico
\end{flushleft}


\begin{flushleft}
(grazie a TCP) ad un sistema con QoS. Si parla quindi di una transizione da
\end{flushleft}


\begin{flushleft}
una struttura a basso costo e senza garanzie ad una con costi dierenziati a
\end{flushleft}


\begin{flushleft}
seconda delle prestazioni da erogare. Vi sono due proposte, incompatibili fra di
\end{flushleft}


\begin{flushleft}
loro:
\end{flushleft}


\begin{flushleft}
$\bullet$ Servizi integrati, RFC 2210: si ragiona per singolo servizio, e quindi si
\end{flushleft}


\begin{flushleft}
cerca di denire per ogni singolo usso la QoS
\end{flushleft}


\begin{flushleft}
necessarie per soddisfare la banda
\end{flushleft}


\begin{flushleft}
7 Questo non si pu` fare con TCP,perch` garantisce che si ricevano sempre i frame in ordine:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
trasparente, ma non va bene se abbiamo un alto jitter!
\end{flushleft}





29





\begin{flushleft}
\newpage
$\bullet$ Servizi dierenziati, RFC 2475: si propone di introdurre QoS a livello di
\end{flushleft}


\begin{flushleft}
rete, quindi la proposta ` quella di lavorare contemporaneamente su pi`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
ussi per migliorare in maniera globale il routing.
\end{flushleft}





3.3





\begin{flushleft}
Gestire la QoS
\end{flushleft}





\begin{flushleft}
Come gestire quindi la QoS? Il controllo della qualit` dovrebbe essere fatto dua
\end{flushleft}


\begin{flushleft}
rante l'esecuzione, e in generale abbiamo una fase iniziale (prima dell'erogazione,
\end{flushleft}


\begin{flushleft}
azioni preventive o statiche), una fase durante il deployment (azioni reattive o
\end{flushleft}


\begin{flushleft}
dinamiche). Tuttavia, in Internet non vi ` n` la fase iniziale (detta anche proe e
\end{flushleft}


\begin{flushleft}
visioning), e non vi ` soprattutto il controllo della qualit` durante l'esecuzione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(come controllare i diversi intermediari??), e soprattutto non esistono protocolli
\end{flushleft}


\begin{flushleft}
standard! Va valutato caso per caso come strutturare la gestione della QoS.
\end{flushleft}


\begin{flushleft}
Nella parte statica quindi client e server si devono mettere d'accordo prima
\end{flushleft}


\begin{flushleft}
di erogare il servizio: ` la fase di negoziazione della QoS. Questa fase cone
\end{flushleft}


\begin{flushleft}
siste nel denire un Service Level Agreement fra le varie parti, che dovr` essere
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
descritto in una maniera opportuna, e quindi nel denire/riservare le risorse necessarie. La fase che precede l'erogazione ` senza costo, perch` non vi ` ancora
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il monitoring ma solo la predisposizione del servizio.
\end{flushleft}


\begin{flushleft}
La fase dinamica invece ` caratterizzata dal monitoring dell'erogazione del
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
servizio, che ` strettamente necessario per poter magari fare una rinegoziazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nel caso sia necessaria (introduzione di nuovi intermediari, presenza di nodi
\end{flushleft}


\begin{flushleft}
guasti, . . . ) per poter mantenere la QoS stabilitae garantire che ci` avvenga:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
questa ` la condizione necessaria perch` un servizio venga retribuito. Questa `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la fase pi` costosa, perch` i vari nodi si devono adattare alle situazioni che si
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vengono a vericare, oppure devono essere estromessi se non adatti. L'idea `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quella di basarsi il pi` possibile sulla localit` : pi` le azioni sono locali, senza
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
dover far intervenire un agente esterno, un fruitore, minore ` il costo; anche per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
questa fase si deve cercare di progettare dei protocolli ottimizzati che costino
\end{flushleft}


\begin{flushleft}
poco, sfruttando il principio della minima intrusione quindi ! Politiche poco
\end{flushleft}


\begin{flushleft}
costose quindi, e limitare l'uso delle risorse necessarie al monitoring! In un
\end{flushleft}


\begin{flushleft}
ipotetico sistema quindi il piano utente (quello della gestione del servizio) e
\end{flushleft}


\begin{flushleft}
quello del management sono accoppiati, ma dovrebbero essere strutturati in
\end{flushleft}


\begin{flushleft}
maniera tale da condividere il minor numero di risorse. Il problema di Internet
\end{flushleft}


\begin{flushleft}
` che siamo sempre in piano utente, e quindi ` dicile capire se ci sono problemi.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Il piano del management in realt` pu` essere scomposto in diverse sottoparti,
\end{flushleft}


\begin{flushleft}
a o
\end{flushleft}


\begin{flushleft}
a seconda di cosa si vuole gestire: vi ` una parte per l'identicazione di fault
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e recovery delle risorse, una parte per il controllo della performance (quindi
\end{flushleft}


\begin{flushleft}
eventuali aggiustamenti del servizio per poter garantire la QoS). Altri settori
\end{flushleft}


\begin{flushleft}
fondamentali riguardano l'accounting e la sicurezza dei servizi.
\end{flushleft}





30





\newpage
3.4





\begin{flushleft}
Gestione dei sistemi: OSI e SNMP
\end{flushleft}





\begin{flushleft}
OSI ha denito un sistema per poter monitorare/gestire un insieme di risorse
\end{flushleft}


\begin{flushleft}
mediante l'uso di risorse astratte 8 : l'idea ` quella di utilizzare delle descrizioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
standard per poter denire risorse e azioni, necessarie per la gestione. Le informazioni che descrivono quindi il mondo sono codicare utilizzando il CMIB,
\end{flushleft}


\begin{flushleft}
Common Management Information Base. OSI quindi sarebbe in grado, mediante queste informazioni, di poter gestire i singoli nodi di una rete (tipo, poter
\end{flushleft}


\begin{flushleft}
specicare la banda erogabile presente su un nodo9 , . . . ). OSI struttura il management con l'idea che vi siano manager in grado di comunicare con gli agenti,i
\end{flushleft}


\begin{flushleft}
responsabili delle singole risorse: non vi ` una specica precisa, permettendo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi di poter realizzare architetture pi` o meno complesse.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
In realt`, il protocollo pi` diuso per la gestione di una rete ` anche uno
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dei pi` semplici, detto Simple Network Management Protocol, sviluppato dall'Iu
\end{flushleft}


\begin{flushleft}
ETF, e per questo incompatibile con OSI : inizialmente non teneva conto della
\end{flushleft}


\begin{flushleft}
sicurezza, e si trattava di pura e semplice comunicazione.
\end{flushleft}


\begin{flushleft}
SNMP denisce (nella sua prima realizzazione) un unico manager centralizzato e diversi agenti non locali, quindi studiati per un sistema distribuito. Il
\end{flushleft}


\begin{flushleft}
manager si preoccupa quindi di fare delle richieste sugli agenti, i quali devono
\end{flushleft}


\begin{flushleft}
rispondere, e possono anche avvisare di eventuali problemi/eventi mediante delle
\end{flushleft}


\begin{flushleft}
trap. Il protocollo ` molto sincrono, ovvero si attende sempre una risposta!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Un agente in realt` gestisce delle variabili standard (non se ne possono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
introdurre di nuove), che sono descritte nel MIB: le operazioni sono quindi
\end{flushleft}


\begin{flushleft}
semplicemente delle GET e SET su queste variabili.
\end{flushleft}


\begin{flushleft}
Una prima reingegnerizzazione di SNMP ha portato alla possibilit` di poter
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
denire il manager come una struttura gerarchica (sfruttando l'idea di realizzare
\end{flushleft}


\begin{flushleft}
degli agenti proxy, una via di mezzo fra un agent e un master), in maniera da
\end{flushleft}


\begin{flushleft}
ridurre i rischi di una congestione, suddividendo la responsabilit`. Il costo `
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi limitato dal numero di agenti presenti. Solo per` con la terza versione si
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
` introdotto in SNMP anche il concetto di sicurezza.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
SNMP presenta alcuni problemi: prima di tutto, la perdita/sostituzione di
\end{flushleft}


\begin{flushleft}
un agente provoca la ricongurazione di tutto il sistema. Inoltre, si tratta sempre di variabili, che sono solo rappresentazioni della risorsa: per esempio, con
\end{flushleft}


\begin{flushleft}
SNMP non si pu` specicare la banda di un router, non la pu` controllare! Il
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
manager poi comunica con gli agent, ma sempre esternamente deve essere specicata come avviene la comunicazione (ogni quanto interroga gli agent?). Inne,
\end{flushleft}


\begin{flushleft}
gli agent forniscono informazioni strettamente locali alla risorsa che gestiscono:
\end{flushleft}


\begin{flushleft}
per poter fornire delle informazioni pi` generali sullo stato della rete ` necessario
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
aancare a SNMP un sistema di Remote MONitoring, per poter fornire all'utente maggiori possibilit`. Si introducono quindi dei monitor (probe), in grado
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di lavorare in autonomia e comunicare con il manager, riportando informazioni
\end{flushleft}


\begin{flushleft}
8 Non esistono speciche su come implementarle, quindi le varie realizzazioni sono standard
\end{flushleft}


\begin{flushleft}
de facto
\end{flushleft}


\begin{flushleft}
9 Attenzione, OSI ` solo comunicazione!! La banda dovr` poi essere stabilita dal singolo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
router, la tecnologia utilizzata deve essere indipendente da questa comunicazione!
\end{flushleft}





31





\begin{flushleft}
\newpage
ltrate. Anche RMON rappresenta una derivazione semplicata da OSI, quindi
\end{flushleft}


\begin{flushleft}
incompatibile.
\end{flushleft}


\begin{flushleft}
OSI permette di denire sistemi molto pi` complessi, grazie all'uso di un MIB
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
pi` organizzato. Si possono infatti realizzare gerarchie dinamiche fra manger e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
agent, questi si possono quindi creare e distruggere a piacimento (senza dover
\end{flushleft}


\begin{flushleft}
ricongurare l'intero sistema)! Il MIB ` totalmente cancellabile, come anche le
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
singole operazioni come la GET: si ragiona quindi anche sulla durata dell'operazione, per cui se ` oltre il limite impostato, ` annullata. Gli oggetti gestiti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possono essere anche molto complessi (non una singola risorsa come con SNMP).
\end{flushleft}





3.5





\begin{flushleft}
Evoluzione dei router
\end{flushleft}





\begin{flushleft}
L'idea alla base dell'introduzione di QoS in Internet ` che sui nodi intermedi si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
hanno delle informazioni sullo stato del servizio. Un router semplice prende e
\end{flushleft}


\begin{flushleft}
rispedisce i pacchetti, in generale sfruttando la politica FIFO, senza sfruttare
\end{flushleft}


\begin{flushleft}
tutte le possibilit` per l'instradamento: garantisce best-eort, ma non QoS,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
poich` i ussi sono limitati da altri ussi!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Lo sviluppo sarebbe quindi quello di realizzare un router che ragiona in termini dierenziati : deve essere in grado quindi di marcare i ussi, e deve riuscire
\end{flushleft}


\begin{flushleft}
a trattare la gestione dei ussi in maniera da favorire i ussi pi` prioritari (magu
\end{flushleft}


\begin{flushleft}
ari scartando/ritardando i pacchetti dei ussi meno prioritari). Si ha che quindi
\end{flushleft}


\begin{flushleft}
lo stato del router dipende dal singolo pacchetto, che a sua volta dipende dal
\end{flushleft}


\begin{flushleft}
traco. In particolare, ` da notare che il costo di una determinata politica
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
viene riesso su ogni usso/messaggio: per questo vuole l'intrusione minima,
\end{flushleft}


\begin{flushleft}
per minimizzare il costo.
\end{flushleft}


\begin{flushleft}
I router per la QoS si possono modellare mediante due modelli non reali, a
\end{flushleft}


\begin{flushleft}
bucket:
\end{flushleft}


\begin{flushleft}
$\bullet$ Leaky bucket: corrisponde a un secchio con perdita. L'idea ` quella che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un router si comporti come un regolatore del usso in uscita. Si stabilisce
\end{flushleft}


\begin{flushleft}
quindi una banda massima, corrispondente alla capacit` del bucket: tutto
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ci` che ` oltre viene scartato dal router, i pacchetti troppo veloci vengono
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
rallentati. Ogni router di questo tipo ` quindi pensato per favorire un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
usso alla volta.
\end{flushleft}


\begin{flushleft}
$\bullet$ Token bucket: si prevede la presenza di un token, che garantisce ai pacchetti del usso che lo possiede di poter essere smistati dal router. Si associa
\end{flushleft}


\begin{flushleft}
quindi uno stato al usso, e questo stato dipende proprio dal numero di
\end{flushleft}


\begin{flushleft}
token presenti. In questo modello i pacchetti vengono solo ritardati, non
\end{flushleft}


\begin{flushleft}
possono essere persi. A seconda della capacit` del bucket, si possono avere
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
trasmissioni o rallentamenti. In particolare, un usso potrebbe non aver
\end{flushleft}


\begin{flushleft}
sfruttato i token, e trovandosi quindi ad essere l'unico usso con tutti i
\end{flushleft}


\begin{flushleft}
token pu` presentare dei burst. Spesso si attende infatti che un determio
\end{flushleft}


\begin{flushleft}
nato usso abbia un numero congruo di token per poter trasmettere tutti
\end{flushleft}


32





\begin{flushleft}
\newpage
assieme un insieme di bit; si tratta quindi di un sistema di buerizzazione,
\end{flushleft}


\begin{flushleft}
per cui son necessarie delle apposite risorse. I token vengono generati
\end{flushleft}


\begin{flushleft}
mediante un'apposita legge lineare.
\end{flushleft}


\begin{flushleft}
Spesso si utilizzano i due bucket in serie, per evitare proprio i burst del token
\end{flushleft}


\begin{flushleft}
bucket (quindi prima il token, seguito a cascata dal leaky!).
\end{flushleft}


\begin{flushleft}
Le politiche che un router per la QoS pu` presentare son diverse, tuttavia
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
l'idea ` quella di realizzare delle politiche conservative del lavoro: se arriva un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
datagramma e non vi sono condizioni per cui il usso ` rallentato e le code son
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
libere, il router lavora alla Internet, reinstradando subito il pacchetto. Infatti,
\end{flushleft}


\begin{flushleft}
per la legge di Kleinrock, il router non pu` essere in una condizione di idle se
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
vi sono dei pacchetti da portare in uscita. La legge di kleinrock stabilisce che,
\end{flushleft}


\begin{flushleft}
dati n ussi, con traco $\lambda$n e tempo medio di servizio $\mu$n :
\end{flushleft}


\begin{flushleft}
$\bullet$ Il prodotto $\rho$n = $\lambda$n · $\mu$n rappresenta l'utilizzo medio del router
\end{flushleft}


\begin{flushleft}
$\bullet$ Denito qn il tempo medio di attesa si ha che
\end{flushleft}


\begin{flushleft}
$\rho$n · qn = K
\end{flushleft}





(15)





\begin{flushleft}
dove K ` una costante
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Questo signica che per favorire un usso (aumento della banda, riduzione del
\end{flushleft}


\begin{flushleft}
ritardo) in realt` se ne deve per forza sfavorire un altro (diminuzione della bana
\end{flushleft}


\begin{flushleft}
da, aumento del ritardo).
\end{flushleft}


\begin{flushleft}
Si ` sempre detto che le politiche vengono giudicate dal loro costo, e che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
politiche pi` semplici sono meno costose. Tuttavia, nel caso di router, si deve
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
anche tener conto se la politica ` fair o meno (vi sono ussi in condizione di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
starving?10 ).
\end{flushleft}


\begin{flushleft}
Un primo esempio, spesso implementato mediante politiche pi` semplici
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
perch` non ` realmente implementabile ma solo un modello a tendere, ` la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
min-max fairness. Si immagini di avere un numero di richieste superiore alle
\end{flushleft}


\begin{flushleft}
risorse disponibili, e si devono quindi dividere le risorse in maniera fair. L'idea
\end{flushleft}


\begin{flushleft}
` quella di classicare i ussi in base alle loro esigenze, privilegiando i ussi che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
richiedono meno risorse, per poter cos` lasciare pi` risorse a chi ne ha maggior\i{}
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
mente bisogno; x1 $<$ x2 $<$ . . . $<$ xn indica quindi la priorit` con cui servire,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
mentre C indica la capacit` massima a disposizione del router. Si possono quina
\end{flushleft}


\begin{flushleft}
di denire mn le risorse eettivamente allocate per il usso n-simo, e Mn le
\end{flushleft}


\begin{flushleft}
risorse attualmente libere. Si ha quindi che:
\end{flushleft}


\begin{flushleft}
mn = min(xn , Mn )
\end{flushleft}


\begin{flushleft}
Mn =
\end{flushleft}





\begin{flushleft}
n
\end{flushleft}


\begin{flushleft}
i=1
\end{flushleft}





\begin{flushleft}
C$-$
\end{flushleft}


\begin{flushleft}
mi
\end{flushleft}


\begin{flushleft}
N $-$n+1
\end{flushleft}





(16)


(17)





\begin{flushleft}
10 Osservazione: le politiche dicono come i router possono trattare i ussi, ma tocca poi
\end{flushleft}


\begin{flushleft}
all'utente specicare quali ussi debbano essere trattati in quale modo!
\end{flushleft}





33





\begin{flushleft}
\newpage
Un altro modello di scheduling, derivato proprio da come funziona quello del
\end{flushleft}


\begin{flushleft}
singolo processore, ` il general scheduling processor : l'idea ` che mediante un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
algoritmo di tipo round-robin si faccia passare un bit per ogni usso alla volta:
\end{flushleft}


\begin{flushleft}
tale politica ` sicuramente molto fair, ma non applicabile realmente visto che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si lavora a pacchetti e non a bit. Anche questo modello in realt` serve solo per
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
studiare le politiche pensate e confrontarle, per determinarne la fairness.
\end{flushleft}


\begin{flushleft}
In realt`, fra le politiche realmente diuse ed implementate in router con
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
QoS vi sono:
\end{flushleft}


\begin{flushleft}
1. Priorit` ai ussi : vi sono diversi livelli di priorit` con cui poter etichettare
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
un usso. Il router quindi si preoccupa di favorire prima i ussi a massima
\end{flushleft}


\begin{flushleft}
priorit`. Questo per` non ` una politica fair ! Se continuano ad arrivare
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pacchetti di questi ussi, quelli meno prioritari non verranno mai serviti
\end{flushleft}


\begin{flushleft}
(non avranno mai banda a sucienza)!
\end{flushleft}


\begin{flushleft}
2. Round robin: ` una politica pi` fair, che garantisce comunque ad ogni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
usso una propria share della banda, ed ` una politica molto buona se i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
datagrammi dei vari ussi sono circa delle stesse dimensioni (altrimenti,
\end{flushleft}


\begin{flushleft}
si potrebbe usare un weighted round robin, per poter pesare diversamente
\end{flushleft}


\begin{flushleft}
i datagrammi. Pi` un datagramma ` pesato, maggiori risorse vi sono
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
associate. La normalizzazione ` dicile da realizzare per ussi troppo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
corti) Il round robin viene spesso implementata in quei router in cui non
\end{flushleft}


\begin{flushleft}
si possono specicare delle priorit` speciche, ma in cui comunque i ussi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
devono competere per delle risorse.
\end{flushleft}


\begin{flushleft}
3. Decit round robin: si associa una storia ad ogni usso, perch` si impone
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un limite per ciascuno. Se un usso supera la soglia consentita, non viene
\end{flushleft}


\begin{flushleft}
erogato dal router ma si memorizza tale decit. L'erogazione riprender`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
solo quando gli altri ussi avranno superato tale limite.
\end{flushleft}


\begin{flushleft}
4. Fair queueing: si tratta di round-robin fatto bit a bit. Si fa avanzare
\end{flushleft}


\begin{flushleft}
sempre il usso con il pacchetto pi` indietro, ovvero quello che se si fosse
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
realmente fatta una comunicazione bit a bit, avrebbe terminato la comunicazione per primo! Questa ` una delle politiche maggiormente usate,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
anche in ambienti Internet, perch` si hanno dei calcoli in tempi accettabili.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Un problema di tutte le politiche ` in realt` il fatto di non sapere cosa aspettarsi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
all'arrivo, cio` cosa aspettarsi dai ussi che entrano nel router e che devono come
\end{flushleft}


\begin{flushleft}
petere per le risorse. Una soluzione possibile ` quindi quella di inviare insieme
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
al usso un'idea dello stato del usso, per vagliare quanto sia pesante o meno!
\end{flushleft}


\begin{flushleft}
Perch` un router possa fornire QoS, deve essere dinamicamente ricongurae
\end{flushleft}


\begin{flushleft}
bile (cio` deve poter ammettere/spegnere ussi in maniera dinamica). Questo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per esempio ` un requisito fondamentale per risolvere il problema della cone
\end{flushleft}


\begin{flushleft}
gestione, addirittura in certi casi prevenendolo. Invece che scartare i pacchetti
\end{flushleft}





34





\begin{flushleft}
\newpage
ricevuti in maniera silenziosa (alla Internet)11 , si scartano i pacchetti in maniera
\end{flushleft}


\begin{flushleft}
visibile. Questo sistema ` contro la trasparenza, ma ` un'indicazione chiara per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
le applicazioni e gli utenti che vi sono dei problemi. Si possono quindi mettere
\end{flushleft}


\begin{flushleft}
in piedi delle politiche preventive, tipo la realizzazione di un'apposita nestra di
\end{flushleft}


\begin{flushleft}
trasmissione sul canale.
\end{flushleft}


\begin{flushleft}
Una politica sempre implementata, anche nei router a basso costo, ` la Rane
\end{flushleft}


\begin{flushleft}
dom Early Detection. Si tabilisce una coda per ciascuno usso, insieme a due
\end{flushleft}


\begin{flushleft}
soglie:
\end{flushleft}


\begin{flushleft}
$\bullet$ Se il usso fa in modo che la coda sia sempre al di sotto della soglia
\end{flushleft}


\begin{flushleft}
minima, non si scarta nessun pacchetto
\end{flushleft}


\begin{flushleft}
$\bullet$ Se il usso ` oltre la soglia massima, tutti i nuovi pacchetti vengono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
scartati.
\end{flushleft}


\begin{flushleft}
$\bullet$ Altrimenti, si decide in maniera random su quale usso scartare i pacchetti, basandosi con una probabilit` crescente con la lunghezza della
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
coda!
\end{flushleft}


\begin{flushleft}
Questa politica preventiva evita la congestione.
\end{flushleft}





3.6





\begin{flushleft}
Servizi integrati, RFC 2210
\end{flushleft}





\begin{flushleft}
L'idea alla base dei servizi integrati ` quella di essere in grado di riconoscere i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
singoli ussi, grazie al router, in modo da poter dierenziare l'uso delle risorse
\end{flushleft}


\begin{flushleft}
a seconda del usso che si viene a presentare. Il Service Level Agreement `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi fatto a livello di singolo usso, e quindi si pu` decidere la QoS per ogni
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
usso. Si deve quindi stabilire la QoS fra mittente, ricevente e necessaria per
\end{flushleft}


\begin{flushleft}
ogni nodo intermedio. Questi protocolli descrivono solo la comunicazione che
\end{flushleft}


\begin{flushleft}
le varie parti devono sostenere: la politica locale sar` implementata a livelli
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
inferiori localmente dalle singole entit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Nonostante il costo, i servizi integrati lavorano proprio al livello applicativo
\end{flushleft}


\begin{flushleft}
(OSI), proprio perch` a questo livello le risorse sono note e si possono valutare:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
questo signica che su ogni nodo si lavorer` a livello applicativo, in maniera tale
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
da poter individuare fra i possibili cammini il cammino migliore, che divverr` ata
\end{flushleft}


\begin{flushleft}
tivo. Per far ci` si utilizza un protocollo detto Reservation Protocol ; questo proo
\end{flushleft}


\begin{flushleft}
tocollo infatti permette di specicare un cammino attivo in grado di rispettare
\end{flushleft}


\begin{flushleft}
una determinata SLA, senza considerare il traco corrente, ovvero permette di
\end{flushleft}


\begin{flushleft}
riservare delle risorse in maniera attiva per il servizio. L'idea ` che si inviino
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
delle informazione dal ricevente al mittente (e viceversa) per poter valutare le
\end{flushleft}


\begin{flushleft}
risorse (ovvero ogni risorsa dovr` provvedere con un opportuno messaggio da
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
inoltrare, per indicare la qualit` di servizio che pu` orire). Si ha quindi una
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
propagazione della gestione, per indicare la disponibilit`!
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Si tratta di un protocollo con soft state, ovvero il ricevente, una volta accordato il servizio e le modalit`, dovr` preoccuparsi di rinnovare periodicamente
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
11 Vi ` ICMP che prova ad avvertire l'utente che i pacchetti non son stati ricevuti, ma lavora
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sempre a livello di IP, quindi rischia di essere coinvolto nella congestione!
\end{flushleft}





35





\begin{flushleft}
\newpage
la richiesta del servizio concordato. Si ha che quindi il protocollo ` denito in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
due passi:
\end{flushleft}


\begin{flushleft}
1. Il cliente invia un messaggio di Resv per valutare la disponibilit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
2. Un servitore che ` disponibile risponde con un messaggio di tipo Path
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
3. Il cliente conferma il cammino scelto12 rinoltrando con un messaggio di
\end{flushleft}


\begin{flushleft}
tipo Resv (solo con questo messaggio riserva le risorse).
\end{flushleft}


\begin{flushleft}
Un cliente quindi dovr` rinnovare mediante gli stessi messaggi la richiesta di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
servizio, tuttavia sono previsiti anche degli appositi messaggi (tear ) sia da parte
\end{flushleft}


\begin{flushleft}
del cliente che del servitore, per poter interrompere l'erogazione del servizio,
\end{flushleft}


\begin{flushleft}
e permettere una ricongurazione del servizio. Il protocollo stabilisce che si
\end{flushleft}


\begin{flushleft}
possono richiedere risorse in esclusiva o in condivisione con altri ussi (particolarmente utile per ottimizzare la comunicazione). Gli scambi di messaggi
\end{flushleft}


\begin{flushleft}
ovviamente avvengono fra nodi vicini, cercando quindi di limitare il costo senza
\end{flushleft}


\begin{flushleft}
eseguire un broadcast.
\end{flushleft}


\begin{flushleft}
Questo ` un sistema conveniente per reti locali e non globali (si ha un alto nue
\end{flushleft}


\begin{flushleft}
mero di messaggi in circolazione): troppi clienti e si avrebbero errori nel riservare
\end{flushleft}


\begin{flushleft}
le risorse perch` prenotate prima da altri, e deve essere noto alle applicazioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che lavorano che lo scambio di informazioni si basa su tale protocollo. Infatti,
\end{flushleft}


\begin{flushleft}
al degradare delle prestazioni si pu` giungere ad una condizione di best-eort,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
per cui ` necessaria la rinegoziazione. Ogni ricevente deve quindi mantenere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
uno stato per avere idea in che situazione si trova. Sicuramente conviene condividere ove possibile. Si possono anche fare spesso delle supposizioni per limitare
\end{flushleft}


\begin{flushleft}
l'overhead (il ricevitore sa a chi mandare per primo le richieste, il servitore sa
\end{flushleft}


\begin{flushleft}
chi potrebbe essere interessato al servizio, . . . ).
\end{flushleft}


\begin{flushleft}
Il problema di RSVP ` che ` un protocollo con una forte intrusione, perch` si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ha una parte statica molto ben denita, ma che potrebbe essere solo ideale (non
\end{flushleft}


\begin{flushleft}
funzionerebbe bene in presenza di nodi congestionati). Per questo, a supporto
\end{flushleft}


\begin{flushleft}
di questo protocollo per la parte statica, sono stati sviluppati altri protocolli
\end{flushleft}


\begin{flushleft}
per il supporto alla QoS a livello applicativo per la parte dinamica. Sono il Real
\end{flushleft}


\begin{flushleft}
Time Protocol e il Real Time Control Protocol. Sono entrambi protocolli basati
\end{flushleft}


\begin{flushleft}
su UDP, per il singolo usso, che si preoccupano di portare materialmente i
\end{flushleft}


\begin{flushleft}
frame, incapsulandoli in maniera opportuna. Proprio per questo motivo non
\end{flushleft}


\begin{flushleft}
la garantiscono ma sono solo di supporto! RTP per esempio si preoccupa di
\end{flushleft}


\begin{flushleft}
marcare ed ordinare i singoli frame, in maniera di mandarli in ordine13 , mentre
\end{flushleft}


\begin{flushleft}
RTCP gestisce la connessione astratta.
\end{flushleft}


\begin{flushleft}
RTP non denisce una sincronizzazione verso un tempo assoluto (nel distribuito questo ha dei costi improponibili), ma ha l'obiettivo di minimizzare il
\end{flushleft}


\begin{flushleft}
jitter. Questi primi protocolli ragionano sul cammino attivo, per poter denire
\end{flushleft}


\begin{flushleft}
correttamente i nodi intermedi. Sono protocolli IETF, con sempre l'obiettivo di
\end{flushleft}


\begin{flushleft}
giungere ad una facile e veloce implementazione.
\end{flushleft}


\begin{flushleft}
12 Il protocollo non spiega come scegliere il cammino (problema implementativo), ma solo
\end{flushleft}


\begin{flushleft}
quali sono i messaggi di comunicazione che i diversi partecipanti devono scambiare
\end{flushleft}


\begin{flushleft}
13 Attenzione: la decisione di come mandare per` non ` a carico del protocollo, che mette a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
disposizione solo meccanismi ma non politiche
\end{flushleft}





36





\begin{flushleft}
\newpage
RTP ` sempre accompagnato da RTCP. Il primo ` un servizio fortemente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
erogato dal servitore verso il ricevente (da chi sa poco a chi sa molto), mentre
\end{flushleft}


\begin{flushleft}
il secondo serve per fornire al gestore informazioni di gestione, e quindi naviga
\end{flushleft}


\begin{flushleft}
in entrambe le direzioni. Tuttavia, si devono specicare in maniera precisa entrambi perch` utilizzano le stesse risorse, e potrebbero aumentare l'intrusione;
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si stabilisce per esempio quale ` la banda che RTCP pu` sfruttare. RTP in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
particolare consente ai singoli intermediari di intervenire sui singoli messaggi,
\end{flushleft}


\begin{flushleft}
per poter comunque garantire il raggiungimento della QoS stabilita. RTCP permette, in particolare con il receiver e il sender report, di poter stabilire lo stato
\end{flushleft}


\begin{flushleft}
del cammino, per poter quindi far eseguire eventuali operazioni (tipo recovery
\end{flushleft}


\begin{flushleft}
di un nodo); tuttavia, si deve sempre considerare che tutto ci` ` particolarmente
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
costoso.
\end{flushleft}


\begin{flushleft}
Questi protocolli sono anche veicoli di informazioni applicative, cio` si pose
\end{flushleft}


\begin{flushleft}
sono specicare nei datagrammi informazioni per le singole applicazioni: sono
\end{flushleft}


\begin{flushleft}
protocolli hop-to-hop, che lavorano su tutti i nodi, per cui bisogna garantire che
\end{flushleft}


\begin{flushleft}
i nodi intemedi non modichino le informazioni a livello applicativo. Le possono
\end{flushleft}


\begin{flushleft}
vedere, ma non modicare.
\end{flushleft}


\begin{flushleft}
Questi protocolli purtroppo non sono molto scalabili, e possono essere usati
\end{flushleft}


\begin{flushleft}
solo in reti molto limitate. Il lettore RealPlayer per esempio sfrutta un altro
\end{flushleft}


\begin{flushleft}
protocollo detto Real Time Streaming Protocol, in cui non si denisce un cammino attivo, ma una volta ottenute le speciche dello stream, si utilizza UDP
\end{flushleft}


\begin{flushleft}
o TCP e un sistema di buering per poter trasferire il usso dalla sorgente al
\end{flushleft}


\begin{flushleft}
player. Infatti, inizialmente si parte mediante TCP che riempe il buer, ma se
\end{flushleft}


\begin{flushleft}
un frame non arriva si sfrutta UDP proprio perch` non garantisce che i messaggi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
arrivino in ordine! E un modello push, in cui le informazioni arrivano dal server. Questo ` un protocollo dal costo minimo, proprio perch` non riserva nulla:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
lavora solo sugli end-point. E sempre possibile comunque tornare a RSVP nel
\end{flushleft}


\begin{flushleft}
caso non fosse suciente.
\end{flushleft}





3.7





\begin{flushleft}
Servizi dierenziati, RFC 2474
\end{flushleft}





\begin{flushleft}
L'approccio a servizi dierenziati consiste nel cercare di fornire QoS non a livello
\end{flushleft}


\begin{flushleft}
applicativo, ma a livello di rete. Facendo ci`, in realt`, si ha che si sono deniti
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
molti meno protocolli rispetto ai servizi integrati (risultando essere inoltre molto
\end{flushleft}


\begin{flushleft}
pi` scalabili). I servizi dierenziati sono studiati per supportare le applicazioni
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
legacy e per domini specici (comunit` di utenti). L'idea ` quella che si devono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
aggreggare i ussi in diverse categorie, e a seconda delle categorie si denisce la
\end{flushleft}


\begin{flushleft}
QoS. Un pacchetto viene quindi classicato dal router in base al suo contenuto,
\end{flushleft}


\begin{flushleft}
e viene associato ad una possibile classe, e quindi ad un possibile trattamento.
\end{flushleft}


\begin{flushleft}
Si ha che quindi l'SLA ` stipulato sulla classicazione dei ussi, e le garanzie
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vengono fornite dalle politiche implementate dai router (la politica ` concordata
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
solo fra l'utente e il server).
\end{flushleft}


\begin{flushleft}
Possibili esempi di servizio sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ l'expedited forwarding, per cui ogni router dispone di due diverse code, per
\end{flushleft}





37





\begin{flushleft}
\newpage
cui si garantisce che almeno i pacchetti classicati come expedited saranno
\end{flushleft}


\begin{flushleft}
consegnati con la qualit` calcolata. Si possono pesare utilizzando una fair
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
queuing pesata.
\end{flushleft}


\begin{flushleft}
$\bullet$ l'assured forwarding, in cui i pacchetti sono marcati a seconda della possibile congestione.
\end{flushleft}


\begin{flushleft}
Vi ` per` un problema: come si possono denire queste classi, nel protocollo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
IPv4 non vi ` possibilit`. L'idea migliore sarebbe quella di passare ad IPv6, che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
grazie a 128 bit contro 32, garantisce la presenza di ancora molti nomi, ove `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
presente un apposito campo dove si pu` classicare il singolo pacchetto!
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
IPv6 ` stato pensato per essere compatibile con IPv4, ma gestisce gli ine
\end{flushleft}


\begin{flushleft}
dirizzi in maniera diversa (il broadcast ` stato eliminato, divenendo in realt`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
multicast; sono stati aggiunti il P2P e l'anycast14 , ed ` in grado di fornire un
\end{flushleft}


\begin{flushleft}
suo supporto alla replicazione! IPv6 in particolare semplica l'header, facendo
\end{flushleft}


\begin{flushleft}
in modo di puntare altri header per poterlo estendere! Un'altra caratteristica
\end{flushleft}


\begin{flushleft}
` che IPv6 ` stato progettato per essere mobile, ovvero: un indirizzo di questo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tipo si pu` spostare senza problema da una rete a quell'altra, grazie al fatto che
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
lo si memorizza in un'apposita struttura. IPv6 in realt` ` stato studiato per
\end{flushleft}


\begin{flushleft}
a e
\end{flushleft}


\begin{flushleft}
essere di supporto anche ai servizi integrati, quindi potrebbe essere un'ottima
\end{flushleft}


\begin{flushleft}
estensione per Internet.
\end{flushleft}


\begin{flushleft}
Oltre a questi approcci, si sta cercando di sviluppare dei sistemi in grado
\end{flushleft}


\begin{flushleft}
di far convivere (in maniera competitiva) servizi integrati e dierenziati, per
\end{flushleft}


\begin{flushleft}
cercare di sfruttare i vantaggi di entrambi.
\end{flushleft}





4





\begin{flushleft}
Sistemi per la comunicazione e la sincronizzazione
\end{flushleft}





\begin{flushleft}
La maniera con cui due processi possono comunicare ` molto variabile: si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possono classicare le comunicazioni in diversi modi (sincrone/asincrone, dirette/indirette, bloccanti/non bloccanti . . . ). Di particolare interesse riguarda
\end{flushleft}


\begin{flushleft}
ovviamente la comunicazione a molti destinatari : un tale sistema pu` essere alle
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
volte molto costoso da gestire, ma spesso ` necessario (gestione a copie attive;
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sottoscrizione di consumer ad eventi; e cos` via. . . ).
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
Nel modello di Internet erano stati studiati due sistemi: il broadcast (realmente inarontabile dal costo) e il multicast (realizzabile su indirizzi di classe
\end{flushleft}


\begin{flushleft}
D). Tuttavia, questi sistemi risultano essere ecienti nch` si lavora comunque
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
con una localit`. Se invece si dovesse lavorare su pi` gruppi, ` necessario utia
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
lizzare come protocollo IGMP (utilizzo quindi di un protocollo non locale), che
\end{flushleft}


\begin{flushleft}
permette a una o pi` reti di trasmettere in multicast, realizzando una sorta di
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
14 Obiettivo: raggiungere un qualunque indirizzo della classe specicata, che sia il pi` vicino
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
o il pi` comodo
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}





38





\begin{flushleft}
\newpage
broadcast locale (comunque abbastanza costoso)15 . Oltre al costo, queste comunicazioni mancano prima di tutto di QoS (IGMP non garantisce l'ordine dei
\end{flushleft}


\begin{flushleft}
messaggi!), ma hanno anche una debole capacit` espressiva (non si riesce per
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
esempio a denire priorit` nelle comunicazioni, oppure sincronismi. . . ). Infatti,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
in Internet si ragiona utilizzando il Time To Live per poter dirigere e guidare
\end{flushleft}


\begin{flushleft}
una comunicazione multicast: se ` progettato male, l'intero sistema si ingolfa.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
IGMP ` un protocollo che permette ai nodi di una rete di lavorare in gruppo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(si registrano tutti a uno stesso indirizzo multicast). Richiede quindi l'utilizzo
\end{flushleft}


\begin{flushleft}
di un router di supporto, in maniera tale da poter controllare sia il traco in
\end{flushleft}


\begin{flushleft}
entrata che in uscita; sfrutta infatti dei particolari messaggi IGMP, come le
\end{flushleft}


\begin{flushleft}
query, per vericare chi si sia registrato a quell'indirizzo multicast mediante un
\end{flushleft}


\begin{flushleft}
messaggio di tipo report. Si cerca quindi di lavorare in un ambiente locale tale
\end{flushleft}


\begin{flushleft}
da garantire che le azioni di multicast siano valide per quella rete.
\end{flushleft}


\begin{flushleft}
Nella versione iniziale del protocollo, vi erano degli altri problemi di gestione,
\end{flushleft}


\begin{flushleft}
dovuti al fatto che vi fosse un singolo router a dover gestire tutta l'infrastruttura
\end{flushleft}


\begin{flushleft}
IGMP. Con la versione 2, un router pu` in realt` controllare pi` reti, perch`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
diventa possibile utilizzare anche pi` router. La versione 2 inoltre introduce un
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
messaggio di leave dal gruppo che mancava: prima era comunque tutto a carico
\end{flushleft}


\begin{flushleft}
del router, che doveva inviare i messaggi query periodicamente e attendere le
\end{flushleft}


\begin{flushleft}
risposte dai clienti.
\end{flushleft}





4.1





\begin{flushleft}
Realizzare il routing multicast
\end{flushleft}





\begin{flushleft}
Non esistono soluzioni standard per realizzare il routing multicast. Lo scenario
\end{flushleft}


\begin{flushleft}
studiato ` quello di pi` utenti ma un unico trasmettitore. Si realizza quindi una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
struttura ad albero dinamico (si possono inserire/togliere utenti/nodi):
\end{flushleft}


\begin{flushleft}
$\bullet$ La radice ` il trasmettitore
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ I clienti sono le foglie
\end{flushleft}


\begin{flushleft}
$\bullet$ I nodi padre sono i router che rendono possibile il cammino.
\end{flushleft}


\begin{flushleft}
La struttura ad albero ` eciente: evita infatti la presenza di cicli e maglie.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Tuttavia, la struttura dell'albero pu` inuenzare notevolmente l'ecienza delo
\end{flushleft}


\begin{flushleft}
l'architettura.
\end{flushleft}


\begin{flushleft}
Il primo passo ` quello di realizzare uno spanning tree per cui si manda
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
in ooding un messaggio per ogni destinatario, cos` che la radice riesca ad in\i{}
\end{flushleft}


\begin{flushleft}
dividuare i cammini possibili, sfruttando i messaggi del protocollo unicast. Il
\end{flushleft}


\begin{flushleft}
problema ` che questo protocollo ha un costo che cresce tantissimo all'aumentare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
del numero dei partecipanti.
\end{flushleft}


\begin{flushleft}
Il secondo passo riguarda quello della ricerca dei cammini condivisi, per cui
\end{flushleft}


\begin{flushleft}
dei router possono essere sfruttati per realizzare un cammino pi` eciente (spanu
\end{flushleft}


\begin{flushleft}
ning tree minimo). Si viene cos` a realizzare una bone o backbone multicast.
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
15 L'alternativa ` peggiore: fare un ooding globale! Ma per mandare un messaggio a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tutti,i router dovrebbero avere uno stato, e vericare che il messaggio non l'abbiano gi`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ricevuto. . . quanto deve durare lo stato?
\end{flushleft}





39





\begin{flushleft}
\newpage
Inne, la radice raccoglie le informazioni ricevute per determinare lo spanning
\end{flushleft}


\begin{flushleft}
tree minimo.
\end{flushleft}


\begin{flushleft}
Una soluzione alternativa ` il Reverse Path Broadcast, ovvero ora l'iniziativa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
` a carico dei clienti. Durante il normale routing, i clienti provano a mandare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un broadcast verso la radice, che pu`, in base a nuove informazioni, cercare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
di ottimizzare/aggregare ulteriormente l'albero. Tale sistema presenta tuttavia
\end{flushleft}


\begin{flushleft}
dei costi ulteriori che devono essere valutati; le tecnologie utilizzate sono infatti
\end{flushleft}


\begin{flushleft}
le stesse per determinare un cammino minimo di Dijkstra, cio` o si sfrutta il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Distance Vector (si deve lavorare sfruttando anche le informazioni del prossimo
\end{flushleft}


\begin{flushleft}
vicino per evitare cammini troppo lunghi) oppure Link State (tanti alberi quanti
\end{flushleft}


\begin{flushleft}
i cammini minimi, poi si devono risolvere i tie break). Tuttavia, questo sistema
\end{flushleft}


\begin{flushleft}
permette di ridurre il numero di messaggi scambiati e permette di poter denire
\end{flushleft}


\begin{flushleft}
la banda necessaria.
\end{flushleft}


\begin{flushleft}
In realt` la maggior parte dei sistemi sfrutta come protocollo il Reverse Path
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Multicast per cercare di limitare (anche se di poco) il costo: resta comunque
\end{flushleft}


\begin{flushleft}
tutto a carico della radice su come realizzare l'albero di routing.
\end{flushleft}


\begin{flushleft}
Non esiste uno standard per queste tecnologie, ma diverse proposte: si hanno
\end{flushleft}


\begin{flushleft}
dei problemi simili a quelli dell'invio della QoS con i servizi integrati di frame.
\end{flushleft}


\begin{flushleft}
Infatti si lavora spesso con stati non permanenti(soft state dalla durata limitata:
\end{flushleft}


\begin{flushleft}
gli intervalli sono un parametro critico della progettazione), alberi dinamici
\end{flushleft}


\begin{flushleft}
in grado di fare riorganizzazioni locali. Le operazioni di base riguardano la
\end{flushleft}


\begin{flushleft}
potatura (eliminazione di un router superuo) e il reinserimento o graft dinamico
\end{flushleft}


\begin{flushleft}
(reinserimento di router). Si deve quindi spesso ricalcolare l'albero in caso di
\end{flushleft}


\begin{flushleft}
variazioni! Le varie proposte sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Distance Vector Multicast Routing Protocol : ` basato su una multicast
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
bone, si attraversano le reti utilizzando un sistema di tunneling. Il risultato
\end{flushleft}


\begin{flushleft}
` che cos` si sfruttano solo alcuni nodi.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
$\bullet$ Multicast Open Shortest Path First: questo sistema invece si basa sull'altra tecnologia, e cerca di ottimizzare l'albero gi` ottenuto determinato i
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
cammini minimi
\end{flushleft}


\begin{flushleft}
$\bullet$ Core Based Trees: si mantengono costanti dei nodi, venendo a denire
\end{flushleft}


\begin{flushleft}
quindi degli alberi sub-ottimi che non variano. In questo modo si limita il
\end{flushleft}


\begin{flushleft}
costo della variazione dell'albero.
\end{flushleft}


\begin{flushleft}
Il problema per` ` tutti questi protocolli sono incompatibili fra di loro: non
\end{flushleft}


\begin{flushleft}
o e
\end{flushleft}


\begin{flushleft}
possono essere attivati contemporaneamente, o se ne sceglie uno o l'altro!
\end{flushleft}





4.2





\begin{flushleft}
Semantica della comunicazione di gruppo
\end{flushleft}





\begin{flushleft}
Come realizzare la semantica della comunicazione di gruppo? Conviene fornire
\end{flushleft}


\begin{flushleft}
delle conferme positive (i riceventi avvisano di aver ricevuto il messaggio) oppure
\end{flushleft}


\begin{flushleft}
quelle negative (chi non ha ricevuto avvisa)? Si ritrasmette a tutti o solo a chi
\end{flushleft}


\begin{flushleft}
non ha ricevuto il messaggio?
\end{flushleft}





40





\begin{flushleft}
\newpage
In generale l'obiettivo che si pressa ` che una send multicast dovrebbe
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
essere garantita come un'operazione atomica. Per risolvere il problema, conviene
\end{flushleft}


\begin{flushleft}
suddividerlo in due sottoproblemi:
\end{flushleft}


\begin{flushleft}
1. Garantire la fault tolerance: nessuno deve perdere dei messaggi! Le ritrasmissioni sono quindi un sistema da prevedere se si vuole adabilit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Tuttavia, si potrebbe rimbalzare il problema a livello applicativo: per
\end{flushleft}


\begin{flushleft}
esempio Chorus eettua multicast mai ripetuti, quindi unreliable, ma
\end{flushleft}


\begin{flushleft}
specica agli sviluppatori di realizzare il sistema di ritrasmissione.
\end{flushleft}


\begin{flushleft}
2. Fornire l'atomicit` della trasmissione: per atomicit` si intende l'ordine
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
con cui i messaggi giungono al gruppo. Si dovrebbe fare in modo infatti
\end{flushleft}


\begin{flushleft}
che tutti i membri del gruppo li ricevano nello stesso ordine?Non ` detto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(solo letture si potrebbero fare in ordine diverso)! Pu` essere infatti che
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a seconda dell'ordine dei messaggi si debbano attuare politiche diverse.
\end{flushleft}


\begin{flushleft}
L'atomicit` ` lo studio di questo problema.
\end{flushleft}


\begin{flushleft}
ae
\end{flushleft}


\begin{flushleft}
Questi due aspetti devono essere tenuti separati : in questo caso quindi si ha
\end{flushleft}


\begin{flushleft}
che l'atomicit` fa l'ipotesi che in ogni modo i messaggi giungano sempre a desa
\end{flushleft}


\begin{flushleft}
tinazione. Nel progetto di una comunicazione di gruppo non ` quindi solo ime
\end{flushleft}


\begin{flushleft}
portante la singola operazione, ma l'ordine con cui giungono al gruppo.
\end{flushleft}


\begin{flushleft}
L'adabilit` viene a mancare se si perde un messaggio, oppure un crash
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
delle due parti. In particolare, per poter garantire l'adabilit` si deve fare in
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
modo che i gruppi siano dinamici : se una copia cade, in maniera trasparente
\end{flushleft}


\begin{flushleft}
si deve proseguire. Per tutti i fault l'infrastruttura dovrebbe essere in grado di
\end{flushleft}


\begin{flushleft}
reagire: ` ovvio quindi che serve un sistema di monitoring dell'infrastruttura,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per poter eettuare le possibili azioni correttive:
\end{flushleft}


\begin{flushleft}
$\bullet$ Ritrasmissione di eventuali messaggi persi
\end{flushleft}


\begin{flushleft}
$\bullet$ Aggiustamento del gruppo dinamico.
\end{flushleft}


\begin{flushleft}
Ovviamente, si deve cercare di minimizzare i costi che si vengono aggiungere,
\end{flushleft}


\begin{flushleft}
tenendo conto del principio di minima intrusione.
\end{flushleft}


\begin{flushleft}
L'idea ` quindi quella di realizzare dei meccanismi molto semplici, in maniera
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
da poter garantire un controllo16 per poter eettuare la ritrasmissione. Si deve
\end{flushleft}


\begin{flushleft}
quindi studiare come richiedere o meno la ritrasmissione: per esempio, se avessimo una conferma positiva per ogni frame (si usa cos` un meccanismo di hold\i{}
\end{flushleft}


\begin{flushleft}
back, trattenendo i messaggi nch` non arriva la conferma che il precedente `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
stato ricevuto), il costo per il monitoring sarebbe elevato. Si riduce utilizzando
\end{flushleft}


\begin{flushleft}
le conferme negative, dove si pu` indicare cosa si ` perso (si hanno dei messaggi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ordinati . . . ). Un altro problema riguarda l'intervallo di tempo per aspettare,
\end{flushleft}


\begin{flushleft}
che deve essere opportunatamente dimensionato.
\end{flushleft}


\begin{flushleft}
16 Da
\end{flushleft}





\begin{flushleft}
non sottovalutare: e se fallisce il controllore? Chi controlla il controllore?
\end{flushleft}





41





\newpage
4.3





\begin{flushleft}
Ordinamenti
\end{flushleft}





\begin{flushleft}
L'atomicit` ` l'aspetto in cui l'utente dovrebbe essere maggiormente coinvolto.
\end{flushleft}


\begin{flushleft}
ae
\end{flushleft}


\begin{flushleft}
Infatti, non lavorando nel concentrato, certe ipotesi d'ordine che si potevano
\end{flushleft}


\begin{flushleft}
fare non sono pi` valide in maniera gratuita! Come devono lavorare le copie?
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Se potessero lavorare in maniera indipendente, per cui ogni copia pu` proo
\end{flushleft}


\begin{flushleft}
cessare i messaggi nell'ordine in cui le arrivano, senza preoccuparsi dell'ordine
\end{flushleft}


\begin{flushleft}
delle altre, si avrebbe un'infrastruttura a costo minimo. . . tuttavia ci` non `
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sempre possibile.
\end{flushleft}


\begin{flushleft}
L'ordinamento classico ` quello FIFO: l'ipotesi generale ` che si abbia seme
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
preun emettitore (si estende anche a casi con pi` emettitori, ma l'ordinamento
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
FIFO riferisce sempre i messaggi provenienti dallo stesso emettitore). Questo
\end{flushleft}


\begin{flushleft}
ordinamento stabilisce che se vengono inviati i messaggi in ordine m1, m2, tutte
\end{flushleft}


\begin{flushleft}
le copie devono ricevere i messaggi nello stesso ordine! Nel caso di pi` emetu
\end{flushleft}


\begin{flushleft}
titori, infatti, l'importante ` che i messaggi provenienti dallo stesso emettitore
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
siano sempre nello stesso ordine, ma fra emettitori diversi no; se un emettitore
\end{flushleft}


\begin{flushleft}
emette m1, m2 e un altro m3, m4
\end{flushleft}


\begin{flushleft}
$\bullet$ m1, m2, m3, m4, m1, m3, m2, m4, m3, m1, m4, m2,. . . vanno bene
\end{flushleft}


\begin{flushleft}
$\bullet$ m2, m1, m3, m4 no!
\end{flushleft}


\begin{flushleft}
Le copie devono quindi essere progettate in maniera tale da mantenere lo stato,
\end{flushleft}


\begin{flushleft}
ovvero da chi arriva la comunicazione? Se vi sono omissioni, si pu` cos` attivare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
un procedimento di hold-back.
\end{flushleft}


\begin{flushleft}
Tuttavia, l'ordinamento FIFO non ` sempre quello desiderato, proprio perch`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
non si possono imporre vincoli di precedenza fra messaggi provenienti da emettitori diversi. Basti pensare ai newsgroup: spesso succede che arrivi prima
\end{flushleft}


\begin{flushleft}
la risposta della domanda, perch` non sono presenti degli orologi sincronizzae
\end{flushleft}


\begin{flushleft}
ti. Questo succede perch` a livello di supporto non si garantisce il rapporto di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
causa-eetto
\end{flushleft}


\begin{flushleft}
L'ordinamento causale tiene conto di questo problema, si basa proprio sulla
\end{flushleft}


\begin{flushleft}
presenza di emettitori diversi, che possono inviare messaggi in relazione di causaeetto fra di loro. Questo vuol dire che se un messaggo m1 ` causa di un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
messaggio m3 da parte di un altro emettitore, la comunicazione sar` valida se
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e solo se m1 preceder` m3 sempre (per altri messaggi non ` stabilito l'ordine).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Il problema del causale ` che ` di dicile realizzazione: non vi sono supporti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che lo realizzano. Nel caso di un singolo mittente, il causale ` praticamente un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
FIFO, ed ` di semplice realizzazione. Ma se si hanno gruppi dinamici, e quindi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dipendenze dinamiche fra i messaggi, non ` banale!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Inoltre, non tutto a questo mondo si pu` rappresentare con il rapporto di
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
causa-eetto: per esempio, se si avessero due multicast che sono rispettivamente
\end{flushleft}


\begin{flushleft}
un accredito e una valutazione degli interessi, l'ordine ` fondamentale. . . ma le
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
due operazioni non dipendono l'una dall'altra! Resta che l'ordinamento su tutte
\end{flushleft}


\begin{flushleft}
le copie deve essere il medesimo, altrimenti si avrebbero dei conti sballati!
\end{flushleft}





42





\begin{flushleft}
\newpage
Questo problema non si risolve neanche con il FIFO perch`, come il causale,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si tratta di un ordinamento parziale. Si pu` pensare invece di risolverlo utilizo
\end{flushleft}


\begin{flushleft}
zando un ordinamento atomico, che ` globale. Questo perch` ` un ordinamento
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ee
\end{flushleft}


\begin{flushleft}
deciso dal gruppo! Il gruppo pu` decidere una famiglia di ordinamenti che tutte
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
le copie devono rispettare, fornendo cos` anche implementazioni diverse. L'or\i{}
\end{flushleft}


\begin{flushleft}
dinamento atomico non ` interessato infatti all'ordine specico, ma al fatto che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tutti i componenti del gruppo ricevano i messaggi nello stesso ordine. L'ordinamento atomico pu` essere realizzato in maniera da rispettare sia (o uno solo, o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
nessuno) l'ordinamento FIFO che quello causale.
\end{flushleft}


\begin{flushleft}
Per poter realizzare l'ordinamento atomico, si deve pensare comunque alla
\end{flushleft}


\begin{flushleft}
presenza di un frontend, in grado di smistare alle varie copie i messaggi che
\end{flushleft}


\begin{flushleft}
arrivano: ogni copia lavora in maniera indipendente, cos` che se manca un mes\i{}
\end{flushleft}


\begin{flushleft}
saggio ad una le altre non sono bloccate. Questo vuol dire che non sono sincrone
\end{flushleft}


\begin{flushleft}
fra di loro, ma l'obiettivo ` solo il raggiungimento di uno stato nale coeso. Il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
coordinamento quindi pu` non rispettare il FIFO, ed ` tutto interno al gruppo.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
L'ordinamento ` un costo aggiuntivo che si deve considerare, tuttavia i divere
\end{flushleft}


\begin{flushleft}
si ordinamenti hanno un costo diverso. In particolare, il causale ` l'ordinamento
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
maggiormente costoso in generale, anche se non vi ` una risposta univoca, dipene
\end{flushleft}


\begin{flushleft}
dendo da caso a caso. Tuttavia, l'atomico vista la sua variabilit` pu` presentare
\end{flushleft}


\begin{flushleft}
a o
\end{flushleft}


\begin{flushleft}
dei costi molto diversi.
\end{flushleft}


\begin{flushleft}
In tutte le architetture per il multicast basato su ordinamento atomico in
\end{flushleft}


\begin{flushleft}
generale si pensa ad un frontend che possa smistare i messaggi secondo l'ordinamento imposto: tuttavia, per garantire adabilit`, si deve considerare anche il
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
caso che il frontend non sia disponibile. Si deve trovare un modo di aggiungere
\end{flushleft}


\begin{flushleft}
qualit` (per esempio, replicazione dei frontend, con token per chi ` eettivaa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mente attivo. . . ). Esistono altre architetture meno centralizzate, ma risultano
\end{flushleft}


\begin{flushleft}
essere maggiormente complesse.
\end{flushleft}


\begin{flushleft}
Inoltre, l'ordinamento atomico basato su frontend pu` essere unfair: clienti
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
pi` vicini al front end sono favoriti. Altre soluzioni si sono preoccupate di suu
\end{flushleft}


\begin{flushleft}
perare questo problema, introducendo per` ulteriori costi.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}





4.4





\begin{flushleft}
Il problema della sincronizzazione
\end{flushleft}





\begin{flushleft}
Per poter coordinare un insieme di copie, ` necessario quindi che queste siano
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sincronizzate. La sincronizzazione non ` nient'altro che la sequenzializzazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di operazioni parallele 17 , mediante la quale si impongono degli invarianti che
\end{flushleft}


\begin{flushleft}
devono essere rispettati : si ha quindi un ordine.
\end{flushleft}


\begin{flushleft}
Tuttavia, la sincronizzazione ` diversa dalla comunicazione: questa infatti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
` interessata ad un contenuto da trasmettere, mentre la sincronizzazione ` solo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'ordine. Nelle classiche architetture C/S i due aspetti sono accoppiati, ma ci`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
non vale in altri casi.
\end{flushleft}


\begin{flushleft}
17 Esempio,
\end{flushleft}





\begin{flushleft}
realizzazione della mutua esclusione
\end{flushleft}





43





\begin{flushleft}
\newpage
Per poter sincronizzare non ` necessario stabilire un ordinamento prescritto:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si pu` scegliere quello pi` adatto a seconda delle esigenze, in maniera anche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
molto indeterministica. In questo modo si hanno spazi di implementazione
\end{flushleft}


\begin{flushleft}
molto variabili. In generale, essendo la sincronizzazione nel distribuito molto
\end{flushleft}


\begin{flushleft}
pi` costosa, si cerca di fornire un ordine solo per gli eventi necessari.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Nel distribuito, i clock non sono sincronizzati. Si potrebbe pensare di realizzare un unico clock per tutti, ma ` impensabile (si pensi a derive nella
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comunicazione del tempo). Esistono standard per stabilire un formato univoco per il tempo (UTC, Universal Coordinated Time), ma che funzionano solo
\end{flushleft}


\begin{flushleft}
se il numero dei partecipanti ` limitato. Per coordinarsi infatti i diversi client
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
chiedono e ricevono il clock mediante uno scambio di messaggi, e quindi si cerca
\end{flushleft}


\begin{flushleft}
di ottenere una mediazione, aggiustando di volta in volta il clock locale. Ma per
\end{flushleft}


\begin{flushleft}
far ci` serve un gestore continuo che faccia monitoring!
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Esiste anche un protocollo, Network Time Protocol, denito per il distribuito,
\end{flushleft}


\begin{flushleft}
in grado di basarsi su UTC per fornire un tempo comune a tutti i partecipanti.
\end{flushleft}


\begin{flushleft}
Si realizza una gerarchia di server, che coinvolge tutti i partecipanti: pi` si `
\end{flushleft}


\begin{flushleft}
u e
\end{flushleft}


\begin{flushleft}
vicini alla radice, maggiormente il tempo sar` preciso. Allontanandosi invece si
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
hanno delle derive. Ma se si guasta un server?
\end{flushleft}


\begin{flushleft}
Questi protocolli son troppo complessi e costosi per garantire un tempo univoco. Il rischio ` sempre che un evento venga etichettato male, per via di derive
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nel clock locale rispetto a quello globale. L'idea ` quindi quella di lasciar perdere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il tempo sico, il clock, ma di realizzare una sincronizzazione solo sugli eventi
\end{flushleft}


`


\begin{flushleft}
d'interesse. E una prospettiva pi` ottimista e molto meno costosa (infatti si
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
riduce la comunicazione solo agli eventi signicativi, evitando di dover tenere
\end{flushleft}


\begin{flushleft}
aggiornati gli orologi sici).
\end{flushleft}


\begin{flushleft}
Vi sono diversi sistemi per poter ordinare in base agli eventi di interesse.
\end{flushleft}


\begin{flushleft}
Quello meno importante ` quello basato su delle priorit` denite in maniera
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
statica. Infatti cos` si viene a realizzare una politica molto rigida, con rischio
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
di starvation (andrebbe bene se l'architettura prevede dei processi che debbano
\end{flushleft}


\begin{flushleft}
eseguire a scapito di altri).
\end{flushleft}


\begin{flushleft}
I metodi pi` interessanti sono invece:
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
$\bullet$ basati sull'ordinamento di Lamport, utilizzato soprattutto in US. Si realizzano dei clock logici da usare al posto dei clock sici.
\end{flushleft}


\begin{flushleft}
$\bullet$ basati sull'uso del sistema di token passing, utilizzato soprattutto in UE.
\end{flushleft}


\begin{flushleft}
Si realizza una struttura ad anello, e chi ha il token ` il coordinatore.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





4.5





\begin{flushleft}
Ordinamento di Lamport
\end{flushleft}





\begin{flushleft}
L'ordinamento di Lamport si basa di avere diversi processi in grado di mantenere
\end{flushleft}


\begin{flushleft}
una propria storia interna (gli eventi su uno stesso processore sono gi` ordinati
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
grazie alla storia), e in grado di comunicare fra di loro, in maniera punto a
\end{flushleft}


\begin{flushleft}
punto con dei messaggi (non si usano multicast, non si possono mandare batch
\end{flushleft}


44





\begin{flushleft}
\newpage
di messaggi !). L'idea ` che il numero degli eventi interessanti ` sicuramente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
inferiore al clock sico, e quindi si possono usare per ordinare.
\end{flushleft}


\begin{flushleft}
L'ordinamento di Lamport si basa sulla relazione happened-before, per poter
\end{flushleft}


\begin{flushleft}
ordinare gli eventi, imponendo prima di tutto un ordine locale. Si ha quindi che
\end{flushleft}


\begin{flushleft}
se l'evento a precede l'evento b sullo stesso processore, si ha che:
\end{flushleft}


\begin{flushleft}
a$\rightarrow$b
\end{flushleft}





(18)





\begin{flushleft}
Ovviamente questa relazione vale anche per la comunicazione fra pi` processi,
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
nel senso: se a ` l'evento di invio di un messaggio, e b la sua ricezione da un altro
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
processore, chiaramente sono in relazione di precedenza! Ovviamente, questa
\end{flushleft}


\begin{flushleft}
relazione presenta anche la propriet` della transitivit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Tuttavia, questo ordinamento non ` globale. Basta pensare a due processi che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comunicano con gli eventi a e b, ed entrambi presentano un evento che li precede
\end{flushleft}


\begin{flushleft}
localmente, k e q rispettivamente. Non esiste un ordinamento fra questi due
\end{flushleft}


\begin{flushleft}
eventi, per cui si stabilisce un'altra relazione, ovvero quella sulla concorrenza;
\end{flushleft}


\begin{flushleft}
due eventi k e q son concorrenti se non si pu` imporre una relazione di happened
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
before fra di loro:
\end{flushleft}


\begin{flushleft}
k $\uparrow$$\uparrow$ q =!(k $\rightarrow$ q)$\land$!(q $\rightarrow$ k)
\end{flushleft}


(19)


\begin{flushleft}
In questo genere di relazione si pu` osservare che il ricevente ha sicuramente pi`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
vincoli rispetto al mittente, trattandosi di una relazione fortemente orientata.
\end{flushleft}


\begin{flushleft}
In questo modo si hanno diversi orologi locali, ma non ancora un unico orologio globale. In particolare, se si trattasse di un mondo asincrono, non si avrebbe
\end{flushleft}


\begin{flushleft}
nessuna ipotesi sulla sincronicit` fra i processi (i tempi di invio potrebbero esa
\end{flushleft}


\begin{flushleft}
sere molto lunghi, maggiori di qualunque tempo osservabile). Si deve quindi
\end{flushleft}


\begin{flushleft}
trovare un modo per denire un orologio globale.
\end{flushleft}


\begin{flushleft}
L'idea ` che se a $\rightarrow$ b, allora si ha che il tempo dell'evento a ` minore del
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tempo dell'evento b:
\end{flushleft}


\begin{flushleft}
a $\rightarrow$ b $\Rightarrow$ T S(a) $<$ T S(b)
\end{flushleft}


(20)


\begin{flushleft}
Questa ` la condizione di clock logico, il quale pu` solo crescere. Si tratta di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
realizzare quindi una sorta di timestamp, per identicare in maniera univoca gli
\end{flushleft}


\begin{flushleft}
eventi nel sistema!
\end{flushleft}


\begin{flushleft}
Nel caso di una trasmissione, per cui a $\in$ Pi e b $\in$ Pj , si denisce la relazione
\end{flushleft}


\begin{flushleft}
di clock logico:
\end{flushleft}


\begin{flushleft}
a $\rightarrow$ b $\Rightarrow$ LCi (a) $<$ LCi (b)
\end{flushleft}


(21)


\begin{flushleft}
Ogni processo incrementa il valore del clock logico fra due eventi, tuttavia
\end{flushleft}


\begin{flushleft}
l'aggiornamento del processo ricevente deve tener conto anche del timestamp
\end{flushleft}


\begin{flushleft}
ricevuto insieme al messaggio per aggiornare correttamente l'orologio:
\end{flushleft}


\begin{flushleft}
LCj = max(T Sricevuto , LCilocale ) + 1
\end{flushleft}





(22)





\begin{flushleft}
Resta per` il problema della relazione di concorrenza, per cui la relazione `
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ancora un ordine parziale! Per ovviare a questo problema, si deve estendere la
\end{flushleft}


\begin{flushleft}
relazione di happend before:
\end{flushleft}


\begin{flushleft}
Se a $\in$ Pi e b $\in$ Pj , si ha che a $\Rightarrow$ b se e solo se:
\end{flushleft}


45





\begin{flushleft}
\newpage
1. LCi (a) $<$ LCj (b) oppure
\end{flushleft}


\begin{flushleft}
2. LCi (a) = LCj (b) e Pi $<$ Pj
\end{flushleft}


\begin{flushleft}
Ovvero, fondamentalmente si impone un ordine fra i processori stessi! Bisogna
\end{flushleft}


\begin{flushleft}
quindi considerare il problema dei sistemi dinamici, in cui il numero dei processori pu` variare dinamicamente. Servono quindi degli appositi gestori per gli
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
indici.
\end{flushleft}


\begin{flushleft}
La relazione di Lamport in genere tende ad aggiornare solo processi che
\end{flushleft}


\begin{flushleft}
ricevono messaggi da altri processi : chi li produce soltanto pu` avere anche dei
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
timestamp molto bassi. Se tutti comunicano fra di loro (entrambe le direzioni),
\end{flushleft}


\begin{flushleft}
allora tutti i processi saranno sincronizzati in maniera univoca. Esistono per`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
dei casi in cui la relazione di Lamport potrebbe avere dei problemi:
\end{flushleft}


\begin{flushleft}
$\bullet$ Problema del canale nascosto: se ci fossero dei processi che usano dei
\end{flushleft}


\begin{flushleft}
canali preferenziali non noti, non si potrebbe sincronizzare correttamente
\end{flushleft}


\begin{flushleft}
(ma ` un problema progettuale non reale!)
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Problema della causalit` vera: la relazione di Lamport ` anche biettiva,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
cio` ` valido anche la relazione opposta? In realt` no, due eventi che
\end{flushleft}


\begin{flushleft}
e e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
soddisfano la relazione di Lamport potrebbero non essere in rapporto di
\end{flushleft}


\begin{flushleft}
causa ed eetto!
\end{flushleft}


\begin{flushleft}
Un sistema per realizzare l'architettura basata su Lamport ` quella basata sui
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
clock vettoriali : ogni processo tiene conto in realt` anche dei clock logici degli
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
altri processori. In questo modo per` si hanno strutture dati e protocolli pi`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
complessi! Tale sistema infatti non ` scalabile:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
1. L'emettitore di un messaggio invia il proprio vector clock, aggiornandolo.18
\end{flushleft}


\begin{flushleft}
2. Il ricevitore ottiene il vector clock, lo confronta con il proprio clock locale
\end{flushleft}


\begin{flushleft}
e quindi aggiorna quest'ultimo.
\end{flushleft}


\begin{flushleft}
Il vector clock garantisce di poter propagare le informazioni e di fornire una
\end{flushleft}


\begin{flushleft}
garanzia sul fatto che siano state propagate. Tuttavia, a dierenza dei normali
\end{flushleft}


\begin{flushleft}
clock logici, non si ha una relazione d'ordine globale! Si potrebbe complicare
\end{flushleft}


\begin{flushleft}
ulteriormente realizzando delle matrici di clock.
\end{flushleft}


\begin{flushleft}
La relazione di Lamport si pu` usare per sincronizzare, per esempio, l'accesso
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ad una risorsa condivisa. Permette di garantire delle caratteristiche fondamentali che sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Correttezza (un solo processo accede alla volta)
\end{flushleft}


\begin{flushleft}
$\bullet$ Liveness (Vi ` un tempo limitato per accedere alla risorsa)
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Fairness (Non vi possono essere processi che rischiano starvation).19
\end{flushleft}


\begin{flushleft}
18 Non
\end{flushleft}


\begin{flushleft}
19 Un
\end{flushleft}





\begin{flushleft}
si incrementa in realt` sempre, per il rischio di giungere velocemente ad overow
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sistema basato su priorit` non garantisce liveness e fairness
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





46





\begin{flushleft}
\newpage
Si pu` realizzare un sistema per accesso alle risorse che rispetti questi invario
\end{flushleft}


\begin{flushleft}
anti creando un processo gestore20 , in grado di lavorare FIFO, e sfruttando un
\end{flushleft}


\begin{flushleft}
protocollo di tipo {`}request-reply-release'. L'idea ` quella di soddisfare prima le
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
richieste arrivate per prime. Il gestore concede l'uso solo al processo con cui
\end{flushleft}


\begin{flushleft}
risponde con reply, il quale lo avviser` con il release una volta terminata l'esea
\end{flushleft}


\begin{flushleft}
cuzione. Il gestore potr` quindi fornire la risorsa al prossimo processo. Si ha un
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
totale di 3 messaggi per ogni accesso alla risorsa.
\end{flushleft}


\begin{flushleft}
Per realizzare questo sistema invece con Lamport e senza uso di un gestore
\end{flushleft}


\begin{flushleft}
centrale, si deve supporre:
\end{flushleft}


\begin{flushleft}
1. Che tutti i processi siano in grado di comunicare l'uno con l'altro. Se
\end{flushleft}


\begin{flushleft}
quindi vi sono n processi, vi devono essere almeno
\end{flushleft}


\begin{flushleft}
n · (n $-$ 1)
\end{flushleft}


2





(23)





\begin{flushleft}
canali per poter comunicare.
\end{flushleft}


\begin{flushleft}
2. Supposizione per la qualit`: i canali sono FIFO, e non perdono messaggi.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
3. Ogni processo gestisce una propria coda per i messaggi. La sincronizzazione si basa propria sulla coda locale ad ogni processo.
\end{flushleft}


\begin{flushleft}
4. Il primo messaggio che ogni processo contiene ` quello sull'indicazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
locale del tempo, T0 : P0 , che corrisponde ad un tempo sempre inferiore
\end{flushleft}


\begin{flushleft}
a quello che si potr` mai trasmettere.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Il protocollo si basa sempre sull'idea di scambiare dei messaggi, e chi riceve tutti
\end{flushleft}


\begin{flushleft}
gli assensi pu` accedere alla risorsa:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
1. Un processo che vuole accedre alla risorsa invia a tutti gli altri processi un
\end{flushleft}


\begin{flushleft}
messaggio con l'indicazione del proprio tempo e di chi si tratta: Tm : Pi .
\end{flushleft}


\begin{flushleft}
2. Gli altri processi ricevono il messaggio, e devono mandare tutti un assenso:
\end{flushleft}


\begin{flushleft}
sono quindi n $-$ 1 messaggi.
\end{flushleft}


\begin{flushleft}
3. Il processo richiedente pu` accedere alla risorsa solo se ha ricevuto tutti
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
gli assensi, ma anche se nella sua coda non vi ` una richiesta superiore
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
alla propria (in base alla relazione di Lamport)!
\end{flushleft}


\begin{flushleft}
4. Una volta che un processo ha nito di lavorare sulla risorsa, elimina dalla
\end{flushleft}


\begin{flushleft}
propria coda ilsuo messaggio, e invia a tutti gli altri n $-$ 1 avvisi, in modo
\end{flushleft}


\begin{flushleft}
che anche loro possano cancellare la richiesta completata.
\end{flushleft}


\begin{flushleft}
Si ha quindi che la coda deve essere mantenuta ordinata secondo timestamp!
\end{flushleft}


\begin{flushleft}
L'attesa che si ha per avere le risposte ` proprio il sistema con cui si garantisce
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la fairness: i messaggi infatti possono essere ritardati, ma comunque arrivano;
\end{flushleft}


\begin{flushleft}
20 Soliti problemi per la QoS: se cade il gestore? Essendo un processo, avr` dei processi che
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
favorisce o meno in base alla vicinaza relativa. . .
\end{flushleft}





47





\begin{flushleft}
\newpage
se un altro processo aveva richiesto la risorsa prima ma il messaggio ` in ritardo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
su alcuni processi, verr` comunque servito prima.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Tale sistema per` ` molto costoso: richiede per ogni sincronizzazione 3(n$-$1)
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
messaggi, e richiede garanzie sull'aaidabilit` del sistema (se un nodo ` guasa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
to e non risponde mai?) e che il gruppo sia statico. Per ottimizzarlo, ci
\end{flushleft}


\begin{flushleft}
dovrebbe pensare l'infrastruttura, magari sfruttando in maniera opportuna il
\end{flushleft}


\begin{flushleft}
broadcast/multicast per eseguire una richiesta!
\end{flushleft}


\begin{flushleft}
A dierenza del protocollo centralizzato, se le copie sono studiate correttamente (con una giusta replicazione), la responsabilit` risulta essere ben disa
\end{flushleft}


\begin{flushleft}
tribuita, e non si dipende pi` da un unico gestore centralizzato. Tuttavia, si
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
deve tener conto dei guasti, su come escludere/ripristinare le copie e cos` via. . .
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
Un protocollo pi` eciente ma sempre basato su Lamport ` quello di Ricart
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e Agrawal: l'idea ` quella di limitare il numero dei messaggi in circolo, aggiune
\end{flushleft}


\begin{flushleft}
gendo intelligenza ai processi. Infatti, adesso il reply viene fatto o da processi
\end{flushleft}


\begin{flushleft}
meno prioritari o che non hanno interesse alla risorsa. In questo modo, in realt`,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
solo un processo ricever` gli n $-$ 1 reply. Il rilascio costa uguale, ma il protocollo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
in tot viene a costare 2(n $-$ 1) messaggi per accesso alla risorsa. Il reply ` invece
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ritardato nel caso che il processo che riceve la request sia proprio quello che la
\end{flushleft}


\begin{flushleft}
sta usando.
\end{flushleft}


`


\begin{flushleft}
Il problema in ci` ` come si fa a denire il ritardo? E un'idea scivolosa/rischiosa,
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
per cui si mescolano ai meccanismi di un protocollo meccanismi di supporto!
\end{flushleft}


\begin{flushleft}
Come si fa a stabilireil ritardo, ` dovuto a congestione o all'applicazione? Per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quanto quindi questo sistema usi meno messaggi, ` applicato ancora meno.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Vi sono esempi di implementazioni:
\end{flushleft}


\begin{flushleft}
$\bullet$ CATOCS,Causal Totally Ordered Comunication Operation Support: `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un sistema scalabile, mantenedo limitato il numero dei partecipanti. Si
\end{flushleft}


\begin{flushleft}
mantengono infatti continuamente dei gestori coordinati fra di loro, in
\end{flushleft}


\begin{flushleft}
grado di servire le richieste, si utilizza broadcast in casi specici.
\end{flushleft}


\begin{flushleft}
$\bullet$ ISIS: ` un sistema totalmente basato su gruppi e risorse di gruppo, per cui
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si necessita di coordinarsi fra le varie copie attive dotate di replicazione.
\end{flushleft}


\begin{flushleft}
Prevede l'utilizzo di diverse forme di multicast, distinte a seconda del tipo
\end{flushleft}


\begin{flushleft}
di ordinamento. Di base si hanno infatti le multicast per i 3 ordinamenti
\end{flushleft}


\begin{flushleft}
specicati (FIFO, causal e atomic), ma inoltre ` presente una particolare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
multicast, che serve proprio per la gestione del gruppo stesso. Utilizzando
\end{flushleft}


\begin{flushleft}
questa multicast, infatti, un gruppo pu` cambiare la propria granularit`,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
eliminando copie non attive o reintroducendo quelle che hanno subito recovery. Caratteristica fondamentale ` che il messaggio di gestione venga
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ricevuto solo dopo che tutti gli altri messaggi, dovuti agli altri tipi di multicast, siano stati ricevuti da ogni membro del gruppo. Riesce a fornire
\end{flushleft}


\begin{flushleft}
un sistema di monitoring (basandosi anche su delle tabelle che vengono
\end{flushleft}


\begin{flushleft}
aggiornate da questi multicast).
\end{flushleft}


\begin{flushleft}
L'atomic multicast di ISIS in particolare utilizza Lamport e le code locali
\end{flushleft}


\begin{flushleft}
ai processi per poter decidere con una politica di gruppo l'ordine dei mes-
\end{flushleft}





48





\begin{flushleft}
\newpage
saggi. Ogni messaggio ricevuto quindi da una copia deve essere spedito a
\end{flushleft}


\begin{flushleft}
tutte le altre copie, con un'indicazione di timestamp. Ogni copia lo marca con il proprio timestamp, e lo rispedisce indietro al primo mittente, il
\end{flushleft}


\begin{flushleft}
quale lo marca denitivamente con il timestamp maggiore e lo rispedisce
\end{flushleft}


\begin{flushleft}
a tutti gli altri (costo di Lamport).
\end{flushleft}


\begin{flushleft}
Il causal multicast aggiunge un costo visto che la dipendenza di relazione
\end{flushleft}


\begin{flushleft}
` al di fuori del gruppo: si tratta di un ordine parziale, per` richiede che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
comunque vi sia un coordinamento fra i clock logici dei mittenti, per poi
\end{flushleft}


\begin{flushleft}
far arrivare l'informazione in maniera corretta anche ai riceventi.
\end{flushleft}





4.6





\begin{flushleft}
Sincronizzazione a token
\end{flushleft}





\begin{flushleft}
Si tratta di un altro modello per superare il problema del gestore centralizzato. L'idea ` quella di avere un anello totalmente ideale, per cui i processi si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
conoscano solo in maniera limitata (prossimo ed antecedente). I vari processi
\end{flushleft}


\begin{flushleft}
si passano un unico, sempre presente token, che stabilisce la sincronizzazione
\end{flushleft}


\begin{flushleft}
(chi ce l'ha ` il gestore dinamico della risorsa, ovvero vi pu` accedere se ne
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ha bisogno). Si tratta di una soluzione molto pro attiva, poich` il token gira
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
lungo l'anello anche senza la presenza di richieste di sincronizzazione. Rispetto
\end{flushleft}


\begin{flushleft}
a Lamport il costo ` inferiore, n $-$ 1 messaggi sempre.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
In questo sistema si deve per` pensare anche all'adabilit` del token: se
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
non arriva? Si dovr` rigenerarlo, facendo in modo per` che vi sia sempre e solo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
un unico token in giro per l'anello. Si hanno quindi delle situazioni di elezione,
\end{flushleft}


\begin{flushleft}
per cui pi` partecipanti vorrebbero eseguire l'azione di recovery, ma deve essere
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
sempre uno solo! L'idea alla base ` che vi sia un time-out per cui scaduto, un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
processo pu` leggittimamente pensare che il nodo che aveva il token sia guasto.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Questo processo allora crea un token d'elezione, che deve essere approvato da
\end{flushleft}


\begin{flushleft}
tutti i nodi perch` diventi il nuovo token dell'anello. Questo signica che per`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ogni nodo deve avere una conoscenza migliore dell'anello (per esempio, non solo
\end{flushleft}


\begin{flushleft}
il prossimo ma anche il nodo ancora successivo, e cos` via). Se il token d'elezione
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
giunge quindi di nuovo a chi lo ha generato, diviene il nuovo token21 . Visto che
\end{flushleft}


\begin{flushleft}
pi` processi possono mandare il token d'elezione, si ha che si decide in maniera
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
statica quale ` il pi` prioritario, numerando i processi.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Un protocollo di elezione molto semplice da fare ed eciente ` Bully: l'idea
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
` che un processo di priorit` superiore zittisca le richieste di processi inferiori,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
per divenire lui il gestore. Si ha quindi che un processo di basso livello manda
\end{flushleft}


\begin{flushleft}
verso l'alto un messaggio d'elezione. Se un processo di priorit` superiore pu`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
assumere il compito di gestore, manda un Answer verso il basso, e propaga verso
\end{flushleft}


\begin{flushleft}
l'alto la sua elezione. Se non riceve nessun Answer entro un certo tempo, assume
\end{flushleft}


\begin{flushleft}
di essere diventato il gestore. Questo protocollo rischi di presentare molte fasi
\end{flushleft}


\begin{flushleft}
in base alla disponibilit` relativa dei processi, ma in realt` si risolve abbastanza
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
velocemente. I protocolli di elezione sono strutture tipiche delle infrastrutture
\end{flushleft}


\begin{flushleft}
dove le entit` possono cambiare ruolo.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
21 Se
\end{flushleft}





\begin{flushleft}
si fosse ripresentato il vecchio token, quello d'elezione sarebbe stato eliminato
\end{flushleft}





49





\newpage
4.7





\begin{flushleft}
Snapshot distribuiti
\end{flushleft}





\begin{flushleft}
Come si denisce uno stato nel distribuito? Si vuole uno stato globale, ma
\end{flushleft}


\begin{flushleft}
non ` sempre possibile salvarsi tutta la memoria sul disco, specialmente con
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un'alta replicazione. L'idea ` quindi quella di realizzare un sistema in cui i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
processi si scambino dei messaggi, mediante dei canali fortemente orientati, per
\end{flushleft}


\begin{flushleft}
poter salvare in maniera opportuna delle foto del sistema. Si tratta quindi di
\end{flushleft}


\begin{flushleft}
eettuare dei tagli, in maniera tale da determinare gli stati signicativi e quelli
\end{flushleft}


\begin{flushleft}
no, per poter inglobare i primi per poter formare uno snapshot globale! Lo stato
\end{flushleft}


\begin{flushleft}
infatti ` la composizione dei singoli stati di ogni processo.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Come si decide quali tagli vanno bene e quali no? I tagli realizzano degli
\end{flushleft}


\begin{flushleft}
snapshot numerati (ovvero sono ordinati), per cui un taglio che faccia in modo
\end{flushleft}


\begin{flushleft}
che un messaggio che inzia nello snapshot x e termini nello snapshot x + 1 deve
\end{flushleft}


\begin{flushleft}
essere salvato per poter mantenere il sistema consistente, mentre l'opposto non
\end{flushleft}


\begin{flushleft}
va bene! Non garantirebbe la consistenza (come si fa a capire nello stato x chi
\end{flushleft}


`


\begin{flushleft}
` il sender del messaggio? E noto solo nello stato successivo!)
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Ogni nodo ` tenuto a salvare il proprio stato locale, cos` da avere inizialmente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
almeno consistenza locale. Questa ` la base per fare uno snapshot globale dise
\end{flushleft}


\begin{flushleft}
tribuito. L'idea ` che si utilizzi un protocollo che indichi quando fare la foto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
locale e quando terminarla. Si sfrutta un apposito messaggio, detto marker, per
\end{flushleft}


\begin{flushleft}
cui ogni nodo pu` presentare due stati:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ bianco per indicare lo stato iniziale, prima dello snapshot.
\end{flushleft}


\begin{flushleft}
$\bullet$ rosso per indicare lo stato successivo.
\end{flushleft}


\begin{flushleft}
Una transizione dal bianco al rosso `una richiesta sul nodo perch` esegua uno
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
snapshot, e come una catena ordina anche agli altri nodi di eseguire uno snapshot: l'idea ` quindi che ognuno salvi il proprio stato e poi rimandi il marker.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
L'idea ` quindi che un nodo o riceve un marker rosso o diventa rosso per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fare lo snapshot: salva lo stato, e poi invia il marker su tutti i suoi canali
\end{flushleft}


\begin{flushleft}
d'uscita. Continua a salvare i messaggi che riceve e a restare rosso no a quando
\end{flushleft}


\begin{flushleft}
non riceve su tutti i suoi canali di input il marker rosso (ovvero le risposte
\end{flushleft}


\begin{flushleft}
dagli altri nodi!). A tale evento, si ferma e salva lo snapshot. Si potrebbe
\end{flushleft}


\begin{flushleft}
anche sviluppare protocolli pi` complessi, per cui il marker viene inviato solo
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
su determinati canali. Da osservare che quindi un processo in stato rosso non
\end{flushleft}


\begin{flushleft}
potr` mai mandare un messaggio a un processo in stato bianco, altrimenti non
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
si salva correttamente!
\end{flushleft}


\begin{flushleft}
Ma no a quando si salva? Fino al prossimo marker! Questo ` un sistema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
assolutamente scalabile! Il problema ` che il marker tiene un'indicazione del
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nodo che ha iniziato lo snapshot, per cui se si volesse che 2 nodi distinti facessero
\end{flushleft}


\begin{flushleft}
lo snapshot, si dovrebbe estendere la politica, magari estendendo in maniera
\end{flushleft}


\begin{flushleft}
semplice le informazioni del marker, che indichi a quale snapshot ` riferito quello
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
stato. A chi si manda poi lo stato in ogni modo? E una politica da decidere, o
\end{flushleft}


\begin{flushleft}
a un nodo che fa da repository oppure a chi ha iniziato lo snapshot. . .
\end{flushleft}





50





\newpage
5





\begin{flushleft}
I middleware
\end{flushleft}





\begin{flushleft}
Un middleware ` un insieme di strumenti di supporto all'utente/sviluppatore
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per meglio poter arontare la complessit` di un sistema in ambienti aperti
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(eterogenei ). Un middleware permette quindi di integrare diverse applicazioni,
\end{flushleft}


\begin{flushleft}
fornendo un supporto alla comunicazione fra sistemi diversi.
\end{flushleft}


\begin{flushleft}
Un middleware mette a disposzione delle risorse per l'utente (ottica B2C),
\end{flushleft}


\begin{flushleft}
ma anche componenti reintegrabili in altre applicazioni (ottica B2B).
\end{flushleft}


\begin{flushleft}
Qual'` il problema dell'eterogeneit`? Si pu` risolvere con approcci ad-hoc,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ma ci` risulta in sistemi non portabili. Quello che si vuole quindi realizzare ` un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
supporto per cui un client e un server, di ambienti diversi, riescano comunque
\end{flushleft}


\begin{flushleft}
a comunicare!
\end{flushleft}


\begin{flushleft}
Un middleware pu` fornire supporto a livelli diversi, sia a livello sico (replio
\end{flushleft}


\begin{flushleft}
cazione per esempio) che applicativo (proxy, . . . ): fornisce degli strumenti per
\end{flushleft}


\begin{flushleft}
l'utente in maniera che possa trascurare l'aspetto tecnologico, concentrandosi
\end{flushleft}


\begin{flushleft}
solo sul servizio da fornire: ` quindi fondamentale per poter astrarre!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Un middleware si pone come uno strato intermedio fra l'applicazione e le
\end{flushleft}


\begin{flushleft}
risorse di pi` basso livello (S.O., dischi, . . . ): si possono inserire diverse funzionu
\end{flushleft}


\begin{flushleft}
alit` (non solo comunicazione), come per esempio un supporto alla trasparenza
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(non importa il livello sottostante, le API del middleware fanno in modo che
\end{flushleft}


\begin{flushleft}
il comportamento sia sempre il medesimo!). Quindi, un middleware non solo
\end{flushleft}


\begin{flushleft}
semplica l'aspetto dell'applicazione, ma anche quello di supporto del sistema
\end{flushleft}


\begin{flushleft}
distribuito!22
\end{flushleft}


\begin{flushleft}
Spesso un middleware viene addottato per la sua capacit` di gestire uno o pi`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
sistemi legacy fondamentali per l'azienda, che altrimenti sarebbero intrattabili
\end{flushleft}


\begin{flushleft}
(evoluzione dei sistemi, e perdita di conoscenza). Fondamentalmente, nel caso
\end{flushleft}


\begin{flushleft}
aziendale, il compito di un middleware ` l'integrazione di risorse aziendali !
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
In ambito accademico, invece, in generale un middleware viene proposto da
\end{flushleft}


\begin{flushleft}
una comunit` per risolvere diversi problemi ed essere introdotto come standard.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Questo spesso pu` risultare problematico perch` i diversi standard non sono
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
interoperabili fra di loro! Esistono diversi dialetti/linguaggi per realizzare la
\end{flushleft}


\begin{flushleft}
comunicazione, che sono uno incompatibile con quell'altro.
\end{flushleft}





5.1





\begin{flushleft}
Valutare un middleware
\end{flushleft}





\begin{flushleft}
Un middleware viene giudicato dalla ricchezza di funzionalit` che sono messe a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
disposizione, e quindi dalle aree in cui riesce ad intervenire. Esistono diverse
\end{flushleft}


\begin{flushleft}
aree di gestione (Presentation, Computation, Information [loggin i.e.], Communication, Control [thread i.e.] e System [sicurezza i.e.]): alcune di queste sono
\end{flushleft}


\begin{flushleft}
fondamentali per un middleware (senza, non lo sarebbe), altre rappresentano
\end{flushleft}


\begin{flushleft}
un valore aggiunto.
\end{flushleft}


\begin{flushleft}
22 Ma in un sistema distribuito, dove si pone il middleware? Dipende! Certi middleware
\end{flushleft}


\begin{flushleft}
devono avere risorse su ogni nodo, altri no. . . In ogni caso, ogni nodo dell'architettura possono
\end{flushleft}


\begin{flushleft}
essere target
\end{flushleft}





51





\begin{flushleft}
\newpage
In generale si possono dividere in 4 livelli le tipologie possibili di un servizio
\end{flushleft}


\begin{flushleft}
per il middleware:
\end{flushleft}


\begin{flushleft}
$\bullet$ Host infrastructure middleware: si tratta del livello pi` basso, il pi` viciu
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


`


\begin{flushleft}
no alla macchina stessa. E quello infatti fondamentale per poter superare
\end{flushleft}


\begin{flushleft}
l'eterogeneit`, in grado quindi di fornire una visione trasparente di quela
\end{flushleft}


\begin{flushleft}
lo che ` presente a livello inferiore. Deve essere quindi un qualcosa di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
distribuito su ogni nodo dell'architettura! Un esempio ` la JVM.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Distribution middleware: altro aspetto fondamentale, ` quella parte di un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
middleware che permette di integrare le risorse distribuite, mediante un
\end{flushleft}


\begin{flushleft}
apposito sistema di comunicazione. Si tratta anche questo di un qualcosa che deve essere opportunatamente distribuito su tutti i nodi. Es`
\end{flushleft}


\begin{flushleft}
empi: RMI23 , JMS, CORBA. E quindi questo il livello che congura e
\end{flushleft}


\begin{flushleft}
gestisce le risorse distribuite. Introduce quindi API per la comunicazione
\end{flushleft}


\begin{flushleft}
e meccanismi di supporto alla comunicazione (per esempio, un sistema di
\end{flushleft}


\begin{flushleft}
nomi).
\end{flushleft}


\begin{flushleft}
$\bullet$ Common middleware services: questo invece ` un aspetto che ` presente in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
middleware maturi, per cui si possono fornire dei componenti distribuibili,
\end{flushleft}


\begin{flushleft}
utili per sviluppare in un'ottica a componenti. Spesso quindi si realizza
\end{flushleft}


\begin{flushleft}
una propria visione, ovvero il sistema si basa su un'architettura comune
\end{flushleft}


\begin{flushleft}
e un modello di supporto. Sono quindi i servizi trasversali, che spesso in
\end{flushleft}


\begin{flushleft}
realt` rappresentano il punto di forza di un mw: ` in base alla loro qualit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
che si decide se sceglierlo o meno.
\end{flushleft}


\begin{flushleft}
$\bullet$ Domain middleware services: altro aspetto presente in middleware maturi,
\end{flushleft}


\begin{flushleft}
si propongono anche servizi applicativi gi` realizzati, specici per una dea
\end{flushleft}


\begin{flushleft}
terminata comunit`. Infatti, spesso il successo di un middleware ` dovuto
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dalla comunit` di utenti che lo utilizzano, e dalle varie sottocomunit` che
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
si vengono a formare, che possono addirittura guidarne lo sviluppo! Basta
\end{flushleft}


\begin{flushleft}
pensare che CORBA ` uno standard proposto da un consorzio d'azienda,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'OMG.
\end{flushleft}





5.2





\begin{flushleft}
Classicazione dei mw
\end{flushleft}





\begin{flushleft}
I middleware si possono categorizzare in diversi modi, tuttavia la maggior parte
\end{flushleft}


\begin{flushleft}
dell'installato consiste in primis dai DOC, Distributed Object Computing (tipo
\end{flushleft}


\begin{flushleft}
CORBA, orientati all'approccio ad oggetti), e quindi dai MOM, Message Oriented MW. In realt` per`, il 'mw' pi` grande esistente forse ` il Web: non ha
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tutte le caratteristiche di un Mw (esempio, QoS, replicazione, . . . ), ma ` un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
esempio di un sistema che permette la comunicazione fra diversi sistemi eterogenei, in generale mediante la pubblicazione di informazioni su un server e il loro
\end{flushleft}


\begin{flushleft}
reperimento da parte di un client. Il grosso problema del Web infatti ` che nato
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per essere usato a livello di presentazione, e quindi di suo non presentava un
\end{flushleft}


\begin{flushleft}
sistema per lo scambio di messaggi : le sue evoluzioni hanno introdotto sistemi
\end{flushleft}


\begin{flushleft}
23 Limite
\end{flushleft}





\begin{flushleft}
di RMI rispetto ad RPC: lega C/S ad una tecnologia, non ` eterogeneo!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





52





\begin{flushleft}
\newpage
di comunicazione ed interazione, ma sempre in maniera molto limitata, dovendo
\end{flushleft}


\begin{flushleft}
basarsi solo sull'approccio C/S!
\end{flushleft}


\begin{flushleft}
Lavorando solo con RPC, che genere di MW si possono ottenere? Il problema
\end{flushleft}


\begin{flushleft}
di RPC ` che comunque limita fortemente (per esempio, si hanno operazioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
strettamente sincrone bloccanti, quando magari altri modi potrebbero essere
\end{flushleft}


\begin{flushleft}
desiderati) e in generale realizza un binding statico e non dinamico. Permette
\end{flushleft}


\begin{flushleft}
gi` di fornire dei livelli di trasparenza, e un sottolinguaggio per poter denire
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
fra C e S i servizi, ma resta che il sistema che si otterr` sar` poco scalabile,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
molto rigido (tutto deciso in maniera statica, senza poter quindi intervenire per
\end{flushleft}


\begin{flushleft}
ottimizzare il sistema!)
\end{flushleft}


\begin{flushleft}
I diversi possibili modelli di mw che si possono trovare sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Distributed Transaction Processing: questi mw nascono per cercare di
\end{flushleft}


\begin{flushleft}
ottimizzare l'accesso ai DB. L'ipotesi ` che si abbiano delle operazioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comandate da un C con poche risorse, e si vuole quindi fornire un supporto
\end{flushleft}


\begin{flushleft}
per facilitare la realizzazione di operazioni ACID (Atomic, Consistent,
\end{flushleft}


\begin{flushleft}
Isolation, Durable), necessarie per avere QoS in sistemi distribuiti basati
\end{flushleft}


\begin{flushleft}
su DB.
\end{flushleft}


\begin{flushleft}
$\bullet$ DB mw : l'obiettivo di questi mw invece ` quello di migliorare/fornire un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
supporto per eettuare ricerche su db distribuiti. Si ha quindi una logica
\end{flushleft}


\begin{flushleft}
vicina al data-mining. Si vuole quindi superare l'eterogeneit` dei diversi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
DB, sfruttando sistemi standard come ODBC, per leggere sui DB.
\end{flushleft}


\begin{flushleft}
$\bullet$ MOM : l'obiettivo di questi mw ` l'estrema indipendenza fra i vari attori ! I
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
diversi sottoinsiemi infatti comunicano a scambio di messaggi, in maniera
\end{flushleft}


\begin{flushleft}
sincrona/asincrona, e fortemente disaccoppiata: si tratta di un sistema di
\end{flushleft}


\begin{flushleft}
comunicazione a pi` basso livello del C/S. Si possono realizzare messaggi
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
tipati o meno, e risulta essere facile la realizzazione di multi/broadcast.
\end{flushleft}


\begin{flushleft}
A livello di implementazione si pu` citare JMS, che venendo dopo gli
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
altri sistemi, sviluppa un sistema basato su interfacce per poter denire i
\end{flushleft}


\begin{flushleft}
messaggi ben formati.
\end{flushleft}


\begin{flushleft}
$\bullet$ DOC : sono i mw in assoluto pi` diusi. Si preoccupano di denire un'inu
\end{flushleft}


\begin{flushleft}
terazione molto precisa e regolata, astraendo le risorse ad essere oggetti.
\end{flushleft}


\begin{flushleft}
Si incapsula il C/S in un universo basato sugli oggetti. Tuttavia, non vi
\end{flushleft}


\begin{flushleft}
` mai in generale una comunicazione diretta, per via della presenza di un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
broker : questo fornisce delle interfacce sia al C che al S, e quindi un supporto alla mediazione fra i due attori. Questo sistemafacilita l'integrazione
\end{flushleft}


\begin{flushleft}
di sistemi, e permette di realizzare operazioni che si possono eseguire in
\end{flushleft}


\begin{flushleft}
maniera automatica.
\end{flushleft}


\begin{flushleft}
Proprio perch` si basa sul modello ad oggetti, i mw di questa tipologia
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sono molto pi` variabili, e possono essere estesi molto pi` facilmente dei
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
MOM. Spesso si hanno mw di questo tipo OpenSource, in grado di creare
\end{flushleft}


\begin{flushleft}
una comunit` molto vasta ed attiva.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





53





\begin{flushleft}
\newpage
$\bullet$ Addattativi e Riessivi: un mw addattativo ` un mw che varia i servizi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nel tempo, a seconda della situazione, quindi a caldo: deve essere quindi
\end{flushleft}


\begin{flushleft}
di fornire nuovi modi di lavorare.
\end{flushleft}


\begin{flushleft}
Il fatto che sia riessivo indica invece che un componente del mw deve essere in grado di esporre quello che fa. Un sistema riessivo ` maggiormente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
costoso di un sistema statico, ma ` un sistema che viene valutato molto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
perch` permette, in maniera dinamica, di denire via real-time come il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
componente funzioni!
\end{flushleft}


\begin{flushleft}
L'obiettivo ` quindi fornire un sistema per la visibilit` dei livelli sottostanti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e permettere di adattatare e sistemare in base alle esigenze.
\end{flushleft}


\begin{flushleft}
Esistono poi diversi mw nati proprio per risolvere dei problemi specici (mobilit`, reti ad-hoc, . . . ).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





5.3





\begin{flushleft}
TINA-C
\end{flushleft}





\begin{flushleft}
TINA-C rappresenta la proposta di un mw per le TLC. Si vuole realizzare un
\end{flushleft}


\begin{flushleft}
sistema dove siano previsti pi` provider, in grado quindi di lavorare su una
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
rete. L'idea alla base ` la possibilit` di denire le varie entit`, i servizi possibili
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e fornire quindi un sistema per denire la negoziazione per l'erogazione dei
\end{flushleft}


\begin{flushleft}
servizi, e quindi la QoS.
\end{flushleft}


\begin{flushleft}
Il modello computazionale di TINA-C ` Distributed Processing Environment.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Ogni nodo deve presentare delle funzionalit` che permettono la comunicazione
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
nel distribuito. Questo ` ovviamente il livello di pi` alto livello, che si basa su
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
livelli sottostanti che forniscono astrazionie e trasparenza. Il livello sottostante
\end{flushleft}


\begin{flushleft}
` il Native Computer and Compunication Environment, che ovviamente deve
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
essere presente su tutti i nodi, per mascherare l'hw per il mw.
\end{flushleft}


\begin{flushleft}
Le applicazioni si possono quindi costruire sopra DPE, sfruttando delle applicazioni TINA-C gi` presenti ! Si hanno quindi una serie di oggetti presenti su
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ogni nodo. Queste applicazioni non sono localizzati, e si pu` trattare di servizi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
da orire, risorse ed elementi della rete. Il sistema ` quindi trasparente, perch`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
non si vede mai dove le risorse sono realmente allocate.
\end{flushleft}


\begin{flushleft}
In realt`, TINA-C prevede anche una visione non trasparente! Lo standard
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
del 2000 infatti denisce che l'utente deve esprimere le proprie preferenze, e
\end{flushleft}


\begin{flushleft}
quindi per poter sviluppare un modello complesso, si deve tener conto della
\end{flushleft}


\begin{flushleft}
locazione: si pu` progettare il sistema inizialmente come non trasparente, e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
quindi aggiungere la trasparenza!
\end{flushleft}





5.4





\begin{flushleft}
I MOM
\end{flushleft}





\begin{flushleft}
Si tratta in assoluto dei mw pi` semplicirealizzabili: sono a basso costo, e i
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
messaggi lavorano a basso livello, garantendo un forte disaccoppiamento fra le
\end{flushleft}


\begin{flushleft}
varie entit`. Basandosi sui messaggi, si supera direttamente l'eterogeneit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Il problema ` come fornire QoS ai messaggi? I messaggi devono essere pere
\end{flushleft}


\begin{flushleft}
manenti (non ` necessaria la presenza di entrambi gli attori per realizzare la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





54





\begin{flushleft}
\newpage
comunicazione), ma soprattutto l'interconnessione ` denita assolutamente in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
maniera statica! Non sono quindi mw dinamici.
\end{flushleft}


\begin{flushleft}
Ogni attore interessato presenta una propria coda locale, dove saranno depositati i messaggi: questo ` un supporto fornito quindi dal MOM, per cui si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tratta di gestire delle code orientate (o in ingresso o in uscita). Quello che realizza un MOM ` quindi un'overlay network, specicando quindi un sistema di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nomi, routing, . . .
\end{flushleft}


\begin{flushleft}
I messaggi possono o essere P2P oppure forme di multicast. Le API che il
\end{flushleft}


\begin{flushleft}
mw prevede sono quindi quelle per poter fare delle send e receive dei messaggi
\end{flushleft}


\begin{flushleft}
sulle code locali!Il mw si preoccupa di realizzare l'instradamento, ` un integrae
\end{flushleft}


\begin{flushleft}
tore di nodi: spiega come i router si debbano coordinare (si possono avere diversi
\end{flushleft}


\begin{flushleft}
intermediari, ed esistono messaggi broker appositi per gestire l'eterogeneit`)!
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Questi sono mw a basso costo, perch` fanno da collante: non si aggiunge
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
molto all'applicazione, ma solo la possibilit` di mandare e ricevere messaggi! Il
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
costo limitato facilita infatti l'integrazione di sistemi legacy!
\end{flushleft}


\begin{flushleft}
Uno dei MOM pi` diusi ` MQSeries di IBM: questo realizza uno stub per
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ogni client, e introduce degli agenti che non sono altro che nodi particolari che
\end{flushleft}


\begin{flushleft}
fanno da relay. I gestori delle code sono a loro volta degli agenti, ve ne ` quindi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
uno per coda. Il problema ` che gli agenti gestori dei canali (MCA) devono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
essere gestiti in fase di congurazione, quindi sono decisi in maniera statica!
\end{flushleft}


\begin{flushleft}
$\bullet$ Per ogni nodo si decide il numero e quali MCA
\end{flushleft}


\begin{flushleft}
$\bullet$ E quindi si attivano le connessioni
\end{flushleft}


\begin{flushleft}
La caratteristica di MQSeries ` che, sfruttando le code, introduce QoS: in partie
\end{flushleft}


\begin{flushleft}
colare si possono realizzare dei broker in grado di ricevere/prendere i messaggi e
\end{flushleft}


\begin{flushleft}
di trattarli a seconda della QoS richiesta (trasformandoli, ottimizzando il routing gi` basato su tabelle in base al contenuto del messaggio e quindi aggiungendo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
un po' di essibilit`, . . . ): introduce quindi un minimo di logica!
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Questi sistemi statici hanno la caratteristica di avere un'intrusione minima,
\end{flushleft}


\begin{flushleft}
ma non permettono molte ottimizzazioni. . .
\end{flushleft}





5.5





\begin{flushleft}
I mw ad oggetti
\end{flushleft}





\begin{flushleft}
Sono i mw pi` interessanti, in grado di lavorare ad alto livello. Si realizza un
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
contratto fra clienti e servitori, in maniera tale da realizzare anche pi` impleu
\end{flushleft}


\begin{flushleft}
mentazioni dello stesso servizio! In particolare, questi mw si basano su un bus
\end{flushleft}


\begin{flushleft}
di interconnessione che si occupa di certe logiche di base, permettendo quindi
\end{flushleft}


\begin{flushleft}
all'utente di pensare solo alla business logic! Un mw ad oggetti si preoccupa di
\end{flushleft}


\begin{flushleft}
denire le interfacce degli oggetti e le interazioni possibili, realizzando anche un
\end{flushleft}


\begin{flushleft}
sistema aperto dove integrare sistemi eterogenei.
\end{flushleft}


`


\begin{flushleft}
E quindi un'estensione del C/S: un C richiede un servizio (ovvero un oggetto). L'interfaccia rappresenta il contratto dell'oggetto, ovvero i servizi richiedibili da parte di un client. In particolare, si possono denire delle operazioni
\end{flushleft}


55





\begin{flushleft}
\newpage
richiedibili sia dagli oggetti che dai clienti per ottenere servizi!
\end{flushleft}


\begin{flushleft}
Una caratteristica particolare ed importante dei mw ad oggetti ` che pree
\end{flushleft}


\begin{flushleft}
sentano delle soluzioni che si ripetono, e delle possibili strategie da scegliere:
\end{flushleft}


\begin{flushleft}
abbiamo dei pattern, meccanismi che si ripetono!
\end{flushleft}


\begin{flushleft}
La base per ogni mw ad oggetti sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ La possibilit` di realizzare un'interazione remota
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Possibilit` di comunicare in maniera asincrona
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Inoltre, si parla di pattern anche per la gestione delle risorse, della QoS, e la
\end{flushleft}


\begin{flushleft}
denizione di nuovi servizi.
\end{flushleft}





5.6





\begin{flushleft}
Pattern per l'interazione remota
\end{flushleft}





\begin{flushleft}
Idea di base: un cliente vuole riferirsi ad un oggetto remoto; per cui serve un
\end{flushleft}


\begin{flushleft}
sistema per avere dei riferimenti remoti. Gli oggetti remoti si possono creare o
\end{flushleft}


\begin{flushleft}
localmente da parte del server, o in maniera remota su richiesta del client. Una
\end{flushleft}


\begin{flushleft}
volta istanziato, deve essere fornito il riferimento al client. Questa ` la versione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di base, di seguito, i diversi pattern che si possono utilizzare per risolvere questo
\end{flushleft}


\begin{flushleft}
problema:
\end{flushleft}


\begin{flushleft}
$\bullet$ Proxy: il client riferisce localmente un'altra struttura detta proxy, che si
\end{flushleft}


\begin{flushleft}
occupa di gestire le richieste al server remoto. Il proxy potrebbe anche
\end{flushleft}


\begin{flushleft}
essere scritto in un altro linguaggio. Il proxy permette di accedere al server
\end{flushleft}


\begin{flushleft}
come se fosse presente localmente.
\end{flushleft}


\begin{flushleft}
Una sua variazione, il pattern stub, realizza invece un proxy lato server.
\end{flushleft}


\begin{flushleft}
Questi oggetti si preoccupano di ricevere le richieste e di ridirigerle direttamente all'oggetto remoto che gestisce. Ogni stub potrebbe gestire anche
\end{flushleft}


\begin{flushleft}
una collezione di oggetti remoti.
\end{flushleft}


\begin{flushleft}
Si deve cercare di limitare il numero di questi oggetti, per ridurre l'overhead nel sistema.
\end{flushleft}


\begin{flushleft}
$\bullet$ ObjectID: questo pattern si preoccupa di denire un oggetto reale, a cui
\end{flushleft}


`


\begin{flushleft}
pu` accedere un client. E quindi necessario trasferire le informazioni dal C
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
al S. Spesso e volentieri si abbina al proxy (il client pu` anche fornire l'id
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
al proxy, che si preoccupa di recuperare il riferimento dell'oggetto: si parla
\end{flushleft}


\begin{flushleft}
spesso anche di nomi globali unici ), il quale potrebbe tener memorizzato
\end{flushleft}


\begin{flushleft}
per comodit` l'id. L'ObjectID deve quindi avere la caratteristica di essere
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
univoco.
\end{flushleft}


\begin{flushleft}
Non ` un pattern strettamente necessario, a seconda di come si vuole reale
\end{flushleft}


\begin{flushleft}
izzare l'architettura: si potrebbe volere per esempio che l'utente non abbia
\end{flushleft}


\begin{flushleft}
conoscenza del riferimento remoto, ma che in maniera trasparente sia il
\end{flushleft}


\begin{flushleft}
supporto a fornire l'oggetto con i servizi richiesti dal cliente24 . L'ObjectId potrebbe essere troppo vincolante. Se non ` necessario uno stato, in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
24 Questo sistema introduce per` altri problemi: due richieste vicine per esempio riferiscono
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
lo stesso oggetto
\end{flushleft}





56





\begin{flushleft}
\newpage
generale ` pi` conveniente questo modo di lavorare, perch` ` il mw che si
\end{flushleft}


\begin{flushleft}
e u
\end{flushleft}


\begin{flushleft}
ee
\end{flushleft}


\begin{flushleft}
preoccupa di associare gli oggetti in maniera eciente.
\end{flushleft}


\begin{flushleft}
$\bullet$ Marshalling/Unmarshalling: nel concentrato in generale o si lavora per
\end{flushleft}


\begin{flushleft}
valore o per riferimento. Nel concentrato quest'ultima opzione ` quele
\end{flushleft}


\begin{flushleft}
la usata normalmente. Tuttavia, come si fa a passare proprio l'oggetto
\end{flushleft}


\begin{flushleft}
(necessario per l'operazione sul server, oppure un oggetto risultante nell'operazione?)? Se ne deve fare proprio una copia, ed ecco la necessit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di avere un sistema che sia in grado di fare marshalling e unmarshalling,
\end{flushleft}


\begin{flushleft}
cio`: si crea una copia dell'oggetto che viene opportunatamente serialize
\end{flushleft}


\begin{flushleft}
zata, trasmessa e poi deserializzata da parte del client! In certi casi per`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
si potrebbe anche volere un oggetto che non sia una copia, ma proprio
\end{flushleft}


\begin{flushleft}
l'oggetto unico presente sul server: si deve quindi trovare una maniera per
\end{flushleft}


\begin{flushleft}
distinguire fra due diversi tipi di marshalling. In generale, si pu` peno
\end{flushleft}


\begin{flushleft}
sare che la maggior parte delle volte al server si pu` passare un oggetto
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
by-value.
\end{flushleft}


\begin{flushleft}
$\bullet$ Gestione degli errori : deve essere possibile anche trasmettere gli errori
\end{flushleft}


\begin{flushleft}
sia da parte del client che da parte del server, e sempre a chiunque possa
\end{flushleft}


\begin{flushleft}
risolvere il problema.
\end{flushleft}


\begin{flushleft}
$\bullet$ Naming support: si tratta di un pattern molto utile per la gestione dei
\end{flushleft}


\begin{flushleft}
riferimenti remoti, ovvero si riferisce un nameserver che mantiene memorizzati gli ObjectID. Si pu` anche aumentare la trasparenza, facendo in
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
modo di riferire proxy e stub dal name server! Si presenta per` il problema
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
di capire come il client conosca il name server!
\end{flushleft}


\begin{flushleft}
$\bullet$ Singleton: questo pattern si preoccupa di denire che vi sia sempre e solo
\end{flushleft}


`


\begin{flushleft}
al massimo un'istanza di un tipo di oggetto. E utile per esempio per
\end{flushleft}


\begin{flushleft}
la sopravvivvenza di questo al di fuori della durata dell'applicazione. Un
\end{flushleft}


\begin{flushleft}
esempio di singleton per esempio pu` essere il servizio di nomi: deve essere
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sempre presente, e possibilmente unico (o magari gerarchizzato in maniera
\end{flushleft}


`


\begin{flushleft}
intelligente). E usato sicuramente per congurare certi oggetti complessi
\end{flushleft}


\begin{flushleft}
una volta sola.
\end{flushleft}


\begin{flushleft}
$\bullet$ Server Application: Come realizzare il deployment nel sistema? In che
\end{flushleft}


\begin{flushleft}
ordine attivare i servizi, e i vari servitori (sistema di nomi, come e quando
\end{flushleft}


\begin{flushleft}
istanziare l'oggetto remoto, . . . ). Devono essere quindi presenti diverse
\end{flushleft}


\begin{flushleft}
strategie d'attivazione, magari denibili in maniera opportuna dai client!
\end{flushleft}


\begin{flushleft}
$\bullet$ Holder : questo ` un pattern necessario per risolvere certi problemi d'eteroe
\end{flushleft}


\begin{flushleft}
geneit`. Si preoccupa infatti di incapsulare in maniera opportuna gli
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
oggetti per presentarli a certi sistemi in maniera che possano trattarli
\end{flushleft}


\begin{flushleft}
mediante le semantiche da loro denite. Un esempio riguarda per esempio linguaggi che permettono parametri di in/out e quelli che non lo
\end{flushleft}


\begin{flushleft}
permettono. Si hanno quindi come possibili operazioni read/write.
\end{flushleft}





57





\newpage
5.7





\begin{flushleft}
Pattern per la comunicazione
\end{flushleft}





\begin{flushleft}
Di base, i mw ad oggetti tendono ad introdurre come primo modello di comunicazione l'interazione sincrona bloccante. Tuttavia, questa comunicazione `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
alquanto pesante, perch` lega in maniera pesante il client al server e viceversa.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Per questo vi sono dei pattern per introdurre altri modelli.
\end{flushleft}


\begin{flushleft}
Per ottenere una comunicazione asincrona, si possono usare:
\end{flushleft}


\begin{flushleft}
$\bullet$ Il Fire and Forget: il client richiama l'operazione, e quindi rinuncia ad
\end{flushleft}


\begin{flushleft}
avere qualunque informazione sul successo dell'operazione. Si ha quindi
\end{flushleft}


\begin{flushleft}
un'attesa minimale, per cui il client ottiene immediatamente il controllo
\end{flushleft}


\begin{flushleft}
appena inviata la richiesta per poter eseguire l'operazione. L'idea ` quella
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di usare un proxy (anche un thread quindi) dal lato del client che si preoccupi di gestire il controllo dell'operazione remota. Non ` garantito per`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
che l'operazione non sia bloccante: il proxy in generale serve le richieste
\end{flushleft}


\begin{flushleft}
usando una coda da cui servirsi, e se la coda fosse piena il client dovrebbe
\end{flushleft}


\begin{flushleft}
attendere. Non ` presente in tutti i mw ad oggetti.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Catch and return: il client attende pi` a lungo rispetto al caso precedente,
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
ma in questo modello deve attendere che sia il server stub a generare un
\end{flushleft}


\begin{flushleft}
processo per risolvere la richiesta, e che quindi faccia return. Dipende
\end{flushleft}


\begin{flushleft}
quindi anche dal tempo di comunicazione dei nodi! Questo modello `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
spesso presente, perch` permette di realizzare un'operazione asincrona
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pi` garantita, ovvero fornisce una maggiore sicurezza sulla consegna della
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
richiesta!
\end{flushleft}


\begin{flushleft}
Invece, per realizzare una comunicazione sincrona non bloccante:
\end{flushleft}


\begin{flushleft}
$\bullet$ Poll Object: il client non resta in attesa ma vuole comunque il risultato.
\end{flushleft}


\begin{flushleft}
Si fa allora attendere un oggetto al suo posto, che viene interrogato di
\end{flushleft}


\begin{flushleft}
tanto in tanto dal client (che ` sbloccato, e quindi pu` proseguire). Una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
volta che il risultato ` disponibile sull'oggetto poll, il client si preoccupa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di recuperarlo.
\end{flushleft}


\begin{flushleft}
In generale, un oggetto poll ` un oggetto semplice ritagliato su quello
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
specico risultato, e quindi non ` generalizzato. Il mw si preoccupa di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
crearlo in maniera automatica. Come si potrebbe per` gestire il risultato
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
per pi` clienti (utilizzo della trasparenza, servizi di multicast?) oppure
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
pi` interazioni (tanti poll object)?
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
$\bullet$ Call-back Object: ` comunque presente un intermediario, ma si pu` ine
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
serire logica in questo oggetto! Il client infatti pu` specicarlo, e una
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
volta che ha ottenuto il risultato ` l'oggetto stesso ad avvertire il client,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fornendogli il risultato! Questo sistema ` sicuramente pi` complesso e non
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
gestibile direttamente in maniera automatica da un mw, per` fornisce un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
disaccoppiamento maggiore rispetto al poll object! Si pu` infatti inserire
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
un qualunque comportamento in questo oggetto.
\end{flushleft}


\begin{flushleft}
Questi ultimi due modelli son presenti in CORBA, .NET e diversi altri mw.
\end{flushleft}


58





\newpage
5.8





\begin{flushleft}
Pattern per la gestione delle risorse e dei servizi
\end{flushleft}





\begin{flushleft}
Spesso questi pattern rappresentano politiche possibili per il deployment e o la
\end{flushleft}


\begin{flushleft}
congurazione dei vari servizi. I mw possono prevederne pi` di uno, a seconda
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
delle esigenze dell'utenza.
\end{flushleft}


\begin{flushleft}
$\bullet$ Il pattern pi` semplice ` quello delle istanze precongurate: viene deciso
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il deployment presso il server in maniera statica, primache il client possa
\end{flushleft}


`


\begin{flushleft}
eseguire delle richieste. E una politica rigida rispetto ad altre, e si deve
\end{flushleft}


\begin{flushleft}
considerare il fatto che troppe istanze potrebbero ingolfare il sistema. Si
\end{flushleft}


\begin{flushleft}
pu` gestire uno stato? Tutti i client devono essere trattati in maniera
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
uguale, quindi verrebbe da dire di no. . .
\end{flushleft}


\begin{flushleft}
$\bullet$ Attivazione On Demand : esattamente l'opposto, i servitori son dotati di
\end{flushleft}


\begin{flushleft}
stato, e si possono realizzare operazioni diverse a seconda del tipo di client
\end{flushleft}


\begin{flushleft}
che si collega. I servitori son creati by-need, e quindi solo quando sono
\end{flushleft}


\begin{flushleft}
richiesti dal client. Quindi, se una tipologia di servizio non ` richiesta
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
spesso, il suo servitore sar` attivo poco spesso, consumando poche risorse:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
si ha quindi un costo limitato! Questa ` la politica di default di quasi tutti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
i mw, visto il suo costo.
\end{flushleft}


\begin{flushleft}
Si pu` anche decidere di introdurre un tempo di vita per limitare ulterio
\end{flushleft}


\begin{flushleft}
ormente il costo, per cui un servitore non richiesto per un tot di tempo
\end{flushleft}


\begin{flushleft}
viene deallocato.
\end{flushleft}


\begin{flushleft}
Come gestire per` il problema del riferimento remoto? Se per esempio
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
un client ha conoscenza di un riferimento remoto di un oggetto, per cui
\end{flushleft}


\begin{flushleft}
volesse riferirlo direttamente senza utilizzare la procedura d'attivazione,
\end{flushleft}


\begin{flushleft}
ma questo ` stato nel frattempo deallocato? Si avr` un errore, per cui si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dovr` gestire.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Attivazione a singola richiesta: limite estremo, si ha che l'oggetto ` si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
creato al presentarsi di una richiesta, ma anche terminato quando questa
\end{flushleft}


`


\begin{flushleft}
` stata espletata! E quindi un sistema molto reattivo, che per` ha ancora
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
problemi nella rappresentazione dello stato (gli oggetti non sono persistenti!). Questo modello ` quindi utilizzato solo in situazioni in cui lo stato
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
non sia necessario. Per limitare l'overhead e il consumo delle risorse, `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
necessario un controllo sul numero d'istanze attivate.
\end{flushleft}


\begin{flushleft}
$\bullet$ Pool di istanze sempre pronte: si tratta sempre di creare al deployment
\end{flushleft}


\begin{flushleft}
(e quindi in maniera statica) un certo numero di istanze disponibili per
\end{flushleft}


\begin{flushleft}
il client, prima che questo possa fare richiesta. Questo modello quindi
\end{flushleft}


\begin{flushleft}
non presenta nessun costo d'attivazione e disattivazione, ma necessita che
\end{flushleft}


\begin{flushleft}
lo stato sia memorizzato sul client (infatti, sfruttando un meccanismo di
\end{flushleft}


\begin{flushleft}
trasparenza, un client potrebbe non riutilizzare la stessa istanza gi` usaa
\end{flushleft}


\begin{flushleft}
ta!). Vi sono per` problemi di dimensionamento di cui tener conto (se son
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
troppe istanze rispetto al traco, si consumano inutilmente le risorse, se
\end{flushleft}


\begin{flushleft}
invece son poche o si estende il pool, oppure si ` necessaria una coda dove
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
memorizzare le richieste). Si potrebbe ottimizzare per esempio facendo
\end{flushleft}


59





\begin{flushleft}
\newpage
in modo che gni istanza possa gestire pi` di una richiesta, e vericando
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
(monitoring) il numero di istanze contemporanee per ottimizzare.
\end{flushleft}


`


\begin{flushleft}
$\bullet$ Attivazione dal client: E compito invece del client attivare l'istanza, e
\end{flushleft}


`


\begin{flushleft}
diventa lui il responsabile e gestore della risorsa remota. E una logica
\end{flushleft}


\begin{flushleft}
spesso scelta, che garantisce al client di utilizzare un'entit` a lui riservata.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Si ha per` un accoppiamento forte fra C e sessione di lavoro.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Esistono poi pattern per gestire la durata della vita degli oggetti, come il passivation:se un C non accede per un determinato tempo ad una sua risorsa, il
\end{flushleft}


\begin{flushleft}
server potrebbe decidere di farne lo store da qualche parte, e liberarne le risorse
\end{flushleft}


\begin{flushleft}
per altri oggetti. Alla richiesta dell'oggetto, il server si preoccuper` di riattia
\end{flushleft}


\begin{flushleft}
varlo, ricaricando lo stato salvato. Questo pattern ` molto importante per la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
scalabilit` del sistema.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Un pattern simile ` il lease, per cui per` il servitore decide di distruggere le
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
istanze non usate. Perch` resti attivo un oggetto, il client deve presentare entro
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il tempo di lease la richiesta di voler ancora adoperare l'oggetto. Si pu` quindi
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
realizzare usando il tempo di passivation e il tempo di presentazione del lease,
\end{flushleft}


\begin{flushleft}
per far scegliere al server quale politica adottare!
\end{flushleft}


\begin{flushleft}
Il pattern Factory ` un pattern di supporto alla creazione di oggetti: si trate
\end{flushleft}


\begin{flushleft}
ta di un attivatore delle classi, e si pu` pensare di realizzarne uno per nodo,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
in grado di creare tutti gli oggetti considerati necessari. Sfruttando il factory,
\end{flushleft}


\begin{flushleft}
si possono realizzare politiche nascoste per ottimizzare quindi il deployment (a
\end{flushleft}


\begin{flushleft}
tutto pensa lui!).
\end{flushleft}


\begin{flushleft}
Spesso, il tempo di vita di un oggetto ` un qualcosa di molto complesso. Vi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sono quindi dei meccanismi comuni nei mw per valutarne il tempo d'esistenza
\end{flushleft}


\begin{flushleft}
(sfruttando passivation, lease, reference counting, . . . ).
\end{flushleft}





5.9





\begin{flushleft}
I servizi addizionali
\end{flushleft}





\begin{flushleft}
Si tratta di servizi che possono aiutare l'utente ad esprimere determinate operazioni. I servizi infatti possono dipendere dal contesto utilizzato, la sessione, o
\end{flushleft}


\begin{flushleft}
da una serie di eventi che si sono venuti a vericare.
\end{flushleft}


\begin{flushleft}
In particolare, l'Invocation Context ` molto utile: in generale, infatti, i mw
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vengono sviluppati in maniera tale che l'utente non sia costretto a specicare
\end{flushleft}


\begin{flushleft}
nelle sue operazioni parametri di supporto, ma solo quelli necessari per la business logic. Per` pu` capitare che in certi casi questi parametri siano proprio
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
necessari per l'operazione (tipo per realizzare delle transazioni sicure): questo
\end{flushleft}


\begin{flushleft}
pattern si preoccupa di recuperare le informazioni aggiuntive, che formano il
\end{flushleft}


\begin{flushleft}
contesto, e vengono aggiunte alla richiesta mediante un proxy. Si va quindi
\end{flushleft}


\begin{flushleft}
oltre il C/S primitivo, introducendo una separazione dei compiti (client prepara
\end{flushleft}


\begin{flushleft}
la richiesta, proxy aggiunge informazioni di contesto necessarie).
\end{flushleft}





60





\begin{flushleft}
\newpage
La sessione ` un altro pattern per poter fornire un supporto al servitore:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si utilizza per mantenere la specica dell'oggetto remoto, permettendo cos` di
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
creare un thin client.
\end{flushleft}


\begin{flushleft}
Un altro pattern inne ` il call-chain interception: vi sono diversi gestori
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di supporto, i quali possono essere inseriti prima dell'invocazione (quindi, a
\end{flushleft}


\begin{flushleft}
dierenza dell'invocation context, sono dal lato del server), per poter eseguire
\end{flushleft}


\begin{flushleft}
dei compiti specici (per es: in base al tipo della richiesta, decidono il formato
\end{flushleft}


\begin{flushleft}
dei dati per la risposta). Questi intercettori possono anche bloccare l'invoke no
\end{flushleft}


\begin{flushleft}
a quando non hanno terminato il loro compito, creando appunto una catena di
\end{flushleft}


\begin{flushleft}
responsabilit`. Si possono anche combinare (caso tipico: encrypt/decrypt di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
messaggi, introducendo quindi anche catene sul client!).
\end{flushleft}





5.10





\begin{flushleft}
Servizi per la QoS
\end{flushleft}





\begin{flushleft}
Tutti i mw dispongono di servizi per fornire QoS, tranne i MOM. Anche qui, si
\end{flushleft}


\begin{flushleft}
possono riscontrare pattern che si ripetono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Broker : si tratta di un gestore unicato per le connessioni. Viene quindi
\end{flushleft}


\begin{flushleft}
utilizzato per impedire che tutti i server utilizzino le risorse inutilmente,
\end{flushleft}


`


\begin{flushleft}
per esempio. E quindi un front end, in grado di ricevere le richieste dal
\end{flushleft}


\begin{flushleft}
client e attivare (mediante i pattern descritti prima) i server necessari.
\end{flushleft}


\begin{flushleft}
$\bullet$ Life cycle manager : si tratta di un sistema per poter gestire la vita degli
\end{flushleft}


\begin{flushleft}
oggetti ad un livello superiore, applicativo proprio per la QoS (esempio:
\end{flushleft}


\begin{flushleft}
gestione dei nodi, per privilegiare certe entit` rispetto ad altre, passivando
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
server meno prioritari!) Si hanno quindi politiche denibili dierenziate!
\end{flushleft}


\begin{flushleft}
$\bullet$ Custom marshaller : ` un sistema per fornire sistemi dierenziati per la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
presentazione dei dati (XML o formato binario: leggibilit` o ecienza
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


. . . ).


\begin{flushleft}
$\bullet$ Sistema a plug-in: si tratta della possibilit` di estendere il mw, introa
\end{flushleft}


\begin{flushleft}
ducendo dei gestori per azioni particolari di determinati protocolli (per
\end{flushleft}


\begin{flushleft}
esempio, per eseguire certi compiti prima dell'invoke nale).25
\end{flushleft}


\begin{flushleft}
$\bullet$ Il mw pu` anche gestire insiemi/gruppi di oggetti, fornendo quindi un
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
supporto alla replicazione (gruppi diversi, QoS diversa).
\end{flushleft}


\begin{flushleft}
$\bullet$ Presenza di pseudo-oggetti : non sono oggetti veri e propri, ma entit` speca
\end{flushleft}


\begin{flushleft}
icate dal mw, quindi oggetti accedibili normalmente ma che non hanno
\end{flushleft}


\begin{flushleft}
interesse da un punto di vista applicativo (un esempio di pseudo-object
\end{flushleft}


\begin{flushleft}
potrebbe essere il sistema di nomi!).
\end{flushleft}


\begin{flushleft}
25 Possono sembrare simili agli interceptor, ma ` dierente il ruolo: questi son presenti per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la singola invocazione del singolo oggetto, mentre un plugin ` un componente per la parte di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
supporto
\end{flushleft}





61





\newpage
6





\begin{flushleft}
CORBA
\end{flushleft}





\begin{flushleft}
CORBA ` uno standard, specica di un mw, nato dall'idea di mettere a dispoe
\end{flushleft}


\begin{flushleft}
sizione di 440 aziende una possibile soluzione per le loro esigenze!
\end{flushleft}


\begin{flushleft}
Essendo uno standard, quindi solo una specica cartacea, si ha che esistono
\end{flushleft}


\begin{flushleft}
diverse implementazioni (IBM, Java, Orbix, Jacorb, . . . ), ma che rispettando le
\end{flushleft}


\begin{flushleft}
speciche possono anche essere interoperabili fra di loro!
\end{flushleft}


\begin{flushleft}
Un mw deve avere oggetti remoti, invocabili da diversi client su diverse macchine: il sistema di supporto deve essere quindi in grado di ottenere tutti i servizi
\end{flushleft}


\begin{flushleft}
conosciuti da parte del client. Si ha quindi una forte idea di razionalizzazione,
\end{flushleft}


\begin{flushleft}
l'obiettivo ` superare tutti i problemi dell'eterogeneit` (in CORBA: supporto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
per linguaggi ed ambienti diversi, denizione di interfacce per servizi e supporti
\end{flushleft}


\begin{flushleft}
per gli oggetti, . . . ).
\end{flushleft}


\begin{flushleft}
CORBA in particolare basala sua architettura sulla presenza di un broker,
\end{flushleft}


\begin{flushleft}
detto Object Request Broker : ` infatti l'incarnazione di tutta l'architettura,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
perch` fornisce il supporto alla comunicazione, il controllo degli oggetti, facilita
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la comunicazione, ed alloca gli oggetti. . . ), ovvero ` il bus per l'interconnese
\end{flushleft}


\begin{flushleft}
sione!26 Una caratteristica importante degli ORB ` che ` prevista la possibilit`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di coordinarli, grazie alla denizione di uno standard preciso (non dipende quindi dalle varie implementazioni!). In questo modo, tutti i servizi riconosciuti da
\end{flushleft}


\begin{flushleft}
un ORB saranno riconosciuti da un altro, magari introdotto in un secondo
\end{flushleft}


\begin{flushleft}
momento27
\end{flushleft}


\begin{flushleft}
CORBA ` un mw maturo, che presenza diversi servizi: per esempio vi sono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
le common facilities, che sono dei servizi utili per poter aiutare tutte le possibili
\end{flushleft}


\begin{flushleft}
applicazioni, in grado di fornire risposte ad esigenze speciche. Corrisponde in
\end{flushleft}


\begin{flushleft}
tutto e per tutto al terzo livello dei mw.
\end{flushleft}


\begin{flushleft}
I servizi veramente importanti, necessari e presenti in ogni implementazione
\end{flushleft}


\begin{flushleft}
sono gli object (o CORBA) services, che permettono di fornire servizi utili per gli
\end{flushleft}


\begin{flushleft}
oggetti (il loro trasporto, la funzione di narrowing, . . . ). Fra quelle fondamentali
\end{flushleft}


\begin{flushleft}
vi sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ Servizio di nomi : rispetto a quello denito per Java RMI, ` molto pi` coe
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
ordinato, e presenta anche delle varianti. Infatti, oltre al normale servizio
\end{flushleft}


\begin{flushleft}
di nomi (per cui si deve conoscere il nome logico del servizio) vi ` anche la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possibilit` di denire un servizio di trading, che funziona come le pagine
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
gialle, ricercando servizi e non nomi!
\end{flushleft}


\begin{flushleft}
$\bullet$ Event e notication: sono sistemi meno orientati agli oggetti, ma che
\end{flushleft}


\begin{flushleft}
quindi aumentano le capacit` del sistema! Infatti, oltre alla maniera sina
\end{flushleft}


\begin{flushleft}
crona/asincrona bloccante, in questo modo si possono introdurre sistemi
\end{flushleft}


\begin{flushleft}
molto pi` essibili.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
26 Tuttavia, CORBA resta solo una specica: come debba essere fatto il deployment
\end{flushleft}


\begin{flushleft}
dell'ORB ` in realt` a carico delle singole implementazioni
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
27 Questo servizio per esempio ` pi` potente del servizio di nomi dei WS, che ` solo locale
\end{flushleft}


\begin{flushleft}
e u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





62





\begin{flushleft}
\newpage
Altri servizi possono essere specici a determinati domini lavorativi, altri potrebbero invece dipendere dal tipo di applicazione che si sta sviluppando.
\end{flushleft}


\begin{flushleft}
Una caratteristica che ` stata sempre trascurata ` la sicurezza: questa per`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
` introducibile, visto che CORBA prevede la possibilit` di utilizzare degli intere
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ceptor !
\end{flushleft}


\begin{flushleft}
CORBA ` denito da una serie di componenti: oltre all'ORB (uno dei
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
principali), vi sono:
\end{flushleft}


\begin{flushleft}
$\bullet$ L'IDL, ovvero un linguaggio per denire le interfacce dei servizi.
\end{flushleft}


\begin{flushleft}
$\bullet$ Il Portable Object Adapater : si tratta di un sistema per incapsulare gli
\end{flushleft}


\begin{flushleft}
oggetti e per facilitare il compito del gestore (nel trasporto, nel supporto
\end{flushleft}


`


\begin{flushleft}
alla QoS, . . . ). E un sistema che viene aggiunto quindi dal supporto!
\end{flushleft}


\begin{flushleft}
$\bullet$ L'Interface Repository, che ` un sistema simile ad un name server, dove si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possono ritrovare appunto le interfacce dei servizi disponibili.
\end{flushleft}


\begin{flushleft}
$\bullet$ Vi sono quindi dei sistemi per richiamare i servizi in maniera statica e
\end{flushleft}


\begin{flushleft}
dinamica
\end{flushleft}


\begin{flushleft}
$\bullet$ E inne vi sono degli appositi protocolli per la comunicazione ed integrazione fra ORB diversi.
\end{flushleft}





6.1





\begin{flushleft}
L'ORB
\end{flushleft}





\begin{flushleft}
L'ORB ` il cuore del sistema, per comunicare si usa sempre l'ORB. Si potrebbe
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi pensare che ` un collo di bottiglia, ma in realt` la comunicazione presente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
in CORBA ` sempre a {`}grana grossa' (si passano oggetti, servizi pesanti): le
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
operazioni sono quindi consistenti, e la comunicazione si paga. L'ORB aiuta
\end{flushleft}


\begin{flushleft}
fornendo diversi sistemi per facilitare il trasporto della richiesta da parte del
\end{flushleft}


\begin{flushleft}
client al server, e la risposta lungo il percorso opposto. Si tratta, quindi, di base
\end{flushleft}


\begin{flushleft}
di una comunicazione sempre sincrona.
\end{flushleft}


\begin{flushleft}
In particolare, l'ORB gestisce i servitori, preoccupandosi di fare l'allocation
\end{flushleft}


\begin{flushleft}
degli oggetti (` lui che deve trovare il server). In particolare, l'ORB permette
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che un cliente si leghi ad un servizio, non ad un servitore! CORBA ` pensato
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
infatti per essere da supporto ai sistemi legacy: non interessa chi serve, ma
\end{flushleft}


\begin{flushleft}
cosa serve! Fornisce quindi un supporto continuo, e sfrutta tutti i sistemi che
\end{flushleft}


\begin{flushleft}
verranno descritti in seguito (POA, interface repository, . . . ).
\end{flushleft}





6.2





\begin{flushleft}
L'IDL
\end{flushleft}





\begin{flushleft}
Il linguaggio per le interfacce ` fondamentale per poter denire il contratto che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si vuole realizzare (quindi la descrizione di tutti i servizi da orire). Questo
\end{flushleft}


\begin{flushleft}
contratto sar` quindi incorporato nei vari proxy, ovvero sar` poi compilato nei
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
linguaggi specici di implementazione!
\end{flushleft}


`


\begin{flushleft}
E mediante IDL che si stabiliscono tutti i collegamenti necessari, e anche
\end{flushleft}


\begin{flushleft}
l'ORB lo sfrutta per individuare il servizio (si lavora quindi ad un livello pi`
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


63





\begin{flushleft}
\newpage
alto dell'implementazione: l'IDL stesso non ` legato a nessun linguaggio di proe
\end{flushleft}


\begin{flushleft}
grammazione (deriva dal C++ come specica, ma ` diverso)). Una connessione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
statica fa in modo che il proxy del client (lo stub) contenga l'IDL, con cui ci
\end{flushleft}


\begin{flushleft}
si interfaccia all'ORB. Questi cerca il servizio descritto dall'IDL, propone la
\end{flushleft}


\begin{flushleft}
richiesta in maniera adeguata usando un Object Adapter, e riporta quindi la
\end{flushleft}


\begin{flushleft}
risposta al client.
\end{flushleft}


\begin{flushleft}
L'IDL ` fondamentale per realizzare le connessioni statiche 28 , che sono molto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
usate in CORBA (quelle dinamiche, per quanto orano un servizio con maggiore
\end{flushleft}


\begin{flushleft}
QoS, sono molto costose). L'IDL denisce (` solo un sistema dichiarativo! un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sistema perch` il compilatore scelto realizzi quindi uno stub e skeleton statici
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(si pu` sfruttare per realizzare uno skeleton dinamico on the y mediante un'ino
\end{flushleft}


\begin{flushleft}
vocazione dinamica del servizio, aggiungendolo al servitore!). Senza un servizio
\end{flushleft}


\begin{flushleft}
di invocazione dinamico, non si pu` trovare un servizio se non ` stato denito
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un contratto (ovvero, ` stato denito all'interno dell'interface repository!).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
IDL resta per` sempre e solo una specica: sar` sfruttato dai compilatori
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
delle varie implementazioni per creare realmente gli oggetti e i servitori. Infatti,
\end{flushleft}


\begin{flushleft}
serve solo come specica delle operazioni possibili.
\end{flushleft}


\begin{flushleft}
Stub e skeleton son necessari per fare le operazioni di marshalling ed unmarshalling. Si ha che si realizza un diverso proxy (quindi stub e skeleton) per ogni
\end{flushleft}


\begin{flushleft}
interfaccia che si denisce.
\end{flushleft}


\begin{flushleft}
Da ribadire: ` denito un contratto statico fra client e servizio, ma non un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
binding statico fra client e servitore!
\end{flushleft}


\begin{flushleft}
CORBA non ore altro agli utenti: le interfacce sono gli unici oggetti manipolabili e visibili, e quindi quando si programma si riferiscono altre interfacce!
\end{flushleft}


\begin{flushleft}
L'IDL di CORBA denisce in maniera automatica i metodi di accesso alle
\end{flushleft}


\begin{flushleft}
propriet` dell'interfaccia, ed ` in grado di fornire delle informazioni sul coma
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pletamento corretto o meno dell'operazione. Si possono quindi denire (come
\end{flushleft}


\begin{flushleft}
in qualunque altra interfaccia) attributi, operazioni ed eccezioni. Le interfacce
\end{flushleft}


\begin{flushleft}
si possono ereditare, anche in maniera multipla, e si possono raggruppare in
\end{flushleft}


\begin{flushleft}
moduli logici coerenti.
\end{flushleft}


\begin{flushleft}
Di particolare interesse, nei tipi, ` la possibilit` di denire attributi di tipo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ANY : un attributo di tale tipo pu` essere sia un valore che un riferimento. Fono
\end{flushleft}


\begin{flushleft}
damentalmente funziona come da contenitore, in grado di fornire informazioni
\end{flushleft}


\begin{flushleft}
su cosa contiene! Nell'ultima versione di CORBA, 3, si ` stabilito che gli
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
oggetti devono essere passati by-value, in maniera da superare correttamente
\end{flushleft}


\begin{flushleft}
l'eterogeneit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Restano comunque problemi nel realizzare un mapping corretto fra l'IDL e
\end{flushleft}


\begin{flushleft}
i vari linguaggi di implementazione! Per esempio, Java non prevede parametri
\end{flushleft}


\begin{flushleft}
28 IMPORTANTE: per legame statico si intende dire solo l'interfaccia, che viene quindi
\end{flushleft}


\begin{flushleft}
denita in maniera statica. Il binding fra client e servitore non ` statico, qui si specica solo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che i servizi del servitore devono essere specicati in maniera statica
\end{flushleft}





64





\begin{flushleft}
\newpage
di output. Per ovviare a questi problemi, CORBA realizza delle apposite classi dette holder : ` un wrapper che permette di leggere e scrivere in maniera
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
coerente al linguaggio utilizzato realmente. Si possono anche determinare automaticamente altre classi d'aiuto dette helper, in maniera da armonizzare i dati
\end{flushleft}


\begin{flushleft}
rispetto a CORBA (narrowing) e di fornire diverse funzioni di varia utilit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





6.3





\begin{flushleft}
Gli Object Adapter
\end{flushleft}





\begin{flushleft}
Gli adattatori sono diventati dei componenti quasi pi` importanti dell'ORB
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
stesso, visto che sono gli abilitatori del servizio stesso. L'ORB si preoccupa di
\end{flushleft}


\begin{flushleft}
crearlo ed abilitarlo, mediante diverse politiche specicabili.
\end{flushleft}


\begin{flushleft}
A cosa serve quindi? A superare le disomogeneit` e dierenze che vi sono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
fra le varie implementazioni degli ORB, dovute appunto all'eterogeneit` (per
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
esempio, riuscendo a far colloquiare linguaggi non tipati con quelli tipati!).
\end{flushleft}


\begin{flushleft}
Questo sistema permette di disaccoppiare in maniera corretta l'ORB dall'implementazione del servizio stesso: l'ORB lo sfrutta, ma ci pensa l'adattatore a
\end{flushleft}


\begin{flushleft}
richiamarlo in maniera corretta a seconda della sua implementazione. L'adattatore riesce quindi ad integrare pi` componenti scritti in linguaggi diversi! Senza
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
un adattatore, l'ORB non riuscirebbe a raggiungere il proxy del servitore, senza
\end{flushleft}


\begin{flushleft}
avere conoscenza della sua logica implementativa.
\end{flushleft}


\begin{flushleft}
Inizialmente, lo standard prevedeva dei BOA, che erano delle implementazioni pi` semplici. Ora gli adattatori sono in grado di fornire servizi diversi a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
server diversi!
\end{flushleft}





6.4





\begin{flushleft}
L'Interface repository
\end{flushleft}





\begin{flushleft}
Si tratta del luogo dove vengono depositati gli IDL, e quindi da dove si possono
\end{flushleft}


\begin{flushleft}
recuperare le informazioni degli unici servizi utilizzabili nell'architettura!
\end{flushleft}


\begin{flushleft}
Questo sistema non ` utilizzato nella gestione statica dell'architettura, ma
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
in quella dinamica. Infatti, ` ricavando l'IDL dall'IR che si pu` realizzare un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
binding dinamico, e quindi permettere di aggiungere in maniera dinamica dei
\end{flushleft}


\begin{flushleft}
servizi ad un servitore/cliente.
\end{flushleft}


\begin{flushleft}
Un IR pu` essere realizzato in diversi modi, tuttavia ` previsto che ogni
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
interfaccia correttamente compilata ed inserita, venga depositata in un'apposita
\end{flushleft}


\begin{flushleft}
struttura ad albero, in base ai moduli che la contengono.
\end{flushleft}





6.5





\begin{flushleft}
Protocolli per la comunicazione fra ORB
\end{flushleft}





\begin{flushleft}
Inizialmente, CORBA era stato progettato per scambiare dati binari, in maniera
\end{flushleft}


\begin{flushleft}
da ottenere un'ottimizzazione della comunicazione. In seguito si sono introdotte
\end{flushleft}


\begin{flushleft}
estensioni come la possibilit` di lavorare in Internet fra diversi ORB, o anche di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
realizzare comunicazioni fra ORB diversi con protocolli pi` generalizzati.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Il problema di utilizzare ORB diversi ` per` la gestione di riferimenti remoti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
fra ORB diversi ! Il servizio si sa che non ` legato allo specico servitore, quindi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





65





\begin{flushleft}
\newpage
si dovr` trovare un sistema di rendere questi riferimenti globalmente unici (e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
qual'` il loro tempo di vita?).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





6.6





\begin{flushleft}
Cosa ` e cosa non ` CORBA
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





\begin{flushleft}
CORBA ` un sistema pesante, quindi non ha senso utilizzarlo per progetti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
semplici o dove le operazioni son semplici (tipo, settare il valore di una singola
\end{flushleft}


\begin{flushleft}
variabile). CORBA infatti sfrutta risorse a grana grossa, che non si muovono!
\end{flushleft}


\begin{flushleft}
Il problema di CORBA ` infatti che se l'ORB non funziona (o la macchina che
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
lo contiene non ` raggiungibile) tutta l'architettura ` oine!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
CORBA non ` un ambiente di linguaggio, cio` non crea lui gli oggetti. L'ate
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tivazione degli oggetti, la loro politica di gestione ` tutta a carico degli Object
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Adapter, che variano in base all'implementazione! Non vi ` quindi uno stane
\end{flushleft}


\begin{flushleft}
dard, ` il POA a decidere come/se salvare lo stato, . . . Infatti, i servant sono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
delle entit` passive, a cui il POA porta la richiesta del client e da cui richiede
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
la risposta corrispondente!
\end{flushleft}


\begin{flushleft}
CORBA fondamentalmente richiede la presenza di un riferimento remoto
\end{flushleft}


\begin{flushleft}
per poter lavorare: le funzioni base di CORBA sono quindi quelle di gestione e
\end{flushleft}


\begin{flushleft}
comunicazione dei riferimenti remoti (trasformazione da/a stringa).
\end{flushleft}





6.7





\begin{flushleft}
Confronto fra Java e CORBA, e sua evoluzione
\end{flushleft}





\begin{flushleft}
I due sistemi sono abbastanza compatibili, proprio perch` hanno obiettivi diversi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(Web invece che integrazione di sistemi legacy) e lavorano utilizzando risorse
\end{flushleft}


\begin{flushleft}
diverse (a grana ne vs grana grossa).
\end{flushleft}


\begin{flushleft}
CORBA ha subito diverse evoluzioni, guidate dalle esigenze delle varie aziende.
\end{flushleft}


\begin{flushleft}
Ogni evoluzione ha mantenuto i sistemi e gli oggetti gi` introdotti, cercando di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
estendere i concetti gi` introdotti (introducendo nuovi linguaggi, aumentando i
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
servizi, . . . ). Per esempio, CORBA 3 introduce altri sistemi di comunicazione
\end{flushleft}


\begin{flushleft}
oltre alla maniera sincrona bloccante.
\end{flushleft}





6.8





\begin{flushleft}
Invocazione statica
\end{flushleft}





`


\begin{flushleft}
E il modello base, ed ` anche quello maggiormente utilizzato: permette solo una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comunicazione di tipo sincrona bloccante29 . Si basa sull'utilizzo di due diversi
\end{flushleft}


\begin{flushleft}
proxy dal lato del client e del server (stub e skeleton). L'attivazione del servitore
\end{flushleft}


\begin{flushleft}
per` ` dinamica: se non ` presente, il POA si preoccupa di attivarlo.
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
L'invocazione statica bloccante ` quella che costa di meno (semantica ate
\end{flushleft}


\begin{flushleft}
most-once), per` pu` anche essere molto limitante. Questo perch` i client e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
i servant devono avere gi` deciso i proxy in maniera statica, e quindi anche i
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
servizi! Tutto prima dell'esecuzione!
\end{flushleft}


\begin{flushleft}
Inizialmente si era introdotta anche un altra modalit`, detta one-way, ma `
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
deprecata (semantica best-eort, senza possibilit` di introdurre QoS).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
29 Da ricordare che statico non signica che il client ` legato allo specico servant, ma che il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
contratto ` deciso prima dell'esecuzione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





66





\newpage
6.9





\begin{flushleft}
Compiti e politiche di un adattatore
\end{flushleft}





\begin{flushleft}
Non ` un componente CORBA, ma che dipende dalle varie implementazioni:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
il loro compito ` quello di dialogare con il servant, il quale si registra presso
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'adattatore corrispondente. In un certo senso, quindi, fanno le veci di un sistema
\end{flushleft}


\begin{flushleft}
di nomi, fornendo ai servant anche le risorse dinamiche necessarie.
\end{flushleft}


\begin{flushleft}
La semantica degli adattatori ` sempre sincrona. Vi sono diverse modalit`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
d'attivazione iniziali:
\end{flushleft}


\begin{flushleft}
$\bullet$ Thread per request: per ogni richiesta l'adattatore30 si preoccupa di creare
\end{flushleft}


\begin{flushleft}
un thread, quindi si ha una creazione by-need. Ha quindi un costo abbastanza elevato.
\end{flushleft}


\begin{flushleft}
$\bullet$ Pool di thread : I thread sono pre-creati, in maniera da ridurre il costo
\end{flushleft}


\begin{flushleft}
d'attivazione (consumano poche risorse se non lavorano). Si deve quindi
\end{flushleft}


\begin{flushleft}
prevedere una coda delle richieste, per poter associare ad ogni richiesta un
\end{flushleft}


\begin{flushleft}
suo thread.
\end{flushleft}


\begin{flushleft}
Si potrebbe realizzare un pool dinamico, in grado quindi di estendere la
\end{flushleft}


\begin{flushleft}
sua dimensione in base all'esigenze che si riscontrano durante l'esecuzione.
\end{flushleft}


\begin{flushleft}
Il costo ` pi` limitato, ma aumenta il tempo d'attesa.
\end{flushleft}


\begin{flushleft}
e u
\end{flushleft}


\begin{flushleft}
$\bullet$ Thread per sessione: ` un sistema per fornire un maggiore accoppiamene
\end{flushleft}


\begin{flushleft}
to. Si trasferisce infatti la responsabilit` sul client, permettendogli quina
\end{flushleft}


\begin{flushleft}
di di battere sullo stesso servant rispetto alla sessione. Si hanno quindi delle richieste sequenzializzate. Questo sistema limita ulteriormente il
\end{flushleft}


\begin{flushleft}
parallelismo.
\end{flushleft}


\begin{flushleft}
$\bullet$ Thread per servant: ogni oggetto viene incapsulato in un singolo servant,
\end{flushleft}


\begin{flushleft}
per cui si limita ulteriormente la parallelizzazione. Prima di poter servire
\end{flushleft}


\begin{flushleft}
un'ulteriore richiesta, il servant deve concludere la richiesta precedente.
\end{flushleft}


\begin{flushleft}
Si hanno dei problemi da considerare nel caso di ORB distribuiti: infatti, si
\end{flushleft}


\begin{flushleft}
immagini che si passi un riferimento remoto ad un client da un ORB diverso,
\end{flushleft}


\begin{flushleft}
utilizzando come modello il thread per sessione. CORBA dice che ` possibile
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mantenere le stesse politiche anche se si passa il riferimento all'esterno, ma
\end{flushleft}


\begin{flushleft}
in realt` si potrebbe avere che un client diverso utilizzi delle politiche diverse
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
(potrebbe non essere necessario, per limitare i costi, costringere il client ad utilizzare lo stesso servant). Si hanno cos` meno garanzie (non mantengo la stessa
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
politica), ma si ottengono anche dei costi limitati. Si potrebbero anche avere
\end{flushleft}


\begin{flushleft}
politiche diverse fra ORB, dovuto tutto ad implementazioni diverse!
\end{flushleft}


\begin{flushleft}
Gli adattatori devono quindi garantire certte funzionalit`, e nel corso del
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
tempo ` diventato sempre pi` un componente centrale dell'architettura. Cone
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
trollano l'esecuzione delle operazione, forniscono un sistema per cui l'ORB non
\end{flushleft}


\begin{flushleft}
si preoccupi realmente dell'implementazione, ma per cui pu` semplicemente
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


`


\begin{flushleft}
portare la richiesta al servant e riportarne indietro la risposta. E il POA a
\end{flushleft}


\begin{flushleft}
30 Sono
\end{flushleft}





\begin{flushleft}
gli adattatori che devono fornire le politiche!
\end{flushleft}





67





\begin{flushleft}
\newpage
decidere quindi le politiche d'attivazione e il numero di servant necessari per
\end{flushleft}


\begin{flushleft}
l'esecuzione!
\end{flushleft}


\begin{flushleft}
Inizialmente si aveva i BOA: questi erano legati a poche interfacce, e ad un
\end{flushleft}


\begin{flushleft}
unico ambiente di linguaggio. I POA sono un'estensione, aggiungendo funzionalit`, potendo interagire con servant dotati di interfacce e linguaggi diversi: da
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
qui la denizione di portable! Non abbiamo infatti una chiara indicazione della
\end{flushleft}


\begin{flushleft}
sua locazione.
\end{flushleft}


\begin{flushleft}
CORBA ` stato il primo standard che ha cercato di realizzare un sistema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
mw per gli oggetti attivi: un riferimento ` quindi in grado di puntare potenziale
\end{flushleft}


\begin{flushleft}
mente a pi` oggetti: un POA riceve il riferimento e deve accedere all'oggetto
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
desiderato. In generale, meno POA son presenti e meglio `: infatti, le varie
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
implementazioni forniscono un POA di base, che contiene tutte le politiche di
\end{flushleft}


\begin{flushleft}
gestione gi` denite. Un suo glio non eredita direttamente tutte le politiche, ma
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
deve essere specicato quali politiche si vogliono attivate: abbiamo quindi in realt` un gestore per i POA, che stabilisce per ogni POA quante e quali politiche
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
debba implementare (attiva/disattiva i POA, blocca/scarta le richieste per i
\end{flushleft}


\begin{flushleft}
POA). Si potrebbe permettere all'utente di modicare dinamicamente l'active
\end{flushleft}


\begin{flushleft}
object map, ma ` fatto di rado.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Essendo il responsabile dell'oggetto, il POA ` responsabile anche del suo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
riferimento. Deve essere in grado quindi di denirlo, identicare gli oggetti in
\end{flushleft}


\begin{flushleft}
base all'ID proposto e gestire i servant. In particolare, deve riuscire a distinguere
\end{flushleft}


\begin{flushleft}
fra oggetti transienti e quelli persistenti.
\end{flushleft}


\begin{flushleft}
Quali sono quindi le politiche d'attivazione per gli oggetti? Possiamo avere:
\end{flushleft}


\begin{flushleft}
$\bullet$ Explicit Object Activation: ` tutto a carico del client
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Single servant: viene attivato un servant per ogni richiesta, uno solo.
\end{flushleft}


\begin{flushleft}
$\bullet$ On demand : sono le politiche per poter scegliere i servant in base alle richieste specicate. Se si tratta di un singolo metodo non vi ` stato, altrimene
\end{flushleft}


\begin{flushleft}
ti si tratta di On-demand per una durata indenita. Una caratteristica
\end{flushleft}


\begin{flushleft}
particolare ` che le politiche si possono combinare!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





6.10





\begin{flushleft}
Binding dinamico
\end{flushleft}





\begin{flushleft}
Avendo a disposizione prima le interfacce, si possono implementare direttamente client e servant. Tuttavia, ` mediante l'invocazione dinamica con cui
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
si possono aggiungere nuovi servizi durante l'esecuzione. L'alternativa sarebbe
\end{flushleft}


\begin{flushleft}
dover spegnere il sistema, e ricongurare il tutto. La dinamicit` si basa sull'uso
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dell'IR, e permette di introdurre in CORBA altri modelli di comunicazione oltre
\end{flushleft}


\begin{flushleft}
al sincrono bloccante.
\end{flushleft}


\begin{flushleft}
Si vuole quindi chiedere o fornire un servizio senza avere il proxy/skeleton
\end{flushleft}


`


\begin{flushleft}
gi` pronto. E un problema di tutti i mw.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Nel caso del client, si parla di Dinamyc Invocation Interface. Si realizza un
\end{flushleft}


\begin{flushleft}
oggetto che funziona come il proxy che si avrebbe avuto in maniera statica. Si ha
\end{flushleft}


68





\begin{flushleft}
\newpage
quindi un oggetto Request, che ` uno pseudo-object 31 , che permette di specicare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
una richiesta dinamica. Si tratta quindi di un contenitore fornito dall'ambiente,
\end{flushleft}


\begin{flushleft}
per cui un client eettua una invoke, e l'ORB utilizza il servant giusto per
\end{flushleft}


\begin{flushleft}
richiamare l'operazione e fornire il risultato. Si potrebbero realizzare tutte le
\end{flushleft}


\begin{flushleft}
operazioni dinamiche, ma hanno un costo molto elevato! Tuttavia, vi sono
\end{flushleft}


\begin{flushleft}
diversi modi per ottenere il risultato, non solo in maniera sincrona bloccante
\end{flushleft}


\begin{flushleft}
(utilizzando la GetAnswer), realizzando quindi delle operazioni maggiormente
\end{flushleft}


\begin{flushleft}
disaccoppiate. Si deniscono quindi la:
\end{flushleft}


\begin{flushleft}
$\bullet$ Send-deferred per realizzare un sistema sincrono non bloccante. Si utilizza
\end{flushleft}


\begin{flushleft}
un sistema basato su un oggetto poll-response.
\end{flushleft}


\begin{flushleft}
$\bullet$ Send-one-way invece per avere una comunicazione asincrona.32
\end{flushleft}


\begin{flushleft}
Ma come funziona? L'oggetto Request,opportunatamente costruito dal client
\end{flushleft}


\begin{flushleft}
(dati, eccezioni, . . . ), passa per l'IR, sfruttandolo proprio come un name server: lo interroga per sapere quale servant possiede quel servizio (quindi non si
\end{flushleft}


\begin{flushleft}
richiede che il servant sia dinamico!). Quindi, l'oggetto Request deve essere particolarizzato in maniera opportuna dall'utente, in maniera da ottenere l'oggetto
\end{flushleft}


\begin{flushleft}
desiderato (ridotta trasparenza!).
\end{flushleft}


\begin{flushleft}
CORBA introduce anche la possibilit` di estendere dinamicamente i servizi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
oerti da un servant (` meno utilizzato). Come fare ci` in realt` non ` spiegato
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(si potrebbero attivare in maniera dinamica): CORBA si preoccupa di standardizzare le interfacce. Se si avesse un sistema solo statico, si avrebbe che si
\end{flushleft}


\begin{flushleft}
dovrebbe spegnere il sistema e aggiornare staticamente i servant.
\end{flushleft}


\begin{flushleft}
Nel modello dinamico (Dinamyc Skeleton Interface) si ha invece che ` pree
\end{flushleft}


\begin{flushleft}
sente un altro tipo di pseudo-object detto ServerRequest, mediante il quale si pu`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
specicare le operazioni, parametri e contesti da aggiungere! L'idea ` che queste
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
informazioni si debbano agganciare ad un'interfaccia che esiste gi`. Quindi, ci
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
si collega all'IR per ottenere un'implementazione gi` presente, e ci si registra
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
presso l'IR come sistema in grado di rispondere (il servant si potr` usare sia in
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
richieste statiche che dinamiche!).
\end{flushleft}





6.11





\begin{flushleft}
Politiche dei riferimenti di CORBA
\end{flushleft}





\begin{flushleft}
CORBA si basa totalmente sull'uso degli ObjRef. CORBA fornisce quindi dei
\end{flushleft}


\begin{flushleft}
sistemi/funzionalit` di base (per realizzare un primo supporto, da estendere a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
seconda della QoS desiderata) per trattare in maniera opportuna i riferimenti
\end{flushleft}


\begin{flushleft}
(da string a riferimento o viceversa, funzioni di narrowing, duplicazione/release
\end{flushleft}


\begin{flushleft}
dell'oggetto). Gli ObjRef sono opachi e gestibili solo dall'ORB.
\end{flushleft}


\begin{flushleft}
La politica per` che persegue CORBA ` che il riferimento punti al servizio,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
non al servitore: tuttavia, questa logica potrebbe non essere quella desiderata dal programmatore (si vorrebbe poter accedere sempre allo stesso servant
\end{flushleft}


\begin{flushleft}
31 Si tratta di facilitatori, connati solo nell'ORB. Non si possono quindi riferire da CORBA,
\end{flushleft}


\begin{flushleft}
e non possiedono helper o holder
\end{flushleft}


\begin{flushleft}
32 Qual'` il problema di lavorare in maniera dinamica? E che si possono avere errori a
\end{flushleft}


`


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
run-time, che sono pi` dicili da gestire!
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}





69





\begin{flushleft}
\newpage
sico). Ma quindi questi riferimenti non sono univoci: localmente si potrebbe
\end{flushleft}


\begin{flushleft}
anche puntare ad oggetti diversi, realizzando quindi incomprensioni e problemi
\end{flushleft}


\begin{flushleft}
(specialmente lato server)!
\end{flushleft}


\begin{flushleft}
In CORBA 2 si ` quindi introdotta la possibilit` di puntare ad uno servant
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
specico, introducendo quindi un sistema per denire dei nomi univoci !
\end{flushleft}





6.12





\begin{flushleft}
Interoperabilit` fra ORB
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
Per poter realizzare le comunicazioni fra ORB diversi, si ` dovuto quindi reale
\end{flushleft}


\begin{flushleft}
izzare degli ObjRef interoperabili : questi sono gli IOR. Hanno un costo pesante
\end{flushleft}


\begin{flushleft}
a livello di implementazione, soprattutto perch` una volta stabilito, deve essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
valido in eterno!
\end{flushleft}


\begin{flushleft}
Gli IOR facilitano le gestioni degli ORB: si ha che se si registrano client/server
\end{flushleft}


\begin{flushleft}
e si vogliano riferire in remoto attraverso una rete di ORB, si denisce uno IOR
\end{flushleft}


\begin{flushleft}
sempre valido. In generale adesso gli oggetti in CORBA non sono mai deallocati
\end{flushleft}


\begin{flushleft}
automaticamente (potrebbe farlo), ma ` tutto a carico dell'utente. Se si utilizza
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
uno IOR!`, l'oggetto deve essere sempre presente!
\end{flushleft}


\begin{flushleft}
Uno IOR ` costituito da una serie di informazioni per renderlo univoco: il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
nome/indirizzo del nodo su cui risiede, un timestamp, il nome del POA che lo ha
\end{flushleft}


\begin{flushleft}
creato ed altre informazioni. Si realizza quindi in generale uno IOR incapsulando
\end{flushleft}


\begin{flushleft}
in maniera opportuna un ObjRef.
\end{flushleft}


\begin{flushleft}
Caratteristica importante degli IOR ` che non ` detto che puntino direte
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tamente ad un adattatore, ma possono anche riferire invece un altro repository, ovvero quello degli oggetti implementati! Si ha quindi la possibilit` di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
denire un legame indiretto oltre a quello diretto: la dierenza sostanziale `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che l'oggetto riferito indirettamente ` veramente permanente, mentre riferene
\end{flushleft}


\begin{flushleft}
dolo direttamente si hanno pi` gradi di libert`, un collegamento maggiormente
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
lasco. L'ObjId di uno IOR riferisce quindi il servizio sicuramente, ma non `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
detto l'oggetto.
\end{flushleft}





6.13





\begin{flushleft}
Gli interceptor in CORBA
\end{flushleft}





\begin{flushleft}
Sono deniti come negli altri mw, ovvero ` un sistema per poter denire dei come
\end{flushleft}


\begin{flushleft}
ponenti che devono essere attivati prima o dopo l'esecuzione di una determinata
\end{flushleft}


\begin{flushleft}
richiesta (per introdurre per esempio un sistema di sicurezza). Gli interceptor
\end{flushleft}


\begin{flushleft}
son pensati per poter lavorare a diversi livelli (applicativo, trasporto, . . . ).
\end{flushleft}





6.14





\begin{flushleft}
Estensibilit` di CORBA
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
CORBA ` pensato per essere facilmente estensibile. In particolare, CORBA
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
3 introduce l'uso di componenti, la possibilit` di denire QoS, e un supporto
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
anche ad Internet come ambiente di lavoro.
\end{flushleft}


\begin{flushleft}
I componenti non sono altro che degli oggetti inseriti in un apposito contenitore, ed inseriti in un apposito ambiente d'esecuzione, detto engine. Il servizio
\end{flushleft}


\begin{flushleft}
di questi componenti ` quindi fornito soltanto nell'ambito del container stesso,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





70





\begin{flushleft}
\newpage
sfruttando delle politiche di default denite proprio dal contenitore. Un esempio
\end{flushleft}


\begin{flushleft}
di componente di questo genere sono gli EJB.
\end{flushleft}


\begin{flushleft}
I componenti sono un fattore trainante per ottenere una base d'utenza sempre pi` ampia: aumenta la possibilit` di adattare il sistema alle proprie esigenze.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Con CORBA 3 in particolare si ` intodotto il sistema dell'Asinchronous
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Method Invocation, che ` un ulteriore modo per denire una comunicazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sincrona non bloccante: il cliente non deve attendere quindi per il risultato.
\end{flushleft}


\begin{flushleft}
Si ottiene cambiando solo l'interfaccia, per cui si delega un altro oggetto per
\end{flushleft}


\begin{flushleft}
attendere la risposta, separando la fase di richiesta da quella callback. Tuttavia,
\end{flushleft}


\begin{flushleft}
` necessario che sia il cliente a specicare il codice della callback da eseguire.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Inoltre, si pu` anche denire che il client recuperi il risultato usando un pollo
\end{flushleft}


\begin{flushleft}
object. Nel caso di call-back quindi si utilizza un sistema di re and forget. In
\end{flushleft}


\begin{flushleft}
entrambi i casi si lavora solo dal lato del client, per estendere la funzionalit`.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Il servant continua a lavorare in maniera sincrona bloccante! Ci` che cambia
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
oltre a chi richiama il metodo (nel primo caso ` l'ORB, nel secondo ` il client),
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'interfaccia ` leggermente diversa: nel poll i parametri necessari sono di out!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Questo genere di interazione ` molto diusa, perch` permette di richiedere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
contemporaneamente molte {`}istruzioni'.
\end{flushleft}





6.15





\begin{flushleft}
Servizi gi` presenti in CORBA
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
Come gi` detto, CORBA fornisce diversi servizi gi` utilizzabili.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Per esempio, per realizzare un servizio di nomi si possono usare il naming
\end{flushleft}


\begin{flushleft}
service gi` presente, oppure addirittura un trading service. La dierenza fra
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
i 2 sistemi ` che il name service permette di categorizzare i servizi in base ad
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un nome logico (si fornisce il nome logico, si ottiene il riferimento al servizio),
\end{flushleft}


\begin{flushleft}
mentre il trading service fornisce un sistema simile a quello delle pagine gialle,
\end{flushleft}


\begin{flushleft}
per cui i servizi sono catalogati in base al loro contenuto. In questo caso si
\end{flushleft}


\begin{flushleft}
ricerca quindi per chiavi: a default vengono forniti tutti i servizi, ma vi ` la
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possibilit` di ltrare i risultati, per ridurne il numero.33
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
In entrambi i casi si pu` pensare (a dierenza di Java RMI) di realizzare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
dei sistemi federati, ovvero una gerarchia di name o trader server federati, in
\end{flushleft}


\begin{flushleft}
maniera di essere coordinati!
\end{flushleft}


\begin{flushleft}
Un altro servizio che viene fornito ` quello di poter lavorare ad eventi e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
notiche: questi infatti non sono strumenti propriamente tipici del modello ad
\end{flushleft}


\begin{flushleft}
oggetti, che possono essere sfruttati per realizzare facilmente architetture con
\end{flushleft}


\begin{flushleft}
molti clienti e produttori; non ` quindi P2P, ma una comunicazione molti a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
molti.
\end{flushleft}


\begin{flushleft}
CORBA stabilisce delle apposite interfacce, denendo mediante ognuna il
\end{flushleft}


\begin{flushleft}
modo di comunicare (push dal produttore, pull dal consumatore, . . . ). Si
\end{flushleft}


\begin{flushleft}
denisce un canale come oggetto di delega, per poter inviare i messaggi ai
\end{flushleft}


\begin{flushleft}
33 Non
\end{flushleft}





\begin{flushleft}
si ricercano ovviamente interfacce, perch` presenti sull'IR
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





71





\begin{flushleft}
\newpage
client, o fare polling ai supplier. Un client si registra quindi al canale, e da
\end{flushleft}


\begin{flushleft}
quel momento comincia a ricevere gli eventi.
\end{flushleft}


\begin{flushleft}
Di solito, non ` noto chi ` che genera l'evento, ` trasparente al consumatore.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Gli eventi sono non persistenti, senza qualit`, e senza possibilit` di ltraggio: si
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ha che quindi la maniera pi` comoda per lavorare ` il sistema push, e per avere
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
QoS conviene utilizzare il notication service, che ` in grado di fornire qualit`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e persistenza!
\end{flushleft}





7





\begin{flushleft}
COM, DCOM e .NET
\end{flushleft}





\begin{flushleft}
Nell'architettura Microsoft, la GUI ` sempre stata fondamentale (la nestra non
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
` solo un elemento graco, ma ` tutto ci` a cui ` costruito attorno il sistema;
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
l'interazione fra i processi ` guidata dalle nestre!). E da loro che ` nata l'idea
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di dinamyc library, cio` di una libreria che si potesse caricare solo su bisogno:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
idea molto dinamica, che per` richiede il costo del caricamento.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Ma quindi, visto che le DLL si possono caricare/scaricare a piacimento, i
\end{flushleft}


\begin{flushleft}
processi non possono avere uno stato, specialmente se condividono codice, cos`
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
da aumentare al massimo la condivisibilit`. Il kernel Microsoft ` un microa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
kernel, proprio sfruttando le DLL (si caricano sempre e solo quelle necessarie).
\end{flushleft}


\begin{flushleft}
Si utilizza un sistema di conteggio dei riferimenti per decidere se deallocare una
\end{flushleft}


\begin{flushleft}
DLL.
\end{flushleft}


\begin{flushleft}
Le DLL sono quindi ascrivibili in 3 diversi gruppi: kernel, utente (windowing) e GUI. Il sistema ` per` facilmente estendibile, potendo introdurre nuove
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
DLL (es, WinSocket).
\end{flushleft}


\begin{flushleft}
Nei sistemi operativi Microsoft tutti i tipi di oggetti (sia utente che kernel)
\end{flushleft}


\begin{flushleft}
possiedono degli appositi handler per riferirli ed identicarli, in maniera tale da
\end{flushleft}


\begin{flushleft}
poterli utilizzare anche con le apposite API di Windows. A dierenza di Unix,
\end{flushleft}


\begin{flushleft}
l'interfaccia per richiamare gli oggetti non ` molto compatta, risultando essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
molto complessa.
\end{flushleft}


\begin{flushleft}
Windows fa un uso pesante del modello ad eventi (il sistema graco fa un
\end{flushleft}


\begin{flushleft}
buon match con ci`). Si tratta di un modello fortemente push (all'epoca era
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
anche l'unico modello esistente per lavorare quando non si avevano ancora i
\end{flushleft}


\begin{flushleft}
processi). Gli eventi vengono usati ancora anche a livello applicativo: a livelli
\end{flushleft}


\begin{flushleft}
inferiori risultano essere molto pi` essibili, sfruttando il modello a call-back:
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
l'applicazione fornisce un handler/funzione da richiamare nel caso si presenti
\end{flushleft}


\begin{flushleft}
l'evento alla DLL opportuna34 . L'evento ` lanciato da una qualunque intere
\end{flushleft}


\begin{flushleft}
azione dell'utente o presso una periferica esterna, e viene lanciato a tutti quelli
\end{flushleft}


\begin{flushleft}
che lo necessitano (ogni programma ha una sua coda per gli eventi).
\end{flushleft}


\begin{flushleft}
Un'altra tecnologia importante introdotta dalla Microsoft ` il cosidetto Obe
\end{flushleft}


\begin{flushleft}
ject Linking and Embedding, per cui si vuole gestire le applicazioni in maniera
\end{flushleft}


\begin{flushleft}
34 Quindi
\end{flushleft}





\begin{flushleft}
ogni nestra registra per ogni evento un possibile handler!
\end{flushleft}





72





\begin{flushleft}
\newpage
integrata. L'idea ` quella di suddividere correttamente i compiti fra il docue
\end{flushleft}


\begin{flushleft}
mento ed il gestore del documento. Ogni tipologia di documento, infatti, ha un
\end{flushleft}


\begin{flushleft}
proprio gestore che viene richiamato all'atto del caricamento del documento.
\end{flushleft}


\begin{flushleft}
Tuttavia, un documento pu` essere fatto di diverse parti, ovvero di altri
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
documenti: si deve quindi anche caricare il gestore degli altri documenti di cui
\end{flushleft}


\begin{flushleft}
` composto. In particolare si pu` avere che:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ Il documento contiene un riferimento all'altra tipologia di documento,
\end{flushleft}


\begin{flushleft}
ovvero si fa linking
\end{flushleft}


\begin{flushleft}
$\bullet$ Il documento contiene proprio una copia dell'altro documento, ovvero si
\end{flushleft}


\begin{flushleft}
fa embedding. Quest'ultimo caso non ` realizzabile direttamente con il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
modello ad oggetti!
\end{flushleft}


\begin{flushleft}
Mediante questa tecnologia si pu` quindi attivare un'applicazione all'interno
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
dell'altra: vi possono essere problemi di duplicazione dell'oggetto o la presenza
\end{flushleft}


\begin{flushleft}
di riferimenti multipli e di molteplici gestori della stessa tipologia di documento
\end{flushleft}


\begin{flushleft}
(quanti ne attiviamo?). Tuttavia, nel concentrato non presenta grossi problemi
\end{flushleft}


\begin{flushleft}
e funziona bene.
\end{flushleft}


\begin{flushleft}
L'idea della Microsoft era per` quella di estendere il concetto di OLE anche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
al distribuito, da qui la tecnologia COM. Nel concentrato era tutto pi` semplice
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
perch` si sfruttava il registry di Windows per identicare in maniera univoca un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
oggetto35 , e per poter registrare quindi i vari gestori.
\end{flushleft}





7.1





\begin{flushleft}
Architettura COM
\end{flushleft}





\begin{flushleft}
COM ` stato il sistema standard per la Microsoft per poter descrivere l'intere
\end{flushleft}


\begin{flushleft}
azione fra processi diversi, utilizzando come base i componenti e una comunicazione C/S sincrona. Si pu` notare la dierenza con i precedenti modelli: nei
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sistemi precedenti la comunicazione si basava soprattutto sul modello ad eventi,
\end{flushleft}


\begin{flushleft}
che ` molto lontano dalla comunicazione sincrona!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Lo standard denisce delle speciche per cui i componenti siano in grado
\end{flushleft}


\begin{flushleft}
di comunicare fra di loro, in maniera indipendente dal linguaggio utilizzato e
\end{flushleft}


\begin{flushleft}
dalle applicazioni che li usano. L'idea ` quella di introdurre una uniformit` nel
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
comportamento: dll, componenti su macchine diverse, . . . Si ottiene cos` omo\i{}
\end{flushleft}


\begin{flushleft}
geneit` a livello di comportamento fra oggetto locale e remoto, introducendo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
cos` trasparenza. In particolare, si utilizzano metodi standard per la comuni\i{}
\end{flushleft}


\begin{flushleft}
cazione remota, come RPC di DCE.
\end{flushleft}


\begin{flushleft}
Alla base di COM vi ` l'uso delle interfacce: un componente, per poter
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
essere usato, deve fornire un'interfaccia comune e conosciuta da tutti gli attori. L'interfaccia infatti denisce la visione logica. Tutte le interfacce COM
\end{flushleft}


\begin{flushleft}
derivano da una stessa interfaccia detta IUnknown. In COM ogni oggetto e ogni
\end{flushleft}


\begin{flushleft}
interfaccia possono essere identicati in maniera univoca da dei GUID, che per`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
distinguono anche fra componenti ed interfacce.
\end{flushleft}


\begin{flushleft}
35 Sfruttando il GUID, derivato dall'UUID descritto dal DCE. In Microsoft, i diversi GUID
\end{flushleft}


\begin{flushleft}
son classicati in base al tipo di oggetti che riferiscono (interfacce, classi, . . . )
\end{flushleft}





73





\begin{flushleft}
\newpage
L'interfaccia funziona semplicemente come un puntatore alle funzioni che descrive, contenute in una virtual method table: ogni entry di questa tabella punta
\end{flushleft}


\begin{flushleft}
al codice che i metodi devono implementare. In COM non esiste l'ereditariet`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a livello di classe ma solo (anche multipla) a livello di interfacce. Si ha quindi
\end{flushleft}


\begin{flushleft}
un grafo che rappresenta l'ereditariet`, che spesso ` dicile da navigare! I nomi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
univoci sono infatti tutti registrati nel registry, a seconda della loro applicazione.
\end{flushleft}


\begin{flushleft}
L'interfaccia IUnknown presenta solo 3 metodi (presenti sempre nei primi
\end{flushleft}


\begin{flushleft}
3 slot di ogni VMT di ogni componente): uno per aggiungere un riferimento
\end{flushleft}


\begin{flushleft}
all'oggetto, uno per farne il release, e inne un QueryInterface. Quest'ultimo `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fondamentale per poter interagire con l'oggetto stesso: prende infatti il GUID e
\end{flushleft}


\begin{flushleft}
verica se esiste un oggetto che implementi quell'interfaccia. In caso aermativo,
\end{flushleft}


\begin{flushleft}
si preoccupa di restituire un puntatore all'interfaccia corrispondente. Questo `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un metodo pervasivo, ` l'unico modo con cui accedere ai diversi metodi. Gli
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
altri infatti sono utilizzati per gestire le risorse in maniera dinamica.
\end{flushleft}


\begin{flushleft}
La deallocazione degli oggetti pu` essere decisa: o si utilizza un garbage colo
\end{flushleft}


\begin{flushleft}
lector, oppure si utilizza il sistema del reference counting, oppure si pu` anche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
non gestire! Si pu` quindi osservare una dierenza rispetto a CORBA: qui `
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
necessario vedere come avviene l'interazione di basso livello! Si deve per forza
\end{flushleft}


\begin{flushleft}
passare per il metodo QueryInterface.
\end{flushleft}


\begin{flushleft}
In COM vi ` quindi solo l'ereditariet` in base alle interfacce: questo perch`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
l'ereditariet` all'epoca era vista come un sistema troppo accoppiante, e quindi da
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
limitare. Infatti, ereditando solo le interfacce non si eredita l'implementazione
\end{flushleft}


\begin{flushleft}
ed eventuali comportamenti non desiderati. Fondamentalmente, l'ereditariet`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
rompeva il principio dell'incapsulamento (la classe derivata infatti pu` accedere
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
alla classe base)!
\end{flushleft}


\begin{flushleft}
COM quindi introduce due metodi alternativi per poter estendere una classe:
\end{flushleft}


\begin{flushleft}
aggregazione o delegazione. In ogni modo, un oggetto non implementa tutti i
\end{flushleft}


\begin{flushleft}
metodi che la sua interfaccia espone, ma {`}ridirige' la richiesta di controllo ad
\end{flushleft}


\begin{flushleft}
oggetti che implementano quei metodi (in un qualche modo li incapsula).
\end{flushleft}


\begin{flushleft}
La delegazione indica che fra gli oggetti vi deve essere una condivisione
\end{flushleft}


\begin{flushleft}
del comportamento, ma non dell'implementazione (non vi ` l'obbligo di usare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la stessa implementazione). La delegazione fondamentalmente corrisponde ad
\end{flushleft}


\begin{flushleft}
esplicitare il fatto che vi ` un altro oggetto che si preoccupa di rispondere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
alla richiesta in maniera corretta. Questo ` un oggetto interno, che deve esere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sempre attivo, e puntato in maniera opportuna dalla VMT dell'oggetto esterno!
\end{flushleft}


\begin{flushleft}
Si tratta sicuramente di uno dei fattori di maggiore complessit` dell'architettura
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
COM.
\end{flushleft}


\begin{flushleft}
L'aggregazione invece gestisce il problema in maniera implicita, realizzando
\end{flushleft}


\begin{flushleft}
quindi una serie di oggetti aggregati. Non ` come prima, per cui l'interfaccia
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
esterna funzionava come un passacarte, ma si realizza come una copia dell'interfaccia dell'oggetto aggregato nella VMT dell'oggetto esterno! Fondamentalmente, quindi, l'oggetto aggregato fornisce i propri metodi all'esterno, direttamente nell'interfaccia dell'oggetto esterno! Anche questa maniera ` complessa,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pi` dell'ereditariet`. L'aggregazione ` consigliata per una gestione a parti (a
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


74





\begin{flushleft}
\newpage
dierenza della delegazione, ogni oggetto si preoccupa di fare da gestore delle
\end{flushleft}


\begin{flushleft}
richieste ai metodi che implementa).
\end{flushleft}





7.2





\begin{flushleft}
Interazione C/S in COM
\end{flushleft}





\begin{flushleft}
L'idea base ` che vi sia uniformit` di comportamento fra ogni tipologia d'oggete
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
to: non interessa quindi come ` fatto, ma la possibilit` di poterci interagire in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
maniera C/S trasparente. Il problema ` che il costo ` molto diverso in realt` a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
seconda del tipo di oggetto con cui si prova a colloquiare (accedere ad una DLL
\end{flushleft}


\begin{flushleft}
in maniera C/S ` molto pi` ottimizzato che accedere ad un oggetto remoto).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Quindi, a dierenza di CORBA36 , l'implementazione sottostante ` diversa a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
seconda di quale tipo di oggetto si acceda
\end{flushleft}


\begin{flushleft}
Un oggetto in COM, perch` si possa riconoscere come server, deve fornire
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
la capacit` di istanziare degli oggetti : in generale questo viene realizzato utiliza
\end{flushleft}


\begin{flushleft}
zando delle Factory, che non son classi ma gestori d'entit`. Ogni Factory ha
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
una sua politica per l'attivazione (potrebbe per esempio realizzare un singleton,
\end{flushleft}


\begin{flushleft}
fornendo il riferimento sempre alla sola copia attiva), ma i diversi meccanismi
\end{flushleft}


\begin{flushleft}
devono restare nascosti.
\end{flushleft}


\begin{flushleft}
Un server quindi implementa o l'interfaccia IClassFactory (oppure la sua
\end{flushleft}


\begin{flushleft}
seconda versione, che permette di lavorare anche sfruttando un'apposita licenza dell'oggetto stesso). Queste interfacce infatti deniscono un metodo per
\end{flushleft}


\begin{flushleft}
creare un'istanza dell'oggetto, oppure di ottenere un riferimento all'oggetto gi`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
esistente (CreateInstance). Questo metodo (e le sue varianti) devono quindi
\end{flushleft}


\begin{flushleft}
esplorare il registry alla ricerca di un oggetto che implementa l'interfaccia ricercata; si pu` anche specicare un contesto, ovvero spiegare dove si potrebbe
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
ricercare l'oggetto.
\end{flushleft}


\begin{flushleft}
Esistono 3 tipi possibili di server in COM:
\end{flushleft}


\begin{flushleft}
$\bullet$ In-process: lavora nello stesso spazio di lavoro del client, mediante un'apposita DLL.
\end{flushleft}


\begin{flushleft}
$\bullet$ Locale: lavora in un processo diverso, ma sulla stessa macchina.
\end{flushleft}


\begin{flushleft}
$\bullet$ Remoto altrimenti.
\end{flushleft}


\begin{flushleft}
Il problema di COM ` che, volendo garantire un'alta trasparenza, richiedeche
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vengano denite tantissime interfacce. Un'altra interfaccia ` per esempio COe
\end{flushleft}


\begin{flushleft}
MOBJ, che si preoccupa di cercare nel registry l'esistenza delle DLL necessarie,
\end{flushleft}


\begin{flushleft}
ne fornisce il riferimento o le carica in memoria. Questo comporta che l'utente debba conoscere i meccanismi presenti in COM ! Fortunatamente, gli stessi
\end{flushleft}


\begin{flushleft}
meccanismi funzionano anche lavorando out-of-process.
\end{flushleft}


\begin{flushleft}
L'unica cosa che si aggiunge lavorando out-of-process ` la presenza di proxy
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e stub per facilitare la comunicazione e realizzare la trasparenza alla comunicazione. Fra proxy e stub si stabilisce quindi in maniera automatica un canale,
\end{flushleft}


\begin{flushleft}
che permette ai due processi di comunicare fra di loro: ` comunque un'astrazione
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
36 Uso
\end{flushleft}





\begin{flushleft}
perenne dell'ORB
\end{flushleft}





75





\begin{flushleft}
\newpage
(in locale si lavorerebbe utilizzando la memoria comune!). Per denire questi
\end{flushleft}


\begin{flushleft}
componenti, si ` sviluppato un apposito IDL, MIDL. Questo deriva e rispetta
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
le speciche di DCE, ma risulta comunque essere incompatibile con altri IDL.
\end{flushleft}


\begin{flushleft}
Come funziona quindi la comunicazione in COM? Si lavora per sequenza: si
\end{flushleft}


\begin{flushleft}
tenta inizialmente di accedere alla risorsa in process, poi in locale, ed inne si
\end{flushleft}


\begin{flushleft}
tenta in remoto sfruttando come meccanismo RPC. In certi casi, essendo poco
\end{flushleft}


\begin{flushleft}
costosa, si utilizza RPC anche in locale, di tipo diverso e pi` leggera.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Per la gestione remota, vi ` anche la presenza di un ulteriore attore al livello
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
pi` basso detto Service Control Manager, che si comporta proprio come un mw!
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Infatti, un proxy che volesse comunicare, si riferisce al SCMper ottenere un
\end{flushleft}


\begin{flushleft}
riferimento all'oggetto remoto, e quindi pu` realizzare una RPC remota.Questa
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
architettura comporta quindi che SCM debba essere presente su ogni nodo, e
\end{flushleft}


\begin{flushleft}
che proxy e stub debbano essere stabiliti prima, in maniera da poter conoscere
\end{flushleft}


\begin{flushleft}
la posizione del SCM! Si potrebbe anche avere, tuttavia, che non vengano mai
\end{flushleft}


\begin{flushleft}
usati se la risorsa ` disponibile in-process!
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





7.3





\begin{flushleft}
DCOM
\end{flushleft}





\begin{flushleft}
DCOM nasce negli anni 90 come esigenza si introdurre anche in COM (come
\end{flushleft}


\begin{flushleft}
in CORBA) l'interazione dinamica. In particolare, ci` che si introduce ` il
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
concetto di automation, ovvero la possibilit` di fornire ad un client di poter
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
gestire oggetti per cui non aveva previsto l'interazione. Si tratta anche di un
\end{flushleft}


\begin{flushleft}
modello realizzato per cercare di andare oltre al classico modello a code di eventi.
\end{flushleft}


\begin{flushleft}
Inizialmente, automation nasce come possibilit` per linguaggi dinamici (tipo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
quelli di scripting per il Web) di poter accedere all'architettura COM. Questo
\end{flushleft}


\begin{flushleft}
genere di linguaggi infatti spesso sono loosely-typed e studiati in maniera tale
\end{flushleft}


\begin{flushleft}
da avere poco controllo. Prima di automation risultava dicile realizzare proxy
\end{flushleft}


\begin{flushleft}
anche per questi linguaggi.
\end{flushleft}


\begin{flushleft}
Quello che fa automation ` semplicemente la realizzazione in automatico di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
una DLL che funzioni come intermediario fra i due mondi, fra COM e qualsiasi
\end{flushleft}


\begin{flushleft}
altro lingaggio, se tale interazione non era gi` stata prevista in maniera statica.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Automation permette quindi di esplorare, in maniera automatica, un oggetto
\end{flushleft}


\begin{flushleft}
la cui interfaccia ` sconosciuta a tempo di esecuzione. Automation incorpora
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
concetti gi` visti in OLE, come la in-place activation, per cui un gestore viene
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
attivato solo se ` necessario, cio` se ` richiesto da un sottocomponente. DCOM
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e e
\end{flushleft}


\begin{flushleft}
introduce anche altre tecnologie, come lo structured storage (tutto ` all'interno
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di un singolo le) e un sistema di scambio dei dati unicato. DCOM introduce
\end{flushleft}


\begin{flushleft}
soprattutto diversi strumenti proprietari Microsoft per il web, spesso incompatibili con altri strumenti.
\end{flushleft}


\begin{flushleft}
Per introdurre la dinamicit`, un oggetto deve implementare anche l'interfaca
\end{flushleft}


\begin{flushleft}
cia IDispatch, che ` riessiva, la base stessa di automation. Infatti, a dierenza
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
di CORBA, in COM-DCOM non vi ` un IR per registrare le interfacce: si tratta
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quindi di interrogare ed invocare in maniera dinamica i componenti! Si tratta
\end{flushleft}


\begin{flushleft}
di un sistema del tutto analogo alla Request di CORBA.
\end{flushleft}


76





\begin{flushleft}
\newpage
Quindi, alcuni metodi riportano informazioni sul componente (GetTypeInfo,
\end{flushleft}


\begin{flushleft}
GetTypeInfoCount), altri preparano il client a richiedere l'invocazione (GetIDsOfNames) e inne vi ` un metodo per invocare in maniera dinamica l'oggetto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
stesso. IDispatch, essendo un'interfaccia COM, eredita direttamente da IUnknown. Possiamo cos` sostituire questa ed altre interfacce, permettendo un'ese\i{}
\end{flushleft}


\begin{flushleft}
cuzione sempre dinamica (ma costosa).
\end{flushleft}


\begin{flushleft}
Si pu` quindi iniziare a parlare di componenti veri, che rappresentano un'esteno
\end{flushleft}


\begin{flushleft}
sione degli oggetti: sono pi` pervasivi, garantendo di non avere limiti alla riusu
\end{flushleft}


\begin{flushleft}
abilit` e possibilit` di essere usati in un qualunque contesto, senza dover dipena
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dere come gli oggetti da un determinato linguaggio.
\end{flushleft}


\begin{flushleft}
A dierenza per` di CORBA, essendo la VMT ssa, non ` possibile realizzare
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
un server dinamico!.
\end{flushleft}





7.4





\begin{flushleft}
Interazione in DCOM
\end{flushleft}





\begin{flushleft}
COM era stato pensato per fornire una visione di alto livello uniforme (sempre
\end{flushleft}


\begin{flushleft}
C/S), per cercare anche di rendere un'ottimizzazione molto forte a seconda
\end{flushleft}


\begin{flushleft}
della comunicazione che si andava a realizzare. A basso livello invece si ha un
\end{flushleft}


\begin{flushleft}
comportamento molto variegato, con un'alta idea di delegazione.
\end{flushleft}


\begin{flushleft}
A sua volta, DCOM prevede di denire dei riferimenti diretti fra C e S,
\end{flushleft}


\begin{flushleft}
facendo in modo quindi che si conoscano comunque, nonostante l'uso di un'interfaccia. Questi riferimenti quindi non son persistenti.37 . DCOM si preoccupa
\end{flushleft}


\begin{flushleft}
di aumentare la dinamicit`, cercando anche di andare oltre al C/S, ma fornendo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
strumenti per trovare in maniera automatica la soluzione, fornendo supporto
\end{flushleft}


\begin{flushleft}
alla portabilit`, cercando di dare una visione semplicata. Purtroppo, per reala
\end{flushleft}


\begin{flushleft}
izzare ci` si ` dovuto ripensare l'architettura, mantenendo per` un sistema per
\end{flushleft}


\begin{flushleft}
o e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
integrare il sistema legacy precedente.
\end{flushleft}


\begin{flushleft}
Quello che infatti succede ` che in automation le DLL diventano oggetti ade
\end{flushleft}


\begin{flushleft}
hoc. Questi oggetti, riassunti ed estensioni, sono i cosidetti ActiveX. Includono
\end{flushleft}


\begin{flushleft}
anche idee come OLE, ma restano molto complessi da realizzare, per cui `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
necessario sfruttare degli appositi wizard. Sono quindi fondamentalmente dei
\end{flushleft}


\begin{flushleft}
piccoli server OLE, in grado di attivarsi con il metodo della in-place activation,
\end{flushleft}


\begin{flushleft}
ma con un comportamento diverso: infatti, lavorano in maniera inside out,
\end{flushleft}


\begin{flushleft}
ovvero son sempre pronti, attivi, no a che l'oggetto contenuto ` presente. Si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tratta quindi di un sistema ad aggregazione sempre attiva (il componente interno
\end{flushleft}


\begin{flushleft}
` sempre attivo).
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





7.5





\begin{flushleft}
Standardizzazione dei componenti
\end{flushleft}





\begin{flushleft}
Un merito di COM e DCOM ` stato quello di fornire un primo tentativo di stane
\end{flushleft}


\begin{flushleft}
dardizzare il concetto di componente. Prima si dovevano denire sempre diverse
\end{flushleft}


\begin{flushleft}
37 Vi ` una losoa diversa rispetto a CORBA: qui ` necesario avere anche una visione di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
basso livello, nonostante l'uso delle interfacce come in CORBA
\end{flushleft}





77





\begin{flushleft}
\newpage
interfacce, sempre utilizzabili dagli utenti, ma senza una razionalizzazione alla
\end{flushleft}


\begin{flushleft}
loro realizzazione.
\end{flushleft}


\begin{flushleft}
DCOM denisce per primo che un sistema a componenti deve denire un'architettura a PEM (Property, Event, Method ), per poter denire stato, output
\end{flushleft}


\begin{flushleft}
e input dei componenti. Questo sistema semplica la realizzazione, permettendo quindi di denire un container che sia semplicemente un gestore degli oggetti
\end{flushleft}


\begin{flushleft}
contenuti, in grado di attivarli attravero un'interfaccia uniforme e al sistema dell'introspezione. Il container deve solo fornire un'interfaccia IDispatch! Quindi,
\end{flushleft}


\begin{flushleft}
il container implementa la dispinterface denita dall'oggetto contenuto (questo
\end{flushleft}


\begin{flushleft}
deve solo denire quali eventi sono interessanti per lui); uno ` la sorgente dele
\end{flushleft}


\begin{flushleft}
l'interfaccoa, l'altro il pozzo che la realizza. A sua volta, il container sfrutta
\end{flushleft}


\begin{flushleft}
degli oggetti intermedi per poter comunicare con l'oggetto contenuto.
\end{flushleft}


\begin{flushleft}
DCOM stabilisce anche la possibilit` di realizzare una persistenza del coma
\end{flushleft}


\begin{flushleft}
ponente, implementando un'apposita interfaccia. (I riferimenti non son ssi in
\end{flushleft}


\begin{flushleft}
DCOM).
\end{flushleft}





7.6





\begin{flushleft}
Gestori delle sottoparti: i monikers
\end{flushleft}





\begin{flushleft}
DCOM introduce i monikers come un sistema ad hoc, piuttosto complesso, per
\end{flushleft}


\begin{flushleft}
poter gestire in maniera persistente la gestione degli oggetti. Questo sistema
\end{flushleft}


\begin{flushleft}
aumenta la essibilit`, memorizzando su disco quindi i riferimenti agli oggetti,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
categorizzandoli in base a cosa sono, e rendendoli indipendenti dalle applicazioni!
\end{flushleft}


\begin{flushleft}
Si ha quindi che ogni moniker viene associato ad un programma, permettendo
\end{flushleft}


\begin{flushleft}
anche di lavorare mediante nomi indiretti. Permette anche di moltiplicare i
\end{flushleft}


\begin{flushleft}
meccanismi, aggiungendo diversi monikers.
\end{flushleft}





7.7





\begin{flushleft}
Modello a thread di DCOM
\end{flushleft}





\begin{flushleft}
Il modello deriva da quello di Win32. Tuttavia, vi possono essere dei problemi se certi componenti non risultano essere thread-safe (magari perch` sono
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
componenti legacy). Per superare questo problema, in DCOM si ` introdote
\end{flushleft}


\begin{flushleft}
to il concetto di Apartment, che consiste ad un ambiente d'esecuzione isolato,
\end{flushleft}


\begin{flushleft}
cio` con una politica di threading ssata. Vi sono due diversi modelli, o quello
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
single-threaded (pi` diuso, un unico componente lavora nell'apartment) opu
\end{flushleft}


\begin{flushleft}
pure multi-threaded. Ogni componente pu` quindi avere pi` STA, ma sempre
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
un solo MTA.
\end{flushleft}





7.8





\begin{flushleft}
Altri strumenti DCOM
\end{flushleft}





\begin{flushleft}
Microsoft ha fornito mediante DCOM tantissimi strumenti, in grado di risolvere
\end{flushleft}


\begin{flushleft}
i problemi sempre pi` nell'ottica di un moderno mw.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
In particolare, si possono citare MSMQ per realizzare un sistema a scambio di
\end{flushleft}


\begin{flushleft}
messaggi, e COM+ per permettere la denizione di componenti solo attraverso
\end{flushleft}


\begin{flushleft}
la parte logica. Presenta anche un servizio X.500 di directory standard, detto
\end{flushleft}


\begin{flushleft}
Active Directory.
\end{flushleft}





78





\newpage
7.9





\begin{flushleft}
.NET
\end{flushleft}





\begin{flushleft}
Questa ` la nuova architettura Microsoft, sviluppata ripensando totalmente il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tutto! Non solo si ` progettato pensando ad un S.O. diverso, ma anche rivoluzioe
\end{flushleft}


\begin{flushleft}
nando la stessa macchina virtuale (realizzando il CLR). Si tratta di un sistema
\end{flushleft}


\begin{flushleft}
derivato e migliorato (sotto certi aspetti) da Java: Java infatti ormai presenta
\end{flushleft}


\begin{flushleft}
dei sistemi legacy con cui deve far conto, per cui non pu` introdurre direttamente
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
nuovi aspetti senza rompere con il passato (non si pu`, per esempio, introdurre
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
un controllo dinamico delle risorse occupate da un thread, per denirlo anche a
\end{flushleft}


\begin{flushleft}
run-time!). .NET realizza anche lui un compilatore JIT, denisce una serie di
\end{flushleft}


\begin{flushleft}
classi base, rintroduce l'ereditariet` dell'implementazione, delle classi, e svilupa
\end{flushleft}


\begin{flushleft}
pa un sistema a livelli molto simile a quello di un mw moderno, con diversi
\end{flushleft}


\begin{flushleft}
servizi attivabili a basso ed ad alto livello.
\end{flushleft}


\begin{flushleft}
In particolare, .NET introduce una forte idea di localit` sfruttando l'idea
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
dell'application domain: i processi non possono comunicare in maniera diretta
\end{flushleft}


\begin{flushleft}
fra di loro, ma devono sfruttare dei protocolli DCOM compatibili (` un sistema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
simile all'apartment), oppure WS o altre nuove tecnologie .NET. WS per esempio ` la tecnologia pi` costosa, ma anche pi` vicina all'applicazione da un punto
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
di vista logico.
\end{flushleft}





7.10





\begin{flushleft}
.NET remoting
\end{flushleft}





\begin{flushleft}
Si basa comunque sull'idea di realizzare dei proxy per facilitare la comunicazione.
\end{flushleft}


\begin{flushleft}
Tuttavia, vi sono due diversi tipi di proxy: quello trasparente (utile per fare
\end{flushleft}


\begin{flushleft}
richieste direttamente al supporto .NET e generato automaticamente) e quello
\end{flushleft}


\begin{flushleft}
reale (realizzato per facilitare la comunicazione C/S, spesso presente). Si ha
\end{flushleft}


\begin{flushleft}
quindi che il secondo proxy ` anche modicabile, per poterlo adattare alle proe
\end{flushleft}


\begin{flushleft}
prie esigenze. In particolare, con questo sistema, si riesce a registrare un oggetto remoto all'interno del proprio application domain, per poterlo utilizzare in
\end{flushleft}


\begin{flushleft}
maniera trasparente!
\end{flushleft}


\begin{flushleft}
I proxy sono utilizzati per superare l'eterogeneit` fra i sistemi, e per generare
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
un canale come veicolo di trasporto dell'informazione. Questi canali possono essere di diverso tipo (binari, testuali, http compatibili, . . . i 2 standard sfruttano
\end{flushleft}


\begin{flushleft}
o TCP o HTTP), e si possono combinare per realizzare una catena di responsabilit` (formattazione del messaggio, encoding, . . . )! Sono questi oggetti che
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
permettono la comunicazione fra application domain diversi. Ogni application
\end{flushleft}


\begin{flushleft}
domain quindi registra i canali che si possono usare, permettendo alle volte anche una comunicazione bidirezionale.
\end{flushleft}


\begin{flushleft}
Di default, le operazioni remote sono sempre sincrone, ma sfruttando opportunatamente i delegati si possono ottenere anche interazioni sincrone non
\end{flushleft}


\begin{flushleft}
bloccanti, sfruttando un meccanismo di call-back. I metodi possono fornire un
\end{flushleft}


\begin{flushleft}
passaggio per valore (maggiormente disaccoppiato, ma in presenza di dati grandi, aumenta notevolmente l'overhead) o per riferimento (mediante la creazione
\end{flushleft}


\begin{flushleft}
di un proxy per memorizzare quindi un riferimento remoto), in maniera quindi
\end{flushleft}





79





\begin{flushleft}
\newpage
del tutto simile a CORBA!
\end{flushleft}


\begin{flushleft}
L'attivazione a chi tocca? Non son presenti dei POA come in CORBA,
\end{flushleft}


\begin{flushleft}
quindi si potrebbe prima di tutto pensare ad un'attivazione da parte del cliente
\end{flushleft}


\begin{flushleft}
(esistono meccanismi per fare il lease, e quindi mantenere il collegamento con il
\end{flushleft}


\begin{flushleft}
server oltre al tempo specicato38 ). In questa maniera si pu` anche mantenere
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
uno stato.
\end{flushleft}


\begin{flushleft}
Gli oggetti remoti possono anche essere attivati dai server, in due diversi
\end{flushleft}


\begin{flushleft}
modi:
\end{flushleft}


\begin{flushleft}
$\bullet$ Come singleton (si attiva ora per sempre, ma non si pu` garantire uno
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
stato permanente: il controllo dell'oggetto resta in mano al supporto che
\end{flushleft}


\begin{flushleft}
potrebbe deallocarlo).
\end{flushleft}


\begin{flushleft}
$\bullet$ oppure come oggetti di tipo single call, ovvero con durata limitata al tempo
\end{flushleft}


\begin{flushleft}
dell'invocazione, e quindi di costo limitato.
\end{flushleft}


\begin{flushleft}
Si ha quindi una politica d'attivazione molto pi` semplice rispetto a quella di
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
CORBA!
\end{flushleft}





8





\begin{flushleft}
I Web Services
\end{flushleft}





\begin{flushleft}
L'idea alla base dei Web Services ` quella di fornire dei servizi B2B invece dei
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
classici servizi Web. La logica ` che il Web ` l'installato pi` diuso e facilmente
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
accedibile al mondo, perch` non sfruttarlo?
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Si ha infatti che molti mw richiedono congurazioni che vanno per esempio
\end{flushleft}


\begin{flushleft}
contro certi principi delle aziende (aperture di ulteriori porte verso l'esterno),
\end{flushleft}


\begin{flushleft}
aggiungendo dei vincoli organizzativi che possono renderne l'applicazione ancora
\end{flushleft}


\begin{flushleft}
pi` complessa.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
Con i Web Services si vuole sviluppare un sistema assolutamente standard
\end{flushleft}


\begin{flushleft}
(basandosi su XML per descrivere i servizi, per fornire le risposte, . . . ), in grado quindi di superare in maniera facile l'eterogeneit` (utilizzo di sistemi solo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
standard). Gli obiettivi sono quindi quelli di realizzare delle Service Oriented
\end{flushleft}


\begin{flushleft}
Application (mappando l'interfaccia di interazione ad alto livello) o delle Enterprise Application Integration,come SAP, ovvero un sistema in grado di integrare
\end{flushleft}


\begin{flushleft}
anche sistemi legacy.
\end{flushleft}


\begin{flushleft}
Perch` allora non usare sempre il web, perch` esistono anche altri mw ancoe
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ra? Il problema ` che il Web ha un costo molto elevato, per cui potrebbe essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
utile per sistemi che richiedono una grana molto grossa.
\end{flushleft}





8.1





\begin{flushleft}
Struttura generale de WS
\end{flushleft}





\begin{flushleft}
Un WS funziona mediante l'emissione da parte di un client di una richiesta,
\end{flushleft}


\begin{flushleft}
per cui si ricerca attravero un apposito broker (ma ` una struttura diversa
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
38 Server
\end{flushleft}





\begin{flushleft}
pu` anche interrogare il client prima di deallocare la risorsa
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}





80





\begin{flushleft}
\newpage
dall'ORB di CORBA: funziona soprattutto come un directory per i servizi ) il
\end{flushleft}


\begin{flushleft}
servizio adatto a soddisfare quella determinata richiesta.
\end{flushleft}


\begin{flushleft}
L'idea ` che quindi vi siano diversi provider in grado di servire i servizi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
richiesti. Per realizzare ci`, sono stati realizzati diversi protocolli standard :
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
$\bullet$ SOAP : Simple Object Access Protocol, consiste nel protocollo per poter
\end{flushleft}


\begin{flushleft}
eseguire le richieste e ricevere le risposte, ed ` ovviamente XML compatie
\end{flushleft}


\begin{flushleft}
bile.
\end{flushleft}


\begin{flushleft}
$\bullet$ WSDL: Web Service Description Language ` il linguaggio basato su XML
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per poter denire dei WS.
\end{flushleft}


\begin{flushleft}
$\bullet$ UDDI : Universal Discovery Distribution Integration: questo invece ` il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
protocollo che specica come i servizi si possano raccogliere in appositi
\end{flushleft}


\begin{flushleft}
contenitori, realizzando un apposito sistema di nomi.
\end{flushleft}


\begin{flushleft}
I servizi sono deniti one-shot, il che signica che sono eseguiti in maniera unica,
\end{flushleft}


\begin{flushleft}
isolata! Per ogni richiesta, si attiva un solo servizio. Siamo quindi in presenza
\end{flushleft}


\begin{flushleft}
di un mw senza stato. Questo ` sempre dovuto al fatto che si deve lavorare con
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
dati a grana molto grossa, che auto-contiene l'interazione: non si assume che il
\end{flushleft}


\begin{flushleft}
provider abbia stato!
\end{flushleft}


\begin{flushleft}
Nelle prime implementazioni dei WS non erano previsti meccanismi per la
\end{flushleft}


\begin{flushleft}
sicurezza, il management e la QoS. Si aveva quindi, per esempio, solo crittograa
\end{flushleft}


\begin{flushleft}
a livello applicativo, il che per` non era un sistema standard!
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Perch` si ` deciso di utilizzare XML? Permette di specicare in una maniera
\end{flushleft}


\begin{flushleft}
e e
\end{flushleft}


\begin{flushleft}
fortemente strutturata (realizzando dati che si possono validare formalmente, e
\end{flushleft}


\begin{flushleft}
utilizzando DTD/XSD si possono anche controllare dal punto di vista sintatticosemantico), potendo quindi esprimere le preferenze in maniera dinamica!
\end{flushleft}





8.2





\begin{flushleft}
SOAP
\end{flushleft}





`


\begin{flushleft}
E il protocollo per la comunicazione, in grado quindi di strutturare l'interazione.
\end{flushleft}


\begin{flushleft}
Denisce quindi come si pu` accedere agli oggetti. Presenta un alto overhead
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
perch` si deve specicar tutto: siamo infatti in un'interazione senza stato, per
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
cui si deve specicare URI, . . . Non vi ` quindi nessun supporto semantico, e vi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
possono essere pi` interazioni.
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
SOAP quindi permette di denire operazioni, dati e parametri. Sfrutta
\end{flushleft}


\begin{flushleft}
HTTP come protocollo per la trasmissione, e XML per poter serializzare i dati.
\end{flushleft}


\begin{flushleft}
In questo modo, si possono denire operazioni remote sfruttando l'XML: un
\end{flushleft}


\begin{flushleft}
servitore riceve una richiesta standard, e la sua implementazione non interessa i
\end{flushleft}


\begin{flushleft}
WS. Un provider dovr` soltanto rispondere rispettando la specica fornita con
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
SOAP!
\end{flushleft}


\begin{flushleft}
SOAP quindi permette di descrivere l'interazione ma non solo: possiamo
\end{flushleft}


\begin{flushleft}
avere operazioni senza risultati, o in grado emulare il comportamento C/S39 ,
\end{flushleft}


\begin{flushleft}
39 Al posto delle RPC, si pu` denire che la comunicazione avviene con uno stile di tipo
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
documento, per cui non si ha mai risposta, sempre asincrona
\end{flushleft}





81





\newpage
`


\begin{flushleft}
ma possiamo anche quindi denire se si utilizza GET o POST per esempio. E
\end{flushleft}


\begin{flushleft}
un protocollo state-less, che non fornisce quindi informazioni semantiche sulla
\end{flushleft}


\begin{flushleft}
comunicazione. Non ` vero che si parla di operazioni leggere e essibili, ma
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
anche abbastanza pesanti alle volte.
\end{flushleft}


\begin{flushleft}
SOAP si basa sull'idea di incapsulare mediante XML le informazioni necessarie alla comunicazione, come se fosse un'envelope:
\end{flushleft}


\begin{flushleft}
$\bullet$ Il body contiene le informazioni richieste per la comunicazione, cio` il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
contenuto vero e proprio del messaggio, e le corrispondenti risposte.
\end{flushleft}


\begin{flushleft}
$\bullet$ L'header specica altre informazioni utili per la comunicazione (es, per la
\end{flushleft}


\begin{flushleft}
sicurezza)
\end{flushleft}


\begin{flushleft}
$\bullet$ Si pu` anche denire una sezione di fault, nel caso che l'operazione non
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
avesse avuto successo.
\end{flushleft}


\begin{flushleft}
La comunicazione non ` necessariamente P2P ma anche molti a molti. Il problee
\end{flushleft}


\begin{flushleft}
ma di SOAP ` che ` altamente costoso (e poco eciente), perch` siamo costretti
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a lavorare a livello applicativo.
\end{flushleft}





8.3





\begin{flushleft}
WSDL
\end{flushleft}





`


\begin{flushleft}
E il linguaggio per descrivere sia in maniera astratta che in maniera concreta
\end{flushleft}


\begin{flushleft}
quali servizi un provider pu` fornire. Descrive quindi l'interfaccia, indicando le
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


`


\begin{flushleft}
operazioni disponibili presso un certo provider. E una sorta di IDL. Quindi,
\end{flushleft}


\begin{flushleft}
WSDL riesce a descrivere in maniera precisa come una richiesta debba essere
\end{flushleft}


\begin{flushleft}
strutturata, e come una risposta sar` ritornata. Si pu` anche specicare dove il
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
servizio risieda, e come lo si pu` invocare.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Questo sistema, a dierenza di altri gi` visti, impone che il cliente debba
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
conoscere il servitore: viene a sapere in maniera concreta chi e come realizza
\end{flushleft}


\begin{flushleft}
l'operazione desiderata. Si passano quindi i dati per copia con i WS. Si ha quindi che se non si conosce un servizio, si pu` richiedere il WSDL corrispondente,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
analizzarlo, e preparare cos` un'apposita richiesta SOAP! Il tutto nell'ottica di
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
ottimizzare le operazioni eseguibili da un possibile mw.
\end{flushleft}


\begin{flushleft}
WSDL ` in grado quindi di denire due parti, una pi` astratta (in grado
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
di denire i messaggi (insieme di elementi tipati), le operazioni (o collezione di
\end{flushleft}


\begin{flushleft}
messaggi), e le interfacce del servizio (insieme di operazioni)) e una pi` concreu
\end{flushleft}


\begin{flushleft}
ta, a basso livello (in grado di denire i tipi, come il servizio si lega realmente
\end{flushleft}


\begin{flushleft}
ad un sistema, alle sue implementazioni concrete, detto binding (che protocollo
\end{flushleft}


\begin{flushleft}
si usa? HTTP, TCP,. . . ), su quali nodi risiede e i service, ovvero le implementazioni delle interfacce disponbili. La parte astratta ` essibile, generalizzabile
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e facilmente estendibile.
\end{flushleft}


\begin{flushleft}
WSDL prevede diversi modi di interazione! Non solo pi` modi sincroni (con
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
attesa di messaggio o sollecitazione da parte del client) ma anche asincroni (one-
\end{flushleft}





82





\begin{flushleft}
\newpage
way, o notication: cambia da chi esce il messaggio!).
\end{flushleft}


\begin{flushleft}
WSDL ` un linguaggio molto pesante, ma che garantisce un'alta essibilit`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
quindi: permette anche di invertire i ruoli fra C e S! Tuttavia, ` fondamentale
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
per poter generare in maniera automatica proxy e stub, oppure per realizzare
\end{flushleft}


\begin{flushleft}
dei wrapper appositi per integrare facilmente sistemi legacy!
\end{flushleft}





8.4





\begin{flushleft}
UDDI e WSIL
\end{flushleft}





`


\begin{flushleft}
E il servizio di nomi presente nei WS. Si tratta di un ulteriore linguaggio con
\end{flushleft}


\begin{flushleft}
cui poter descrivere dove risiedono i vari servizi, e come aggregare fra di loro
\end{flushleft}


\begin{flushleft}
pi` servizi. La prima informazione che si necessita ` la possibilit` di descrivere
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
le aziende che forniscono i servizi, per permettere quindi ad un generico utente
\end{flushleft}


\begin{flushleft}
di poter navigare.
\end{flushleft}


\begin{flushleft}
Con UDDI si pu` infatti realizzare facilmente un sistema di pagine bianche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
(name server normale), pagine gialle (ovvero un sistema di trading, si memorizza per categorie) o inne per pagine verdi (sono pagine tecniche aggiuntive
\end{flushleft}


\begin{flushleft}
sui servizi oerti). Fondamentalmente, UDDI ` un {`}name server d'alto livello',
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
globale e condiviso ma non gerarchizzato. Questo aspetto presenta grossi problemi di coordinazione e di sicurezza fra i diversi gestori dei servizi !
\end{flushleft}


\begin{flushleft}
Gli attori possibili quindi per UDDI sono due: i publisher di un servizio e i
\end{flushleft}


\begin{flushleft}
loro requester. Vista la struttura degli UDDI, un requester dovr` navigare sina
\end{flushleft}


\begin{flushleft}
golarmente gli UDDI, perch` appunto non vi ` ridirezione fra questi! In maniera
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
particolare, per aggiungere sicurezza si dovrebbe memorizzare e garantire il publisher!
\end{flushleft}


\begin{flushleft}
A tale proposito ` stato pensato WSIL, dove si rovesciano le responsabilit`:
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
in questo modo ` il provider a dover garantire sicurezza, e non ` pi` compito di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e u
\end{flushleft}


\begin{flushleft}
un eventuale server dei servizi vericare l'identit` dei provider. Si tratta quindi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di un protocollo alternativo, in grado di realizzare un sistema decentralizzato,
\end{flushleft}


\begin{flushleft}
leggero e non focalizzato sul business. In maniera analoga ad UDDI, sfrutta
\end{flushleft}


\begin{flushleft}
WSDL per descrivere i servizi!
\end{flushleft}





8.5





\begin{flushleft}
Considerazioni nali sui WS
\end{flushleft}





\begin{flushleft}
I protocolli realizzati dal W3C sono molto apprezzati da diverse organizzazioni,
\end{flushleft}


\begin{flushleft}
come le banche in Italia. Tuttavia, i WS presentano un alto overhead rispetto ad
\end{flushleft}


\begin{flushleft}
altre tecnologie (` possibile che non sia una comunicazione limitata a due attori,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e si lavora sempre a livello applicativo). Attualmente ` una tecnologia ancora
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
molto in fase di sviluppo e studio (nelle prime versione, i protocolli mancavano
\end{flushleft}


\begin{flushleft}
molto d'espressivit`: la sicurezza per esempio era fornita solo a basso livello).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
L'evoluzione che si immagina quindi per i WS ` quella di far evolvere il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sistema, come una composizione e coordinazione dei servizi, per poter aprire i
\end{flushleft}


\begin{flushleft}
WS ad una categoria di utenti pi` ampia. L'idea sarebbe quindi quella che, per
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
ottenere un nuovo servizio, si compongano quelli precedenti. Per far ci` sono
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


83





\begin{flushleft}
\newpage
stati introdotti nuovi linguaggi a usso (Business Process Execution Language
\end{flushleft}


\begin{flushleft}
4WS: si possono mettere in sequenza, parallelo, in alternativa o in join) per
\end{flushleft}


\begin{flushleft}
i WS, che lavorano sempre ad un livello molto alto. L'estensione dei WS in
\end{flushleft}


`


\begin{flushleft}
questa direzione ` indicata come WS*. E una visione maggiormente orientata
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
ad perseguire logiche di business.
\end{flushleft}





9





\begin{flushleft}
Gestione delle risorse e sistemi mobili
\end{flushleft}





\begin{flushleft}
Le risorse in un sistema distribuito possono essere o concentrate o distribuite.
\end{flushleft}


\begin{flushleft}
L'idea ` comunque quella di cercare di orire un servizio d trasparenza accedene
\end{flushleft}


\begin{flushleft}
do alla risorsa.
\end{flushleft}


\begin{flushleft}
Si deve quindi avere un sistema per descrivere le risorse, magari sfruttando
\end{flushleft}


\begin{flushleft}
l'XML se si sta lavorando ad alto livello. Se inoltre si potesse denire la qualit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sulla risorsa, si potrebbe dimostrare che si ` capito il costo fondamentale nello
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
sviluppo.
\end{flushleft}


\begin{flushleft}
Si possono avere due diversi piani per il progetto delle risorse:
\end{flushleft}


\begin{flushleft}
$\bullet$ Statico: si progettano le risorse no al deployment, realizzando anche delle
\end{flushleft}


\begin{flushleft}
politiche complesse per poter descrivere dove inserirle, come replicarle,. . .
\end{flushleft}


\begin{flushleft}
$\bullet$ Dinamico: si realizzano politiche per la gestione e il deployment durante
\end{flushleft}


\begin{flushleft}
l'esecuzione dell'applicazione stessa.
\end{flushleft}


\begin{flushleft}
Tipicamente, si ha gi` pensato a come realizzare il deployment delle risorse, alla
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
loro allocazione, essendo l'approccio pi` semplice da gestire: questo per` ` un
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
oe
\end{flushleft}


\begin{flushleft}
approccio poco essibile e dinamico.
\end{flushleft}


\begin{flushleft}
Un esempio di sistema distribuito coordinato per le risorse potrebbe essere
\end{flushleft}


\begin{flushleft}
un File System distribuito: richiederebbe l'introduzione di agenti coordinati per
\end{flushleft}


\begin{flushleft}
gestirle (questi dovrebbero introdurre delle fasi di negoziazione, prima di poter
\end{flushleft}


\begin{flushleft}
fornire l'accesso alla risorsa). Garantisce trasparenza all'allocazione delle risorse,
\end{flushleft}


\begin{flushleft}
mantenendo un comportamento uguale. Un altro modello potrebbe essere quello
\end{flushleft}


\begin{flushleft}
basato su una service request, che rappresenta un sistema C/S.
\end{flushleft}





9.1





\begin{flushleft}
Mobilit` delle risorse
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
Nel progetto di un sistema, si deve considerare cosa e come si pu` muovere. Per
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
esempio, se si pensa allo stack di un programma Java, questo ` legato alla stack
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
della JVM: non si pu` spostare facilmente su un altro nodo! Altre caratteristiche
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
dicili da muovere sono i riferimenti a risorse strettamente locali (tipo i le40 ).
\end{flushleft}


\begin{flushleft}
Se ` presente la possibilit` di muovere le risorse, aggiungendo un servizio di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
trasparenza si ha che si lavora senza fornire la possibilit` di vedere le risorse
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
locali!
\end{flushleft}


\begin{flushleft}
Questi concetti sono utili anche per decidere cosa posizionare su ogni nodo:
\end{flushleft}


\begin{flushleft}
se per esempio le risorse dovessero essere allocate tutte sullo stesso nodo, si pu`
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
40 Si
\end{flushleft}





\begin{flushleft}
potrebbero spostare, se si lavorasse su un le system distribuito
\end{flushleft}





84





\begin{flushleft}
\newpage
realizzare un sistema a memoria comune, con operazioni per` solo sequenziali.
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Potendole distribuire su pi` nodi, si riescono a fornire operazioni anche in paru
\end{flushleft}


\begin{flushleft}
allelo ma molto pi` costose. Se le risorse son semplici poi, basta semplicemente
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
copiarle, mentre certe risorse con vincoli che le rendono complesse, richiedono
\end{flushleft}


\begin{flushleft}
un apposito sistema di trasparenza.
\end{flushleft}


\begin{flushleft}
Esistono quindi diversi requisiti per fare un'esecuzione remota: si deve cercare di limitare l'overhead, e di interferire il meno possibile con l'esecuzione
\end{flushleft}


\begin{flushleft}
locale (gradita la non-interferenza), ed ` necessario fornire anche delle infore
\end{flushleft}


\begin{flushleft}
mazioni di stato sui singoli processori. Questo ` particolarmente importante,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vista l'ampia eterogeneit` presente: non vi ` per esempio un sistema di nomi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
comune, ed ` quindi necessario stipulare delle apposite convenzioni.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}





9.2





\begin{flushleft}
Muovere i processi
\end{flushleft}





\begin{flushleft}
Esistono diversi S.O. che prevedono la possibilit` di spostare i processi su altri
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
processori, per cercare di fornire un bilanciamento di carico migliore. Si realizza
\end{flushleft}


\begin{flushleft}
cos` uno scheduling distribuito, in grado di fornire sia una politica locale che
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
globale con cui trattare i processi. Un sistema di scheduling globale deve essere
\end{flushleft}


\begin{flushleft}
in grado di fornire dei meccanismi con cui i processi possano comunicare in
\end{flushleft}


\begin{flushleft}
remoto e quindi la possibilit` di realizzare delle politiche per la gestione delle
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
risorse.
\end{flushleft}


\begin{flushleft}
In particolare, si possono avere due diversi approcci:
\end{flushleft}


\begin{flushleft}
$\bullet$ Load Sharing: si denisce la condivisione del carico come carico globale
\end{flushleft}


\begin{flushleft}
del sistema, ovvero ` uno scheduling totale del sistema. L'idea ` quella di
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
evitare processi idle, mantenendoli sempre al massimo del lavoro possibile.
\end{flushleft}


\begin{flushleft}
Si tratta di una valutazione statica, i processi non si possono muovere su
\end{flushleft}


\begin{flushleft}
altri processori
\end{flushleft}


`


\begin{flushleft}
$\bullet$ Load Balancing: E una valutazione dinamica, ovvero a tempo d'esecuzione
\end{flushleft}


\begin{flushleft}
le risorse si possono muovere. Si vuole quindi mantenere un carico equilibrato su ogni processore, per ottenere un'ecienza elevata.
\end{flushleft}


\begin{flushleft}
Il problema del muovere un processo ` che ` un'operazione particolarmente cose
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
tosa. Utilizzando una politica di load balancing, conviene comunque fare delle
\end{flushleft}


\begin{flushleft}
valutazioni dinamiche (quindi non di tutto l'insieme dei processori; spesso sono
\end{flushleft}


\begin{flushleft}
valutazioni euristiche, per poter limitare il costo a volte inaccettabile) per approssimare il comportamento, per limitare il costo. Una possibile strategia, per
\end{flushleft}


\begin{flushleft}
esempio, ` quella di ridurre il numero dei processori su cui un processo pu` ese
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sere trasferito. Il load balancing deve essere valutato attentamente, perch` pu`
\end{flushleft}


\begin{flushleft}
e o
\end{flushleft}


\begin{flushleft}
divenire molto intrusivo. Le valutazioni dinamiche, che realizzano politiche di
\end{flushleft}


\begin{flushleft}
minima intrusione locali e semplici son sempre da preferire.
\end{flushleft}


\begin{flushleft}
Si sono visti diversi modelli per l'esecuzione di processi per ilload sharing:
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello a ring logico: un esempio ` V-kernel. Si denisce quindi una
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
struttura ssa, statica, che spiega come i processi possano muoversi. Vi
\end{flushleft}


85





\begin{flushleft}
\newpage
` un token che stabilisce quale processore ` il gestore in quel momento, il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quale richiede informazioni sul sistema mediante un broadcast. Ottenute
\end{flushleft}


\begin{flushleft}
le risposte, si genera il bilanciamento distribuendo il carico (che non si
\end{flushleft}


`


\begin{flushleft}
pu` quindi spostare). E una struttura statica e proattiva, per` semplice
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
da gestire anche a fronte di guasti.
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello a foresta: un esempio ` Micros. Vi ` una gerarchi di processori, in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
genere rappresentata ad albero, quindi pi` dinamica. Possibilit` di rappreu
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sentare anche foreste di processori. Al livello pi` basso vi sono i processori
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
che lavorano direttamente sulle risorse (worker), e i loro padri sono i manager: la profondit` dell'albero dipende quindi dal numero delle risorse che
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
si vengono a denire (in generale si cerca di avere un albero binario). L'obiettivo di Micros ` quello di gestire un elevato numero di risorse ed utenti,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
non basandosi sulla topologia reale della rete. Il sistema ` dinamico proe
\end{flushleft}


\begin{flushleft}
prio perch` permette anche di fare un'allocazione dinamica delle risorse,
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
richiedendole al livello superiore. L'architettura ` fault-tolerant.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Modello derivato dai worm d'Internet: si tratta di un buon livello per
\end{flushleft}


\begin{flushleft}
la ridistribuzione del carico. Rappresenta un sistema molto dinamico che
\end{flushleft}


\begin{flushleft}
richiede pochissime informazioni sull'architettura del sistema. L'idea `
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quella di ricopiare l'applicazione che si ricerca, valutando i nodi vicini e
\end{flushleft}


\begin{flushleft}
scegliendo quelli liberi.
\end{flushleft}


\begin{flushleft}
Nel caso di load balancing si parla di migrazione: un processo viene trasferito su
\end{flushleft}


`


\begin{flushleft}
un altro nodo. E un'operazione costosa, ma che presenta degli indubbi vantaggi,
\end{flushleft}


\begin{flushleft}
perch` permette di smistare il carico nel sistema. In questo modo si riescono a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
far lavorare tutti i processori, aumentando l'ecienza.
\end{flushleft}


`


\begin{flushleft}
E ovvio per` che per capire se le politiche addottate sono veramente un aiuo
\end{flushleft}


\begin{flushleft}
to, serve un apposito sistema di monitoring: rappresentano dei costi aggiuntivi,
\end{flushleft}


\begin{flushleft}
ma necessari per poter valutare istante per istante la situazione del sistema, e
\end{flushleft}


\begin{flushleft}
quindi per poter bilanciarlo correttamente! Il monitoring deve tenr conto dei
\end{flushleft}


\begin{flushleft}
processori, delle risorse e del tempo di comunicazione, e deve essere studiato per
\end{flushleft}


\begin{flushleft}
realizzare una politica di minima intrusione, assumendo un principio di continuit` dell'applicazione. Si introduce cos` una logica di trasparenza, rendendo
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
certi dati noti solo al supporto. Si punta quindi all'ecienza del sistema, alla
\end{flushleft}


\begin{flushleft}
mobilit` e alla realizzazione di un sistema fault-tolerant (crolla un processore,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
ma il processo migra su un'altra macchina!).
\end{flushleft}


\begin{flushleft}
La migrazione deve tener conto di diversi aspetti:
\end{flushleft}


\begin{flushleft}
1. Si deve comunque lasciar la precedenza alle computazioni locali.
\end{flushleft}


\begin{flushleft}
2. Si deve evitare il fenomeno del trashing, ovvero che un processo si muova
\end{flushleft}


\begin{flushleft}
continuamente da un processore all'altro, senza mai essere eseguito.
\end{flushleft}


\begin{flushleft}
3. Si deve evitare il fenomeno delle dipendenze residue: un nodo non dovrebbe
\end{flushleft}


\begin{flushleft}
mai ridirezionare le richieste verso il nuovo nodo su cui gira il processo.
\end{flushleft}


\begin{flushleft}
Vi ` infatti a possibilit` di generare dei cicli assolutamente pericolosi.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


86





\begin{flushleft}
\newpage
4. Il sistema deve essere concorrente, in grado di realizzare migrazioni multiple.
\end{flushleft}


\begin{flushleft}
Si deve quindi progettare il processo in maniera da poter trasportare quello che
\end{flushleft}


\begin{flushleft}
serve: in generale lo stato corrente pi` eventuali modiche che sono state apporu
\end{flushleft}


\begin{flushleft}
tate (magari si pu` trasportare anche solo un sottoinsieme delle informazioni).
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
Il grosso problema della migrazione ` quello del riuscire, nella maniera pi`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
eciente e meno costosa, a fornire ai clienti un sistema per accedere al processo
\end{flushleft}


\begin{flushleft}
anche se ` stato spostato.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
Una prima possibilit` ` quella di ridirigere i messaggi, sfruttando per esemae
\end{flushleft}


\begin{flushleft}
pio un'apposita struttura detta forwarder, in grado di farlo in maniera traspar`
\end{flushleft}


\begin{flushleft}
ente. E una strategia pessimistica/pro-attiva. In questo modo il cliente non
\end{flushleft}


\begin{flushleft}
viene avvisato! Una prima modica consiste quindi nel riqualicare i messaggi,
\end{flushleft}


\begin{flushleft}
avvisando anche il cliente oltre a ridirigerli per un certo tempo.
\end{flushleft}


\begin{flushleft}
Tuttavia, la strategia pi` brusca (ottimista e reattiva) ` quella di far proprio
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fallire il client: in questo modo il client si accorge che vi ` un qualche problema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
(non ` trasparente!) e si deve preoccupare di ricercare dove ` adesso il processo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che desidera, per ottenerne un riferimento.
\end{flushleft}


\begin{flushleft}
Demos/MP (anni 70) ` stato uno dei primi S.O. a pensare ad un sistema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


`


\begin{flushleft}
di load balancing, in cui ` il supporto che fa migrare i processi. E un sistema
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
basato sullo scambio di messaggi, e i processi si conoscono in base ad appositi
\end{flushleft}


\begin{flushleft}
link : queste strutture non sono come le porte, non son legati ai nodi su cui
\end{flushleft}


\begin{flushleft}
girano, ed era un sistema univoco per puntare al processo. Si tratta quindi di
\end{flushleft}


\begin{flushleft}
sistemi gestiti dall'infrastruttura.
\end{flushleft}


\begin{flushleft}
In particolare, Demos/MP si preoccupa di spostare solo processi pesanti, cio`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
che hanno un tempo d'esecuzione molto lungo (per esempio, processi ciclici).
\end{flushleft}


\begin{flushleft}
Non si fanno quindi migrare i processi con un tempo di vita limitato.
\end{flushleft}


\begin{flushleft}
Demos/MP ` stato anche il primo ideatore di un forwarder, che pu` lavorare
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
correttamente grazie al sistema a link! Il forwarder tuttavia ` una struttura
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
temporanea, nch` il link al processo non viene riqualicato, ovvero anche i
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
client riescono ad accederci direttamente senza dover passare dal nodo iniziale
\end{flushleft}


\begin{flushleft}
(si pu` comunque anche fare un sistema a scarto di messaggi, per cui la reo
\end{flushleft}


\begin{flushleft}
sponsabilit` del trovare il nuovo processore tocchi al cliente). Si deve quindi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
fermare l'esecuzione del processo sul nodo originale, trasferire lo stato sul nuovo
\end{flushleft}


\begin{flushleft}
processore, attivarlo e attivare il forwarder temporaneo. Si ha quindi alla ne
\end{flushleft}


\begin{flushleft}
una trasparenza all'allocazione.
\end{flushleft}


\begin{flushleft}
Un altro S.O. che prevede la migrazione dei processi ` il V-kernel (sempre
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a scambio di messaggi), che punta all'ecienza e ad essere fault-tolerant, oltre
\end{flushleft}


\begin{flushleft}
alla trasparenza all'allocazione. Questo S.O. lavora in maniera preventiva, per
\end{flushleft}


\begin{flushleft}
cui copia le dierenze fra i processori su cui gira (in tempi diversi) per evitare
\end{flushleft}


\begin{flushleft}
le dipendenze residue dovute al forwarder! Si ha quindi sempre una riqualicazione dei link.
\end{flushleft}





87





\begin{flushleft}
\newpage
La migrazione ` un modo molto buono per poter separare meccanismi e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
politiche. Le politiche per la migrazione dipendono da diverse considerazioni:
\end{flushleft}


\begin{flushleft}
1. Vale la pena migrare?
\end{flushleft}


\begin{flushleft}
2. Chi e quando trasferisce il processo?
\end{flushleft}


\begin{flushleft}
3. Su quale processore si allocher` il nuovo processo?
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
In generale possiamo osservare che vi sono dei meccanismi/caratteristiche comuni, per cui vi sono solo certe categorie di processi che si possono spostare, ed
\end{flushleft}


\begin{flushleft}
` necessario un gestore per la migrazione per ogni nodo. Si deve quindi essere in
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
grado di denire cosa trasferire, cosa si pu` migrare, ovvero la costituzione steso
\end{flushleft}


\begin{flushleft}
sa della risorsa! Si ha che quindi si blocca il processo, se ne crea una copia sul
\end{flushleft}


\begin{flushleft}
nuovo processore, e quindi si avvia un sistema per riqualicare i link, elimando
\end{flushleft}


\begin{flushleft}
quelli obsoleti. Nel mentre, si riutano le comunicazioni con il processo.
\end{flushleft}


\begin{flushleft}
Quanto costa? Un S.O., Charlotte, stimava il costo in base al numero dei
\end{flushleft}


\begin{flushleft}
link presenti, della dimensione del processo da trasferire e da una parte costante
\end{flushleft}


\begin{flushleft}
di comunicazione: al crescere delle dimensioni del processo, il tempo totale per
\end{flushleft}


\begin{flushleft}
il trasferimento aumenta notevolmente.
\end{flushleft}


\begin{flushleft}
Le politiche di migrazione sono quindi stabilite mediante un sistema di valutazione del carico, e la decisione di chi trasferire e quando, spesso accomunata
\end{flushleft}


\begin{flushleft}
a dove si deve trasferire, ovvero un concetto di locazione. In particolare, si deve
\end{flushleft}


\begin{flushleft}
trovare un sistema per valutare qual'` l'impatto sullo scheduling locale, potendo
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
integrare quindi politiche di pi` alta gestione. Le politiche si possono quindi
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
classicare come:
\end{flushleft}


\begin{flushleft}
$\bullet$ Statiche: sono molto facili da valutare, e risulta facile denire come trasferire
\end{flushleft}


\begin{flushleft}
(tipo, si decide che sono i processi nuovi a muoversi, fornendo per` un rio
\end{flushleft}


\begin{flushleft}
schio di trashing). La locazione ` statica, e anche se non risulta essere
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
essibile, presenta un costo molto basso.
\end{flushleft}


\begin{flushleft}
$\bullet$ Semi-dinamiche: sono politiche pi` costose, perch` dipendono dalla situu
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
azione attuale. Si realizza una scelta ciclica dei processi e dei destinatari.
\end{flushleft}


\begin{flushleft}
Il carico ` quindi dinamico.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
$\bullet$ Dinamiche: Si intende di lavorare per un sistema di vicinato, ovvero si
\end{flushleft}


\begin{flushleft}
cerca di spostare il carico su processi vicini. Si deve quindi valutare il
\end{flushleft}


\begin{flushleft}
carico del vicinato, e trovare sistemi poco costosi per determinarlo.
\end{flushleft}


\begin{flushleft}
Le politiche possono essere pi` o meno complesse, realizzando magari politiche
\end{flushleft}


\begin{flushleft}
u
\end{flushleft}


\begin{flushleft}
incondizionate (meccanismi random) o condizionate: queste ultime sonopi` cosu
\end{flushleft}


\begin{flushleft}
tose, presentando un overhead dovuto ad una comuncaizione per fare delle negoziazioni ! Questo sistema ` detto probing, perch` ovviamente si cerca nel
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
vicinato, per limitare il costo (non ha senso cercare nella globalit` !). Si possono
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
anche realizzare politiche di bidding, per ricercare un processore disponibile ad
\end{flushleft}


\begin{flushleft}
eseguire il processo, e scegliendo la migliore oerta proposta.
\end{flushleft}





88





\begin{flushleft}
\newpage
Non esiste una politica migliore in assoluto: in generale, conviene avere
\end{flushleft}


\begin{flushleft}
un'inziativa da parte di un sender (da chi possiede il processo e che lo vorrebbe
\end{flushleft}


\begin{flushleft}
spostare) se si ha un sistema con carichi bassi, altrimenti da parte del receiver
\end{flushleft}


\begin{flushleft}
(un processore che potrebbe fornire risorse per un altro processo). Un approccio
\end{flushleft}


\begin{flushleft}
misto risulta quindi essere il migliore.
\end{flushleft}


\begin{flushleft}
La migrazione ` un sistema che deve essere studiato attentamente: pu`
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
infatti ridurre notevolmente i tempi dell'applicazione, sfruttando politiche semplici. Si ha quindi un'intrusione limitata per ottenere i risultati desiderati. Si
\end{flushleft}


\begin{flushleft}
deve quindi puntare all'ecienza, tendere all'ottimalit` e realizzare un sistema
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
stabile.
\end{flushleft}





9.3





\begin{flushleft}
Sistemi ad agenti mobili
\end{flushleft}





\begin{flushleft}
I sistemi ad agenti mobili si mappa molto bene con il problema della migrazione.
\end{flushleft}


\begin{flushleft}
Tuttavia, l'approccio ` diverso: non si navigano i nodi per ottimizzare il bilane
\end{flushleft}


\begin{flushleft}
ciamento del carico, ma per ottenere informazioni dai diversi nodi. Si ha quindi
\end{flushleft}


\begin{flushleft}
un movimento dovuto all'applicazione, e non da esigenze di ecienze per la
\end{flushleft}


\begin{flushleft}
computazione e diretto dal supporto!
\end{flushleft}


\begin{flushleft}
Il movimento ` quindi una caratteristica base degli agenti mobili, per cui si
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
deve cercare di determinare dei sistemi ecienti. Nulla per esempio impedisce
\end{flushleft}


\begin{flushleft}
ad un agente di ritornare su nodi gi` visitati.
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
Per gli agenti si parla quindi di mobilit` del codice (modello che va oltre
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
al normale approccio C/S, per cui si passano solo dati. Sono sistemi utili per
\end{flushleft}


\begin{flushleft}
esempio per aggiornare i diversi router). Prima degli agenti mobili, per mobilit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
del codice si parla di:
\end{flushleft}


\begin{flushleft}
$\bullet$ Remote EValuation: ` un'operazione singola, one-hop, per cui si invia il
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
codice al server, che ne diventa parte integrante!
\end{flushleft}


\begin{flushleft}
$\bullet$ Code On Demand : processo inverso, ovvero il client scarica codice proveniente dal server (un esempio classico sono le applet Java!)
\end{flushleft}


\begin{flushleft}
Questi sistemi per` non prevedono ancora la possibilit` che il codice, mentre si
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
muove, esegua! Questo si ha solo con l'introduzione degli agenti mobili. Sono infatti sistemi a multi-hop, in grado di cambiare l'allocazione durante l'esecuzione
\end{flushleft}


\begin{flushleft}
e mantenere comunque uno stato coeso. Si pu` pensare a varie ottimizzazioni,
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
magari trasportando solo le dierenze rispetto ad uno stato iniziale o una sintesi
\end{flushleft}


\begin{flushleft}
dei risultati ottenuti.
\end{flushleft}





9.4





\begin{flushleft}
Classicazione della mobilit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





\begin{flushleft}
Per gli agenti mobili, si pu` classicare in diversi gradi la mobilit`:
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Forte: In ogni punto del codice ` possibile specicare la mobilit`. Tali
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sistemi sono in realt` dicilmente realizzabili, perch` presentano grossi
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
problemi di supporto.
\end{flushleft}





89





\begin{flushleft}
\newpage
$\bullet$ Debole: Si vincola invece la posizione in cui si pu` mettere la {`}move': tale
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
sistema ` meno essibile, ma maggiormente e facilmente gestibile.
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
La dierenza quindi ` nella continuit` della mobilit` (o avviene sempre, oppure
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
solo in certi momenti prestabiliti). Come risolvere la mobilit` forte? L'idea `
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
quella di realizzare un sistema a codice intermedio, potendo cos` fornire su ogni
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
nodo degli interpreti del codice intermedio (per poter superare cos` i diversi
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
problemi dovuti all'eterogeneit`).
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}





9.5





\begin{flushleft}
Servono gli agenti mobili?
\end{flushleft}





\begin{flushleft}
In generale, un progetto giustica la scelta della tecnologia. Tuttavia, se i vincoli
\end{flushleft}


\begin{flushleft}
risultano essere sbagliati, si usa a sproposito la tecnologia.
\end{flushleft}


\begin{flushleft}
Attualmente, per gli agenti mobili si ` ancora alla ricerca di una killer applie
\end{flushleft}


\begin{flushleft}
cation; in certi casi conviene ancora usare sistemi come REV o COD. La mobilit`
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
attualmente ` vista come il sistema migliore per poter accedere a risorse vine
\end{flushleft}


\begin{flushleft}
colate, cercando di ottimizzare il sistema utilizzando delle operazioni locali. Vi
\end{flushleft}


\begin{flushleft}
sono diversi tipi di mobilit`:
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
$\bullet$ Utente nomade: non ha senso utilizzare gli agenti, ma conviene invece
\end{flushleft}


\begin{flushleft}
gestire un sistema a repository centrale. L'utente vuole eseguire le proprie
\end{flushleft}


\begin{flushleft}
applicazioni indipendentemente da quale macchina stia utilizzando.
\end{flushleft}


\begin{flushleft}
$\bullet$ Terminali mobili : potrebbe aver senso utilizzare gli agenti. Si tratta infatti
\end{flushleft}


\begin{flushleft}
dell'idea di realizzare terminali in grado di lavorare comunque ed ovunque
\end{flushleft}


\begin{flushleft}
si trovino.
\end{flushleft}


\begin{flushleft}
$\bullet$ Codice mobile: denitivamente utile utilizzare gli agenti.
\end{flushleft}





9.6





\begin{flushleft}
Gli agenti mobili
\end{flushleft}





\begin{flushleft}
Sono delle entit` che si devono muovere per eseguire i propri compiti, operando
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
per conto di un principal. Si tratta quindi di sistemi in cui il programmatore stabilisce la mobilit`, e in cui si realizza una programmazione location-awareness,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
cio` dipendente dal posto in cui si esegue. Possono essere utili quindi per poter
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
fornire un controllo locale alle risorse, ltrando quindi le richieste da parte di un
\end{flushleft}


\begin{flushleft}
gestore centrale! Gli agenti mobili devono essere progettati secondo un'ottica di
\end{flushleft}


\begin{flushleft}
leggerezza: essere semplici, single-threaded (Java sembra un'ottima tecnologia
\end{flushleft}


\begin{flushleft}
per realizzarli). Sono in corso di sviluppo mw, orientati alla weak mobility:
\end{flushleft}


\begin{flushleft}
studio quindi di strutture dati apposite per la mobilit`, permettendo soltanto
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
delle richieste esplicite alla migrazione.
\end{flushleft}


\begin{flushleft}
Vi possono essere diverse implementazioni: con connessione o connectionless,
\end{flushleft}


\begin{flushleft}
comunicazioni sincrone o meno, possibilit` di realizzare un sistema sincronizzato
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
di agenti o meno, e cos` via. Tuttavia, tutti i sistemi ad agenti introducono un
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
enorme problema per la sicurezza (codice che naviga ed agisce in una rete. . . ). Si
\end{flushleft}


\begin{flushleft}
potrebbe infatti avere del codice maligno che gira. Tuttavia, i controlli potrebbero anche impedire ad un nodo di eseguire codice non maligno, scartando
\end{flushleft}





90





\begin{flushleft}
\newpage
via l'agente! Si deve quindi vericare mediante l'uso di diversi agenti se per
\end{flushleft}


\begin{flushleft}
vericare il comportamento del nodo.
\end{flushleft}


\begin{flushleft}
Un altro problema ` sul fatto che il codice pu` essere letto senza problemi
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
dal nodo su cui esegue: si devono quindi anche garantire certe propriet` di
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
incapsulamento, perch` non sia un nodo a modicare il codice contenuto da un
\end{flushleft}


\begin{flushleft}
e
\end{flushleft}


\begin{flushleft}
agente!
\end{flushleft}


\begin{flushleft}
A cosa pu` essere utile tutto ci`? A realizzare mobile computing (utenti in
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
o
\end{flushleft}


\begin{flushleft}
grado di muoversi e di mantenere uno stato/sessione costante, anche cambiando
\end{flushleft}


\begin{flushleft}
terminale, ottenendo cos` la massima accessibilit`) ottenendo per esempio la
\end{flushleft}


\begin{flushleft}
\i{}
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
generazione di reti spontanee (utili per esempio per creare reti per giochi, solo su
\end{flushleft}


\begin{flushleft}
disponibilit`), possibilit` di coordinare utenti mobili in ambienti civili e militari,
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
a
\end{flushleft}


\begin{flushleft}
sistemi location awareness. . .
\end{flushleft}





91





\newpage



\end{document}
